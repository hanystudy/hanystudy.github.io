<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Wing of Dream 梦境之翼]]></title>
  <link href="http://www.hanyi.name/atom.xml" rel="self"/>
  <link href="http://www.hanyi.name/"/>
  <updated>2015-07-08T15:46:54+08:00</updated>
  <id>http://www.hanyi.name/</id>
  <author>
    <name><![CDATA[Han Yi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Ruby Web服务器：这十五年]]></title>
    <link href="http://www.hanyi.name/blog/2015/06/28/ruby-webserver-last-10-years/"/>
    <updated>2015-06-28T16:39:54+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/06/28/ruby-webserver-last-10-years</id>
    <content type="html"><![CDATA[<p>坦率的说，作为一门年轻的计算机语言，Ruby在最近二十年里的发展并不算慢。但如果与坐拥豪门的明星语言们相比，Ruby就颇显平民范儿，表现始终不温不火，批评胜于褒奖，下行多过上扬。但总有一些至少曾经自称过Rubyist的程序员们，愉快地实践了这门语言，他们没有丝毫的歧视习惯，总是努力尝试各家之长，以语言表达思想，用基准评判高下，一不小心就影响了整个技术发展的进程。</p>

<p>本文谨以Ruby Web服务器技术的发展为线索，回顾Ruby截至目前最为人所知的Web领域中，重要性数一数二的服务器技术的发展历程，试图帮助我们了解过去，预见未来。</p>

<h3>一、随波逐流</h3>

<p>长久以来，任何Web服务器都具备的两项最重要的功能：一是根据RFC2616解析HTTP/1.1协议，二是接收、处理并响应客户端的HTTP请求。幸运的是Web技术的发展并不算太早，使得Ruby恰好能赶上这趟顺风车，但在前期也基本上受限于整个业界的进展。像Apache HTTP Server、Lighttpd和Nginx这些通用型Web服务器＋合适的Web服务器接口即可完成大部分工作，而当时开发者的重心则是放在接口实现上。</p>

<h4>cgi.rb</h4>

<p>作为Web服务器接口的早期标准，CGI程序在调用过程中，通过环境变量（GET）或$stdin（POST）传递参数，然后将结果返回至$stdout，从而完成Web服务器和应用程序之间的通信。cgi.rb是Ruby官方的CGI协议标准库，发布于2000年的cgi.rb包含HTTP参数获取、Cookie/Session管理、以及生成HTML内容等基本功能。</p>

<p><img src="http://7xk84n.com1.z0.glb.clouddn.com/ruby_web_servers/cgi.png" alt="Web服务器和CGI" /></p>

<p>当支持CGI应用的Web服务器接到HTTP请求时，需要先创建一个CGI应用进程，并传入相应的参数，当该请求被返回时再销毁该进程。因此CGI原生是单一进程/请求的，特别是每次请求时产生的进程创建/销毁操作消耗了大量系统资源，根本无法满足较高负载的HTTP请求。此外，CGI进程模型还限制了数据库连接池、内存缓存等资源的复用。</p>

<p>对于标准CGI应用存在的单一进程问题，各大厂商分别提出了兼容CGI协议的解决方案，包括网景的NSAPI、微软的ISAPI和后来的Apache API（ASAPI）。上述服务器API的特点是既支持在服务器进程内运行CGI程序，也支持在独立进程中运行CGI程序，但通常需要在服务器进程中嵌入一个插件以支持该API。</p>

<h4>Webrick</h4>

<p>作为最古老的Ruby Web服务器而不仅仅是一个接口，诞生于2000年的Webrick从Ruby 1.9.3（2011年10月正式发布）起被正式纳入标准库，成为Ruby的默认Web服务器API。Webrick支持HTTP/HTTPS、代理服务器、虚拟主机服务器，以及HTTP基础认证等RFC2617及以外的其它认证算法。同时，一个Webrick服务器还能由多个Webrick服务器或服务器小程序组合，提供类似虚拟主机或路由等功能：例如处理CGI脚本、ERb页面、Ruby块以及目录服务等。</p>

<p>Webrick曾被用于Rails核心团队的开发和测试中。但是，Webrick内置的HTTP Parser非常古老，文档缺失，性能低下且不易维护，功能单一且默认只支持单进程模式（但支持多线程，不过在Rails中默认关闭了对Webrick的多线程支持），根本无法满足产品环境中的并发和日常维护需求。目前一般只用于Web应用的本地开发和基准测试。</p>

<h4>fcgi.rb</h4>

<p>fcgi.rb是FastCGI协议的Ruby封装（latest版底层依赖libfcgi）。为了与当时的NSAPI竞争，FastCGI协议最初由Open Market提出和开发、并应用于自家Web服务器，延续了前者采用独立进程处理请求的做法：即维持一个FastCGI服务器。当Web服务器接收到HTTP请求时，请求内容和环境信息被通过Socket（本地）或TCP连接（远程）的方式传递至FastCGI服务器进行处理，再通过相反路径返回响应信息。分离进程的好处是Web服务器进程和FastCGI进程是永远保持的，只有相互之间的连接会被断开，避免了进程管理的开销。</p>

<p><img src="http://7xk84n.com1.z0.glb.clouddn.com/ruby_web_servers/fastcgi.png" alt="Web服务器和FastCGI/SCGI服务器" /></p>

<p>进一步，FastCGI还支持同时响应多个请求。为了尽量减少资源浪费，若干请求可以复用同一个与Web服务器之间的连接，且支持扩展至多个FastCGI服务器进程。FastCGI降低了Web服务器和应用程序之间的耦合度，进而为解决安全、性能、管理等各方面问题提供新的思路，相比一些嵌入式方案如mod_perl和mod_php更具灵活性。</p>

<p>由于FastCGI协议的开放性，主流Web服务器产品基本都实现了各自的FastCGI插件，从而导致FastCGI方案被广泛使用。fcgi.rb最早开发于1998年，底层包含C和Ruby两种实现方式，早期曾被广泛应用于Rails应用的产品环境。</p>

<h4>mod_ruby</h4>

<p>mod_ruby是专门针对Apache HTTP Server的Ruby扩展插件，支持在Web服务器中直接运行Ruby CGI代码。由于mod_ruby在多个Apache进程中只能共享同一个Ruby解释器，意味着当同时运行多个Web应用（如Rails）时会发生冲突，存在安全隐患。因此只在一些简单部署环境下被采用，实际上并没有普及。</p>

<h4>LiteSpeed API/RubyRunner</h4>

<p>LiteSpeed是由LiteSpeed Tech公司最初于2002年发布的商用Web服务器，特点是与被广泛采用的Apache Web服务器的配置文件兼容，但因为采用了事件驱动架构而具有更好的性能。</p>

<p>LiteSpeed API（LSAPI）是LiteSpeed专有的服务器API，LSAPI具备深度优化的IPC协议以提升通信性能。类似其它Web服务器，LiteSpeed支持运行CGI、FastCGI、以及后来的Mongrel。同时在LSAPI的基础上开发了Ruby接口模块，支持运行基于Ruby的Web应用。此外，LiteSpeed还提供RubyRunner插件，允许采用第三方Ruby解释器运行Ruby应用，但综合性能不如直接基于LSAPI Ruby。</p>

<p>由于LiteSpeed是收费产品，其普及率并不高，一般会考虑采用LiteSpeed作为Web服务器的业务场景包括虚拟主机/VPS提供商、以及相关业务的cPanel产品。同时，LiteSpeed也会被用于一些业务需求比较特殊的场合，例如对Web服务器性能要求高，且应用程序及其部署需要兼容Apache服务器。LiteSpeed于2013年发布了开源的轻量Web服务器——OpenLiteSpeed（GPL v3），移除了商业版本中偏具体业务的功能如cPanel等，更倾向于成为通用Web服务器。</p>

<h4>scgi.rb</h4>

<p>scgi.rb是对SCGI协议的纯Ruby实现。从原理上来看，SCGI和FastCGI类似，二者的性能并无多大差别。但比起后者复杂的协议内容来说，SCGI移除了许多非必要的功能，看起来十分简洁，且实现复杂度更低。</p>

<p><img src="http://7xk84n.com1.z0.glb.clouddn.com/ruby_web_servers/fastcgi_advance.png" alt="Web服务器和多FastCGI/SCGI服务器" /></p>

<p>与FastCGI类似，一个SCGI服务器可以动态创建服务器子进程用于处理更多请求（处理完毕将转入睡眠），直至达到配置的子进程上限。当获得Web服务器请求时，SCGI服务器进程会将其转发至子进程，并由子进程运行CGI程序处理该请求。此外，SCGI还能自动销毁退出和崩溃的子进程，具有良好的稳定性。</p>

<h3>二、闻名天下</h3>

<p>2005年，David Heinemeier Hansson（DHH）发布了基于Ruby的开发框架Ruby on Rails（Rails），聚光灯第一次聚焦在Ruby身上。但是业内普遍对Web服务器的方案感到棘手，本地环境Webrick/产品环境FastCGI＋通用Web服务器几乎成了标配，无论是开发、部署或维护都遇到不少困难，一些吃螃蟹的人遂把此视为Rails不如J2EE、PHP方案的证据。</p>

<h4>Mongrel</h4>

<p>2006年，Zed Shaw发布了划时代的Mongrel。Mongrel把自己定位成一个“应用服务器”，因为其不仅可以运行Ruby Web应用，也提供标准的HTTP接口，从而使Mongrel可以被放置在Web代理、Load Balancer等任意类型的转发器后面，而非像FastCGI、SCGI一样通过调用脚本实现Web服务器和CGI程序的通信。</p>

<p>Mongrel采用Ragel开发HTTP/1.1协议的Ruby parser，而后者是一个高性能有限自动机编译器，支持开发协议/数据parser、词法分析器和用户输入验证，支持编译成多种主流语言（包括Ruby）。采用Regel也使parser具有更好的可移植性。但是，Mongrel本身不支持任何应用程序框架，而需要由框架自身提供这种支持。</p>

<p><img src="http://7xk84n.com1.z0.glb.clouddn.com/ruby_web_servers/mongrel.png" alt="Mongrel Web服务器" /></p>

<p>Mongrel支持多线程运行（但对于当时非线程安全的Rails来说，仍然只能采用多进程的方式提高一部分并发能力），曾被Twitter作为其第一代Web服务器，还启发了Ryan Dahl发布于2009年的Node.JS。</p>

<p>但是当Mongrel发布后没过多久，Shaw就与Rails社区的核心成员不和（实际上Shaw对业界的许多技术和公司都表达过不满），随后就终止了Mongrel的开发。进而在其Parser的基础上开发了其后续——语言无关的Web服务器Mongrel2（与前续毫无关系）。</p>

<p>尽管Mongrel迅速衰落，却成功启发了随后更多优秀Ruby应用服务器的诞生，例如后文将介绍的Thin、Unicorn和Puma。</p>

<h4>Rack</h4>

<p>随着Web服务器接口技术的发展，从开始时作为一个module嵌入Web服务器，到维护独立的应用服务器进程，越来越多的应用服务器产品开始涌现，同时相互之间还产生了差异化以便适应不同的应用场景。但是，由于底层协议和API的差别，基于不同的应用服务器开发Web产品时，意味着要实现各自的通信接口，从而为Web应用开发带来更多工作量。特别是对于类似Django、Rails这些被广泛使用的Web框架来说，兼容主流应用服务器几乎是必须的。</p>

<p>2003年，Python界权威Phillip J. Eby发表了PEP 0333（Python Web Server Gateway Interface v1.0，即WSGI），提出一种Web服务器和应用程序之间的统一接口，该接口封装了包括CGI、FastCGI、mod_python等主流方案的API，使遵循WSGI的Python Web应用能够直接部署在各类Web服务器上。与Python的发展轨迹相似，Ruby界也遇到了类似的挑战，并最终在2007年出现了与WSGI类似的Rack。</p>

<p>与WSGI最初只作为一份建议不同，Rack直接提供了模块化的框架实现，并由于良好的设计架构迅速统一了Ruby Web服务器和应用程序框架接口。</p>

<p>Rack被设计成一种中间件“框架”，接收到的HTTP请求会被rack放入不同的管线（中间件）进行处理，直到从应用程序获取响应。这种设计通过统一接口，把一般Web应用所需的底层依赖，包括Session处理、数据库操作、请求处理、渲染视图、路由/调度、以及表单处理等组件以中间件的形式“放入”rack的中间件管线中，并在HTTP请求/响应发生时依次通过上述管线传递至应用程序，从而实现Web应用程序对底层通信依赖的解绑。</p>

<p><img src="http://7xk84n.com1.z0.glb.clouddn.com/ruby_web_servers/rack.png" alt="Rack中间件" /></p>

<p>Rack接口部分包含两类组件：Handler，用于和Web服务器通信；Adapter，用于和应用程序通信。截至Rack 1.6，Rack内置的handlers包括WEBrick、FCGI、CGI、SCGI、LiteSpeed以及Thin，上述handlers用以兼容已有的常见应用服务器。而2008年后，随着rack逐渐成为事实标准，更新的Ruby Web服务器几乎都包含Rack提供的handler。包括Rails、Sinatra、Merb等等几乎所有主流框架都引入了Rack Adapters的支持。</p>

<h3>三、百花齐放</h3>

<p>Mongrel和Rack的相继诞生，使Ruby Web服务器、乃至应用程序框架的发展有了一定意义上可以遵循的标准。Mongrel后相继派生出Thin、Unicorn和Puma；而Rack统一了Ruby Web服务器和应用程序框架接口，使应用开发不再需要考虑特定的部署平台。Ruby Web服务器开始依据特定需求深入发展。</p>

<h4>Thin/Goliath</h4>

<p>发布于2009年的Thin沿用了Mongrel的Parser，基于Rack和EventMachine开发，前者上文已有介绍，EventMachine是一个Ruby编写的、基于Reactor模式的轻量级事件驱动I/O（类似JBoss Netty、Apache MINA、Python Twisted、Node.js、libevent和libev等）和并发库，使Thin能够在面对慢客户端的同时支持高并发请求。</p>

<p>发表自1995年的Reactor模型的基本原理是采用一个单线程事件循环缓存所有系统事件，当事件发生时，以同步方式将该事件发送至处理模块，处理完成后返回结果。基于Reactor模型的EventMachine具备异步（非阻塞）I/O的能力，被广泛用于大部分基于Ruby的事件驱动服务器、异步客户端、网络代理以及监控工具中。</p>

<p><img src="http://7xk84n.com1.z0.glb.clouddn.com/ruby_web_servers/reactor.png" alt="Reactor模型" /></p>

<p>2011年，社交网络分析商PostRank开源了其Web服务器Goliath，与Thin相似（都采用了EventMachine）但又有很大不同，采用新的HTTP Parser，同时针对异步事件编程中的高复杂度回调函数问题，借助Ruby1.9+的纤程技术实现了线性编码，使程序具备更好的可维护性。Goliath支持MRI、JRuby和Rubinius等多平台。在附加功能方面，Goliath的目标不仅是作为Web服务器，更是一个快速构建WebServices/APIs的开发框架，但是随着之后PostRank被Google收购，Goliath项目也就不再活跃在开源界了。</p>

<h4>Unicorn</h4>

<p>2009年，Eric Wong在Mongrel 1.1.5版本的基础上开发了Unicorn。Unicorn是一个基于Unix/类Unix操作系统的、面向快客户端、低延迟和高带宽场景的Rack服务器，基于上述限制，任何情况下几乎都需要在Unicorn和客户端之间设置一个反向代理缓存请求和响应数据，这是Unicorn的设计特点所决定的，但也使得Unicorn的内部实现相对简洁、可靠。</p>

<p>尽管来源于Mongrel，但Unicorn只在进程级运行，且吸收和利用了一些Unix/类Unix系统内核的特性，如Prefork模型。</p>

<p>Unicorn由1个master进程和n个fork(2)子进程组成，子进程分别调用select(2)阻塞自己，直到出错或者超时时，才做一些写日志、处理信号以及维护与master的心跳链接等内置任务。子进程和master间通过一个共享socket实现通信，而由Unix/类Unix系统内核自身处理资源调度。</p>

<p><img src="http://7xk84n.com1.z0.glb.clouddn.com/ruby_web_servers/unicorn.png" alt="Unicorn的多进程模型" /></p>

<p>Unicorn的设计理念是“只专注一件事”：多进程阻塞I/O的方式令其无从接受慢客户端——但前置反向代理能解决这一问题；workers的负载均衡就直接交给操作系统处理。这种理念大大降低了实现复杂度，从而提高了自身可靠性。此外，类似Nginx的重加载机制，Unicorn也支持零宕机重新加载配置文件，使其允许在线部署Web应用而不用产生离线成本。</p>

<h4>Phusion Passenger（mod_rails/mod_rack）</h4>

<p>2008年初，一位叫赖洪礼的Ruby神童发布了mod_rails。尽管Mongrel在当时已经席卷Rails的Web服务器市场，但是面对部署共享主机或是集群的情况时还是缺少统一有效的解决方案，引起业内一些抱怨，包括DHH（也许Shaw就不认为这是个事儿）。</p>

<p>mod_rails最初被设计成一个Apache的module，与FastCGI的原理类似，但设置起来异常简单——只需要设置一个RailsBaseURI匹配转发至Rails服务器的URI串。mod_rails服务器会在启动时自动加载Web应用程序，然后按需创建子进程，并协调Web服务器和Rails服务器的通信，从而支持单一服务器同时部署多个应用，还允许按需自动重启应用服务器。</p>

<p>mod_rails遵循了Rails的设计原则，包括Convention over Configuration、Don&rsquo;t Repeat Yourself，使其面向部署非常友好，很快得到了业界青睐，并在正式release时改名Passenger。</p>

<p>在随后的发展中，Passenger逐渐成为独立的Ruby应用服务器、支持多平台的Web服务器。截至2015年6月，Phusion Passenger的版本号已经达到5.0.10（Raptor），核心采用C++编写，同时支持Ruby、Python和Node.js应用。支持Apache、Nginx和独立HTTP模式（推荐采用独立模式），支持Unix/类Unix系统，在统计网站Builtwith上排名Ruby Web服务器使用率第一。</p>

<p>值得一提的是，Phusion Passenger的开源版本支持多进程模式，但是其企业版同样支持多线程运行。本文撰写时，Phusion Passenger是最近一个号称“史上最快”的Ruby Web服务器（本文最后将进一步介绍Raptor）。</p>

<h4>Trinidad/TorqueBox</h4>

<p>Trinidad发布于2009年，基于JRuby::Rack和Apache Tomcat，使Rails的部署和世界上最流行的Web服务器之一Tomcat结合，支持集成Java代码、支持多线程的Resque和Delayed::Job等Worker，也支持除Tomcat以外的其它Servlet容器。</p>

<p>与Trinidad相比，同样发布于2009年的TorqueBox不仅仅是一个Web服务器，而且被设计成一个可移植的Ruby平台。基于JRuby::Rack和WildFly（JBoss AS），支持多线程阻塞I/O，内置对消息、调度、缓存和后台进程的支持。同时具有集群、负载均衡、高可用等多种附加功能。</p>

<h4>Puma</h4>

<p>Puma——Mongrel最年轻的后代于2011年发布，作者是Evan Phoenix。</p>

<p>由于Mongrel诞生于前Rack时期，而随着Rack统一了Web服务器接口，任何基于Rack的应用再与Mongrel配合就有许多不便。Puma继承了前者的Parser，并且基于Rack重写了底层通信部分。更重要的是，Puma部分依赖Ruby的其它两个流行实现：Rubinius和JRuby，与TorqueBox类似拥有多线程阻塞I/O的能力（MRI平台不支持真正意义上的多线程，但Puma依然具有良好并发能力），支持高并发。同时Puma还包含了一个事件I/O模块以缓冲HTTP请求，以降低慢客户端的影响。但是，从获得更高吞吐量的角度来说，Puma目前仍然需要采用Rubinius和JRuby这两个平台。</p>

<h4>Reel</h4>

<p>Reel是最初由Tony Arcieri发布于2012年的采用事件I/O的Web服务器。采用了不同于Eventmachine的Celluloid::IO，后者基于Celluloid——Actor并发模型的Ruby实现库，解决了EM只能在单一线程中运行事件循环程序的问题，从而同时支持多线程＋事件I/O，在非阻塞I/O和多线程方案间实现了良好的融合。</p>

<p>与其它现代Ruby Web服务器不同的是，Reel并不是基于Rack创建，但通过Reel::Rack提供支持Rack的Adapter。尽管支持Rails，与Puma也有一定的相似性，但与Unicorn、Puma和Raptor相比，Reel在部署Rails/Rack应用方面缺少易用性。实际上基于Celluloid本身的普及程度和擅长领域，相比其它Web服务器而言，Reel更适合部署WebSocket/Stream应用。</p>

<h4>Yahns</h4>

<p>2013年，Eric Wong等人受Kqueue（源自FreeBSD，同时被Node.js作为基础事件I/O库）的启发启动了Yahns项目。其目标与Reel类似，同样是在非阻塞I/O设计中引入多线程。与Reel不同的是，Yahns原生支持Rack/HTTP应用。</p>

<p>Yahns被设计成具有良好的伸缩性和轻量化特性，当系统应用访问量较低或为零时，Yahns本身的资源消耗也会保持在较低水平。此外，yahns只支持GNU/Linux（并通过kqueue支持FreeBSD），并声称永远不会支持类似Unicorn或Passenger里的Watchdog技术，不会因为应用崩溃而自动销毁和创建进程/线程，因此对应用程序本身的可靠性有一定要求。</p>

<h3>四、迈向未来</h3>

<p>回顾过去，Ruby Web服务器在发展中先后解决了缺少部署方案、与Web应用程序不兼容、运维管理困难等问题，基础架构趋于成熟且稳定。而随着更多基准测试结果的出现，业界逐渐开始朝着更高性能和并发量发展，同时针对HTTP协议本身的优化和扩展引入的HTTP/2，以及HTML5的WebSocket/Stream等需求均成为未来Ruby Web服务器发展的方向。</p>

<h4>高吞吐量</h4>

<p>以最新的Raptor（上文提到的Phusion Passenger 5）为例，其在网络I/O模型的选择上融合了现有其它优秀产品的方案，包括Unicorn的多进程模型、内置基于多线程和事件I/O模型的反向代理缓冲（类似Nginx的功能，但对Raptor自身做了大量裁减和优化）、以及企业版具有的多线程模型（类似Puma和TorqueBox）；此外，Raptor采用的Node.js HTTP Parser（基于Nginx的Parser）的性能超过了Mongrel；更进一步，Raptor甚至实现了Zero-copy和一般在大型游戏中使用的区域内存管理技术，使其对CPU和内存访问的优化达到了极致（感兴趣的话可以进一步查阅<a href="http://www.rubyraptor.org/how-we-made-raptor-up-to-4x-faster-than-unicorn-and-up-to-2x-faster-than-puma-torquebox/">这篇文章</a>）。</p>

<p><img src="http://7xk84n.com1.z0.glb.clouddn.com/ruby_web_servers/raptor.png" alt="Raptor的优化模型" /></p>

<p>另外也需要看到，当引入多线程运行方式，现有Web应用将不得不仔细检查自身及其依赖，是否是线程安全的，同时这也给构建Ruby Web应用带来更多新的挑战。这也是为什么更多人宁愿选择进程级应用服务器的方式——毕竟对大多数应用来说不需要用到太多横向扩展，引入反向代理即可解决慢客户端的问题，而采用Raptor甚至在独立模式能工作的更好（这样就不用花时间去学习Nginx）。</p>

<p>除非你已经开始考虑向支持大规模并发的架构迁移，并希望节省接下来的一大笔花费了。</p>

<h4>HTTP/2</h4>

<p>2015年5月，HTTP/2随着RFC7540正式发布。如今各主流服务器/浏览器厂商正在逐渐完成从HTTP/2测试模块到正式版本的过渡。而截至目前，主流Ruby Web服务器都还没有公开HTTP/2的开发信息。HTTP-2是在2013年由Ilya Grigorik发布的纯Ruby的HTTP/2协议实现，包括二进制帧的解析与编码、流传输的多路复用和优先级制定、连接和流传输的流量控制、报头压缩与服务器推送、连接和流传输管理等功能。随着HTTP/2的发布和普及，主流Ruby Web服务器将不可避免的引入对HTTP/2的支持。</p>

<h4>WebSocket/流（Stream）/服务器推送事件（Server Sent Events，SSE）</h4>

<p>2011年，RFC6455正式公布了WebSocket协议。WebSocket用于在一个TCP链接上实现全双工通信，其目的是实现客户端与服务器之间更高频次的交互，以完成实时互动业务。鉴于该特点，仅支持慢客户端的Web服务器就无法有效支撑WebSocket的并发需求，更何况后者对并发量更加严苛的要求了。而对于同样需要长连接的流服务器和服务器推送事件服务（SSE），都避免不了对长连接和高并发量的需求。尽管高性能的Ruby Web服务器都有足够的潜力完成这些任务，但是从原生设计的角度来看，更加年轻的Reel和Yahns无疑具有优势。</p>

<p>本文灵感来源于RailsConf 2015的Session：&#8221;Riding Rails for 10 Years - John Duff&#8221;。</p>

<h3>参考资源</h3>

<p><a href="http://www.fastcgi.com/devkit/doc/fcgi-spec.html">http://www.fastcgi.com/devkit/doc/fcgi-spec.html</a></p>

<p><a href="https://github.com/rails/rails/blob/master/railties/lib/rails/commands/server.rb#L82">https://github.com/rails/rails/blob/master/railties/lib/rails/commands/server.rb#L82</a></p>

<p><a href="https://github.com/shugo/mod_ruby">https://github.com/shugo/mod_ruby</a></p>

<p><a href="http://www.rubyinside.com/no-true-mod_ruby-is-damaging-rubys-viability-on-the-web-693.html">http://www.rubyinside.com/no-true-mod_ruby-is-damaging-rubys-viability-on-the-web-693.html</a></p>

<p><a href="http://confreaks.tv/videos/railsconf2015-riding-rails-for-10-years">http://confreaks.tv/videos/railsconf2015-riding-rails-for-10-years</a></p>

<p><a href="http://kovyrin.net/2006/08/28/ruby-performance-results/lang/en/">http://kovyrin.net/2006/08/28/ruby-performance-results/lang/en/</a></p>

<p><a href="http://chneukirchen.org/blog/archive/2007/02/introducing-rack.html">http://chneukirchen.org/blog/archive/2007/02/introducing-rack.html</a></p>

<p><a href="https://www.wiredtree.com/blog/litespeed-replacement-for-apache/">https://www.wiredtree.com/blog/litespeed-replacement-for-apache/</a></p>

<p><a href="https://utcc.utoronto.ca/~cks/space/blog/programming/SCGIvsFastCGI">https://utcc.utoronto.ca/~cks/space/blog/programming/SCGIvsFastCGI</a></p>

<p><a href="https://www.litespeedtech.com/support/wiki/doku.php?id=litespeed_wiki:ruby_rails">https://www.litespeedtech.com/support/wiki/doku.php?id=litespeed_wiki:ruby_rails</a></p>

<p><a href="https://www.colm.net/open-source/ragel/">https://www.colm.net/open-source/ragel/</a></p>

<p><a href="http://zedshaw.com/archive/ragel-state-charts/">http://zedshaw.com/archive/ragel-state-charts/</a></p>

<p><a href="https://en.wikipedia.org/wiki/Comparison_of_parser_generators">https://en.wikipedia.org/wiki/Comparison_of_parser_generators</a></p>

<p><a href="https://blog.twitter.com/2010/unicorn-power">https://blog.twitter.com/2010/unicorn-power</a></p>

<p><a href="http://david.heinemeierhansson.com/posts/31-myth-2-rails-is-expected-to-crash-400-timesday">http://david.heinemeierhansson.com/posts/31-myth-2-rails-is-expected-to-crash-400-timesday</a></p>

<p><a href="http://techcrunch.com/2008/01/01/zed-shaw-puts-the-smack-down-on-the-rails-community/">http://techcrunch.com/2008/01/01/zed-shaw-puts-the-smack-down-on-the-rails-community/</a></p>

<p><a href="http://code.macournoyer.com/thin/">http://code.macournoyer.com/thin/</a></p>

<p><a href="http://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf">http://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf</a></p>

<p><a href="http://www.cs.wustl.edu/~schmidt/PDF/proactor.pdf">http://www.cs.wustl.edu/~schmidt/PDF/proactor.pdf</a></p>

<p><a href="http://www.infoq.com/articles/meet-goliath">http://www.infoq.com/articles/meet-goliath</a></p>

<p><a href="http://2ndscale.com/rtomayko/2009/unicorn-is-unix">http://2ndscale.com/rtomayko/2009/unicorn-is-unix</a></p>

<p><a href="http://unicorn.bogomips.org/SIGNALS.html">http://unicorn.bogomips.org/SIGNALS.html</a></p>

<p><a href="http://nginx.org/en/docs/control.html">http://nginx.org/en/docs/control.html</a></p>

<p><a href="http://izumi.plan99.net/blog/index.php/2008/01/14/what-is-so-hard-about-rails-deployment/">http://izumi.plan99.net/blog/index.php/2008/01/14/what-is-so-hard-about-rails-deployment/</a></p>

<p><a href="https://blog.phusion.nl/">https://blog.phusion.nl/</a></p>

<p><a href="https://trends.builtwith.com/web-server">https://trends.builtwith.com/web-server</a></p>

<p><a href="https://github.com/puma/puma">https://github.com/puma/puma</a></p>

<p><a href="http://www.rubyraptor.org/how-we-made-raptor-up-to-4x-faster-than-unicorn-and-up-to-2x-faster-than-puma-torquebox/">http://www.rubyraptor.org/how-we-made-raptor-up-to-4x-faster-than-unicorn-and-up-to-2x-faster-than-puma-torquebox/</a></p>

<p><a href="http://ohcoder.com/blog/2014/11/11/raptor-part-1/">http://ohcoder.com/blog/2014/11/11/raptor-part-1/</a></p>

<p><a href="https://github.com/celluloid/reel">https://github.com/celluloid/reel</a></p>

<p><a href="http://yahns.yhbt.net/README">http://yahns.yhbt.net/README</a></p>

<p><a href="https://en.wikipedia.org/wiki/HTTP/2">https://en.wikipedia.org/wiki/HTTP/2</a></p>

<p><a href="https://github.com/igrigorik/http-2">https://github.com/igrigorik/http-2</a></p>

<p><a href="https://github.com/celluloid/reel/wiki/Frequently-Asked-Questions">https://github.com/celluloid/reel/wiki/Frequently-Asked-Questions</a></p>

<p><a href="https://en.wikipedia.org/wiki/WebSocket">https://en.wikipedia.org/wiki/WebSocket</a></p>

<p><a href="https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming">https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[microsevices陷阱: 安全]]></title>
    <link href="http://www.hanyi.name/blog/2015/06/10/microservices-security/"/>
    <updated>2015-06-10T08:02:55+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/06/10/microservices-security</id>
    <content type="html"><![CDATA[<p>自计算机普及开始，安全问题就成为困扰产业发展的阿喀琉斯之踵。如今，安全问题爆发所造成严重后果的并不鲜见，事实上每一个产品参与者都承担了安全缺陷所带来的风险和损失。因此业界必须重视安全，理解并持续加固IT设施。当采用微服务架构后，安全问题的解决将面临新一轮挑战，更高的成本投入也是显而易见。</p>

<h3>1. 认证（Authentication）和授权（Authorization）</h3>

<p>在应用级，安全的第一道锁就是认证和授权。认证的目的是确认用户提交的身份信息是否属实，例如系统登录验证，而能够唯一识别用户的信息通常被称作Principal。授权是指依据用户的Principal允许其从事某些操作的机制。一旦Principal被验证，系统就能根据相关信息（例如Hierarchy）对用户进行授权。但在微服务架构下，由于服务的相互隔离性，Principal的传递面临挑战，毕竟用户并不希望访问任何独立服务都输一遍密码——这是一个很直观的用户体验问题。</p>

<h4>单点登录（SSO）</h4>

<p>SSO是最常见的一种认证和授权方案。SAML、OpenID Connect是当前业界比较流行的SSO实现，但基本原理相差无几，本文将以SAML为例简单介绍SSO技术。</p>

<p>当Principal试图访问系统资源时，首先由身份提供者验证其密钥信息，如果验证通过，Principal将被引导至服务提供者，并且由后者决定是否向Principal授权相关资源。</p>

<p>在上述过程中，身份提供者可以是第三方系统。例如，Google提供的就是基于OpenID Connect的身份提供服务，对于其它企业应用来说，这种身份提供者有权链接至组织内部的目录服务（可以是LDAP或Active Directory，此类系统能够存放Principles），也可以由自身直接提供数据服务。基于SAML技术的有Okta，也提供链接至企业目录的服务。</p>

<p>SAML本身基于SOAP标准，其背后的工程复杂度并不低；而OpenID Connect实际上是一种OAuth 2.0的特定实现，来源于采用SSO的Google和其它一些公司，后者使用简单REST调用。OpenID Connect的缺点是本身缺少支持它的身份提供服务，因此更广泛的用于互联网第三方登录机制，特别是在如今越来越多的公众互联网服务应用中。然而如果要采用组织内的身份提供服务，目前较好的方案是OpenAM和Gluu，但并不完善。这也成为OpenID Connect在统治SSO领域之路上的绊脚石，尽管它看起来确实是最终的选择。</p>

<h4>单点登录网关</h4>

<p>在微服务架构中，每个独立的服务都有权决定对应的身份提供者，显然这将造成大量的资源浪费。如果考虑采用共享代码库，还要规避异构技术栈的问题。因此这里给出一个基于SSO网关的有效解决方案。</p>

<p>该方法的核心是只在一处处理全部用户重定向请求和握手信息，并且要求下游服务都接收一个Principle，如果基于HTTP构建微服务通信，那么很自然地就可以利用HEADER解决信息承载的问题，Shibboleth就是其中一个实践方案。此外，如果认证服务被置于网关，就更难对隔离状态下的微服务进行调试，同时也不利于日常开发。</p>

<p>上述方法最大的问题是它可能给人一种绝对安全的错觉——导致越来越多的功能依赖网关进行传递。这么做的结果就是网关服务变得越来越臃肿，成为系统中一个巨大的耦合点，同时也提高了单点失败的风险，特别是它也是反安全模式的——功能扩充意味着增加攻击面，就更容易遭受攻击。</p>

<h4>细粒度授权</h4>

<p>网关能够提供一个有效但较粗粒度的授权。但是由于它只有Principle而无法做到深度解析，就缺少更细的授权功能，而后者更多需要微服务自身去负责。而对于用户Role这种Principle信息来说，围绕组织功能实现粗粒度授权——然后进一步在微服务中实现细粒度授权。</p>

<h3>2. 服务间认证和授权</h3>

<p>Principle通常用来指代人机交互过程中的认证和授权对象。随着微服务架构日益复杂，服务间也必然会出现类似的交互过程。下面列举了若干种当前常用的解决方案：</p>

<h4>边界内畅通</h4>

<p>最简单的可能是，当服务请求来自组织内部——那么自然被当作是可信的。或者更远一些，建立HTTPS通信以防止中间人攻击。缺点是一旦内网被攻破，那么内部系统几乎没有任何防御，这就是安全领域的单点失败，然而事实上这也是目前多数组织的选择。</p>

<h4>HTTP(S)基础认证</h4>

<p>HTTP(S)协议具有基本的认证机制，其在Header中携带一个用户名和密码，并由服务端进行认证，实现起来也十分方便。缺点是采用HTTP传输用户名和密码十分危险，你几乎始终需要HTTPS——但需要额外的证书管理成本。此外，基于SSL的通信无法被类似Varnish、Squid等反向代理缓存，也就是说，在这种情况下，缓存策略只能在应用服务端、或是客户端实施。一种解决方法是在外层搭建一个LBS用于解析SSL通信，并在LBS后端存储缓存。</p>

<p>另一方面，如果现有架构已经采用SSO，那么如何结合SSO也是一个难题。如果允许基本服务访问与SSO一致的目录服务，也可以另外搭建一份目录服务——这种重复功能的存在会导致更多的潜在风险。还需注意：如果采用身份认证方案，那就意味着拥有Principle就能够访问资源，而无论它身在何处。</p>

<h4>采用SAML和OpenID Connect</h4>

<p>直接应用SSO架构能够减轻一些开发成本，如果基于SSO网关，那就意味着所有的通信将路由至网关，否则就又相当于重复功能。此外，客户端服务需要妥善保存自身的证书，以便用于各类服务间通信的认证——这就需要第三方存储服务。此外，无论是SAML和OpenID Connect，其组织内应用的支持都还远未成熟。</p>

<h4>客户端证书</h4>

<p>另一种认证方法是采用TLS（相当于SSL的继任）的特性，由于TLS要求每个客户端都具备X.509证书，那么基于证书认证的通信可以保证安全性。问题是需要一个完整的证书管理机制，因为这不仅仅意味着创建和管理证书，同时还要验证证书正确工作。采用通用证书也许是一种方法，但会引起一定的安全风险。因此当通信安全要求较高时，才应考虑该方案。</p>

<h4>基于HTTP的HMAC</h4>

<p>HMAC指一种基于哈希值的消息码技术，它克服了HTTP基础认证的安全缺陷，同时能够在HTTP上实现类似HTTPS通信。该技术最初由Amazon的AWS S3 API实现，并且属于OAuth规范的一部分。HMAC通过计算消息体和私钥的哈希值，将结果封装进消息体本身。服务端同样保存了一份私钥，然后重算并比较消息体携带的值，如果二者结果一致，则被认为是合法的请求。HMAC能够有效防止中间人攻击，同时由于私钥本身不会被明文传输，因此能保证一定的安全性。同时比起HTTPS还拥有更好的计算性能。</p>

<p>HMAC的主要缺点在于，首先服务间需要共享相同的私钥，这种私钥可以是硬编码的（缺少灵活性），也可以通过第三方获取（需要额外设计私钥交换机制）。其次，当前HMAC并没有一种统一的实现，需要开发者自己决定实现细节，比如采用SHA-256。JSON Web Tokens（JWT）也是一种可行的方案，但依然缺少标准实现。最后，需要知道HMAC只能保证通信不被第三方篡改，由于消息体本身使用HTTP传输，依然会被网络程序嗅探。</p>

<h4>API密钥</h4>

<p>目前绝大多数的互联网服务都采用API密钥解决认证和授权问题。然而如果要直接用于微服务架构，还存在一些困难。首先，一些系统使用共享的API密钥，同时基于类似HMAC的方法进行通信，而也有部分系统采用公钥＋私钥的形式。此外，密钥管理一般也是集中式的，类似前文提到的网关方案。</p>

<p>API密钥真正风靡的原因是其易用性，与SAML相比，基于API密钥的认证与授权几乎就是零成本。而且API密钥还能够用于频率控制、转化率分析、API目录、以及服务发现系统，具有相当的灵活性。一些API系统还允许将API密钥链接至现有目录服务，这样就能真正实现同步管理Principle和密钥，达到高可配置化。一种随之而来的复杂结构是：用户认证统一采用SAML实施SSO，然后取得API密钥用于服务间通信，二者共用一套目录服务。</p>

<h4>代理问题</h4>

<p>随着服务数量和调用层级增加，代理问题可能影响系统安全。如果采用传统单一系统的形式，服务调用和用户界面直接通信，因此SSO就能直接解决所有问题。但对于微服务而言，调用层级使得SSO不再有效。例如，当用户访问A服务，并且需要通过A服务调用B服务的借口时，对B来说现有SSO方案就无能为力，此时为了确保用户合法性，就只能在发生调用时携带原始Principle，并在B端进行重新认证。随着微服务架构的普及，此类应用场景会越来越多，代码和功能的重复性会显著提升。</p>

<p>一般而言，解决上述问题存在三种基本方法：1.忽略安全性，即隐式可信，一些安全性要求低的应用就无所谓了。2.前面提到的传递Principle。3.服务B向A请求Principle。但无论是哪一种，目前都缺少一个成熟的解决方案。</p>

<h3>3.静态数据安全</h3>

<p>静态数据Data at Rest，与使用中数据Data in Use，以及动态数据Data in Motion，分别描述了计算领域中的三种数据形态。使用中数据，一般指存在于内存、寄存器或逻辑计算单元中的数据。动态数据，主要指网络中传输的数据。而静态数据，主要指存放在物理介质中的数据。通常所说的安全一般都是针对使用中的动态数据，例如网络安全、系统安全和应用安全。然而如果上述安全措施不再有效，静态数据被窃取就会显得易如反掌——从而为业界引入了深度安全的概念。</p>

<p>无论如何，数据窃取事件的发生不外乎未加密存储、或是保护系统失效，在任何安全方案中，此类隐患是必须得到重视的。</p>

<h4>尽量采用稳固的加密算法</h4>

<p>如果要自己实现加密算法，安全性就很难保证。即使采用第三方加密算法，也需要时刻保证该算法是否会随时被发现漏洞并攻破。AES-128和AES-256是一种有效的静态数据加密算法，许多语言都内置了算法实现，Java和C#也可以采用Bouncy Castle Libraries。密码也应至少实现带盐哈希加密。</p>

<h4>密钥存储</h4>

<p>许多加密算法都引入了密钥环节，因此对密钥本身的保护也不容忽视，否则再强大的加密算法也是十分脆弱的。采用第三方系统管理密钥是必须的，或者直接采用类似SQL Server的透明数据加密。无论采用何种方案，都需要仔细分析相关的安全风险。</p>

<h4>可选和必选</h4>

<p>应有选择的加密静态数据——这不仅关系到应用性能问题。一方面，前文介绍的日志和监控需要明文数据，此外，数据移植也会因为引入解密、加密过程而变得繁琐和低效。因此，对数据进行安全性分级是必要的。此外，对高安全要求的数据，当数据获取后即加密，只在请求数据时解密——除此之外不要在任何形式下存储该数据。对于备份数据，应实现整体加密并妥善保存和管理。</p>

<h3>4.深度防御</h3>

<p>安全如今已经不仅仅是一个单一的概念，要实现高可靠的安全，必须采用综合、深度防御，摒弃单点失败带来的潜在风险。当防御因素增加，攻击者成本也就越高，系统安全性才能得到保证。</p>

<h4>防火墙</h4>

<p>防火墙依然在进化，相比过去的端口限制和包识别，像ModSecurity已经实现了限制IP段连接次数、主动监测某些恶意攻击等功能。同时，采用多层防火墙也是必要的，例如系统级可以采用Iptables，而在应用级，服务内部也可以设置防火墙进行自身防御。</p>

<h4>日志</h4>

<p>日志是把双刃剑，一方面，良好的日志结构能方便发现各种风险，包括安全问题。但是日志中的敏感数据本身也会造成风险，适当遮蔽这部分数据是有必要的。</p>

<h4>入侵检测和防御系统（IDS/IPS）</h4>

<p>与防火墙不同的是，入侵检测主要监控系统内部行为，并发出警告或选择阻止危险行为。但是IDS（IPS）在实施上需要投入长期的人力成本，现有的IDS基本都是基于启发式防御，其基本形式就是通过设置一些规则，当某些系统行为与该规则相匹配，则认为该行为有风险。但在实施过程中，特别是系统初期建设时，入侵规则的建立是和系统和架构特点息息相关的。因此通常应从一个被动式IDS/IPS开始，逐步完善入侵规则，再逐渐过渡到主动防御——才是有效且可靠的。</p>

<h4>网络隔离</h4>

<p>在单一系统中，由于应用设施都部署在同一环境，从而导致安全性的单点失败风险。而对于微服务架构，由于服务隔离性，本身就可以通过现有的网络管理机制增加安全性。例如AWS就提供一种自定义虚拟私有云VPC的服务，该服务允许主机处于相互隔离的子网中，从而通过定义网络规则指定服务间的可见性，或者指定网络通信的路由方式。</p>

<h4>操作系统</h4>

<p>操作系统级别的安全策略，主要集中在运行服务的用户最小权限、以及基础软件的漏洞修复速度。目前大型软件的更新都支持自动化，同时提供警告机制，例如微软的SCCM和RedHat的Spacewalk。</p>

<p>另一方面，操作系统的第三方安全模块也值得考虑。例如RedHat采用的SELinux，Ubuntu和SuSE支持的AppArmour，还有GrSSecurity，上述模块允许用户定义系统安全行为，并且直接监视内核行为，及时制止相关操作。</p>

<h3>5.小结</h3>

<p>在德语中有一个短语Datensparsamkeit，意思是当你需要存储数据时，应尽量保证只保存有效且合法的最小数据集，该定义来源于德国的隐私保护法案。实际上，当你不携带“有价值”的数据，那么自然就不会引起攻击者觊觎了。许多系统发生隐私泄漏事件，其本身就无权存储相关信息，这才是风险的源头。</p>

<p>另外，组织内部人员也是一大风险因素，如何处理权限的创建和删除、避免社会工程攻击、或者其他内部人员的恶意攻击，都是组织管理需要考虑的问题。</p>

<p>安全领域的另一大忌就是避免重复造轮子，因为很难得到充分的审议和验证，此类代码将成为极高的风险源。</p>

<p>最后，随着OWASP等的流行和安全测试框架的日益完善，可以考虑把安全测试引入到现有CI/CD流程，例如Zed Attack Proxy（ZAP），Ruby支持的Brakeman，Nesssus等等。微软提出的安全开发生命周期，也是一个有效的开发团队安全实施模型。然后就是定期邀请组织内外的安全专家逐轮审议、修订安全架构，以确保安全设施的持续更新。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[microsevices陷阱: 监控]]></title>
    <link href="http://www.hanyi.name/blog/2015/06/04/microsevices-trap-monitoring/"/>
    <updated>2015-06-04T13:57:50+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/06/04/microsevices-trap-monitoring</id>
    <content type="html"><![CDATA[<p>微服务带来的是更高的架构复杂度，即使你有能力驾驭整体设计，也很难处理生产环境中的各种failures。监控在运维中是一项专门的技术，而对微服务而言则更具有必要性。原因在于，对于单一系统、或者是单点失败型系统而言，任何的错误信息都是有的可循的，然而对于微服务类似的自治系统来说，除非拥有良好的日志和监控系统，否则连发现问题都成问题。一个好的解决办法就是分布式日志数据抽取和聚合查询。</p>

<h3>1. 系统架构对监控模式的影响</h3>

<p>由于系统架构的不同，即使利用前述的思想，实施监控模式也有一定区别。</p>

<h4>单服务，单节点</h4>

<p>一切都变得如此简单，CPU、内存&hellip;日志和查询系统、平均响应时间、负载增长&hellip;甚至当你知道Nagios或New Relic，搭建此类系统就几乎等于零成本。当然，这并不意味着你就此精通监控技术&hellip;&hellip;</p>

<h4>单服务，多节点</h4>

<p>由于各个节点的权重由LBS决定，因此监控时采用的系数可能会有差别。不过，通过把多个节点的运维数据聚合在一起，实现一次查询也是理想的方案。直观的，可以利用ssh-multiplexers类的工具同时在多节点上获取数据，并存储在第三方节点上向运维提供分析平台。</p>

<h4>多服务，多节点</h4>

<p>在遇到真正的微服务大杀器时，运维会遇到很多从未谋面的问题。例如在复杂架构下，如何判断某个服务的错误和功能错误有关（可调试性），如何在海量运维数据中找到具体的错误（可检索性），这些都成为眼前难题。而解决方案还是采集＋聚合，无论数据属于日志或系统应用度量。</p>

<h3>2. 日志系统架构</h3>

<p>现在，开源界流行专门的日志采集工具logstash，和聚合查询系统Kibana，实际上就体现了一种良好的日志监控系统架构。logstash负责分布式日志数据采集和过滤，并将其存储至任何介质。Kibana是一个基于ElasticSearch的聚合查询工具，能够方便管理其中的日志数据，并提供可视化。但是，针对不同类型的日志数据也要采取不同的采集和管理方案。</p>

<h4>跨多服务跟踪系统应用度量数据</h4>

<p>系统应用度量，包括CPU、内存、网络请求/响应等基础数据，在复杂架构中，运维可能需要全局性数据，也可能需要针对单个服务的全部节点数据，也就是说，在元数据中必须加入相关的关联性，以保证日志数据的可用性。当数据准备就绪，Graphite这种实时可视化工具就能派上用场了。</p>

<h4>服务度量</h4>

<p>系统度量采集了除应用服务之外的几乎全部运维数据，而对应用本身来说，利用其自身的日志工具在多数情况下就足够了。但是，我们可能有时会遇到如下若干需求：希望查看所有用户检查其购物车的次数、希望查看用户操作的平均间隔时间&hellip;对于此类统计需求，一方面可以作为功能进行开发，但由于引入发布流程，本身缺乏灵活性，在多数场合下并不适用。另一方面，可以直接从日志数据中攥取所需信息。很显然，后者带来的好处更多，实现现有数据的更高效利用（但具体技术还在发展中，例如大数据技术），甚至可能挖掘出新的商业信息。因此，在任何关于日志数据挖掘的理论普及之前，好的实践应是尽量多的保存日志信息，因为其中可能蕴藏着未被发现的金矿。</p>

<h3>3. 监控系统</h3>

<h4>综合监控和语义化</h4>

<p>对日志系统的监控，通常要求实现一个对人的警告功能。但是在具体实践中，可能只是对CPU、内存甚至磁盘利用率设置一个阈值，一旦运维数据达到这个值就向运维人员发送警告。问题在于，现实中我们想在第一时间得到的信息其实是“系统在正常工作吗？”，而单个维度的超限可能无法等同于上述答案。</p>

<p>因此为了保证运维人员不至于整晚都睡不好觉，监控模型的改进还是很有必要的。除了针对底层运维数据的监控，从业务角度入手实现综合监控是未来发展的趋势，特别是在微服务架构下。例如，有时需要监控微服务间可用性，除了观察各服务的基础运维数据，还可以从业务角度入手，检查数据流的变化情况，以及健康度。这种更高层的监控，也被称作语义化监控，在实际中对运维人员实现了更高要求：理解业务和设计。</p>

<h4>关联IDs</h4>

<p>分布式系统的跟踪调试是一个世界性难题，实际中也很少有人能够遇到、甚至尝试解决此类问题。一般而言，微服务架构的日志系统至少应包含一个跟踪功能，否则一旦出现监控警告，我们能看到的只有直接服务代码，其上游成百上千的服务调用却一无所知——当然这种规模的系统没有几家公司拥有。Google在2010年发表了Dapper——其大规模分布式系统跟踪基础架构，Twitter随后在前者的研究基础上实现了zipkin——开源分布式系统跟踪框架。上述解决方案无一不具有“重”的特点，但基本原理类似：在服务间传递消息时，在消息头封装一个特殊的GUID，并将其写入日志或第三方系统。</p>

<p>目前来看，关联IDs是微服务架构必须要尽早考虑的问题，否则一旦出现问题就很难有充分的信息进行定位。而采用重量级框架带来的成本可能较高，理想方案是尽量简单实现类似功能，并集成进现有日志系统，如果需求复杂度进一步提升，就可以考虑引入大杀器灭之。</p>

<h4>层级关联</h4>

<p>本节开始提到了语义话监控的概念，它对于“系统正确运行”含义的代表可能要强于底层运维数据警告。但如果从定位问题的角度出发，即使发现问题存在，也不意味着立即定位问题，更谈不上提高可用性了。例如，两个独立服务分别运行良好，但服务间通信出现问题，导致数据无法正确传输，但现有功能依然存在，严重的话可能引起数据级别的错误，因此这种服务间集成点的监控成为必须要考虑解决的问题。</p>

<p>实践中针对服务层级的监控多引入一种名为断路器的工具，其用途是一旦发现通信中断，就立即断开当前服务与下游的通信，从而避免错误的持续传递造成灾难。Netflix的Hystrix是这一领域中基于JVM的开源框架。</p>

<h4>标准化和可读性</h4>

<p>日志/监控系统的重要内容就是标准化，当你采用微服务架构，标准化就更加重要——这恐怕是你唯一能够从整体上把握系统的切入点。另一方面，监控最终还是向人提供决策参考——因为角色的不同，不同的人对监控数据的理解也存在偏差，因此在设计监控系统时还需要考虑的重要问题：</p>

<ol>
<li><p>人们当前需要什么数据。</p></li>
<li><p>人们随后需要什么数据。</p></li>
<li><p>人们习惯于如何消费这些数据。</p></li>
</ol>


<p>至少你应该尝试读一下《Information Dashboard Design: Displaying Data for At-a-Glance Monitoring》，相信会把对监控的理解上升到人文的高度。</p>

<h4>4. 总结与未来</h4>

<p>监控领域非常得大，有时甚至超过产品本身——这会不会是一次大规模的历史性误区，目前还很难说。但现状是几乎所有的技术研发公司都在该领域发力，希望从此走上数据金矿的道路。传统上，我们利用自身简易工具监控系统应用，利用GA、Omniture抓取业务数据，利用日志系统定位问题。碎片化的工具方便实现精细化分工，但很大程度上阻碍了数据的进一步攥取，成为大数据之路上的绊脚石。</p>

<p>监控工具的融合进程目前依然缓慢，Riemann是现有的比较流行的分布式系统监控框架，其本质上是一个事件服务器，通过接收分布式系统的各类事件采集、聚合相关数据，但仍主要集中在系统应用监控方面。Suro是由Netflix开源的一套分布式数据管线框架，数据处理方式类似Riemann，但更集中于数据管线的功能，其下游应用包括Storm实时数据分析框架、Hadoop离线批处理框架以及Kibana日志分析平台。</p>

<p>当然，这种融合趋势并不会影响专注于不同领域的工具的发展，但统一数据接口是眼下应当开始的工作。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[microservices陷阱: 测试]]></title>
    <link href="http://www.hanyi.name/blog/2015/06/01/microservice-testing/"/>
    <updated>2015-06-01T08:53:39+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/06/01/microservice-testing</id>
    <content type="html"><![CDATA[<p>层级良好的测试是保证持续集成/交付的前提。对微服务而言，随着系统复杂性的提高，原有测试层级会遭遇挑战，本文将在澄清现有基本概念的基础上讨论这一问题。</p>

<h3>1.测试自动化</h3>

<p>《Agile Testing》的测试四方图帮我们理清了测试开发的基本类型：验收测试、探索测试、单元测试和性能测试。当然这既包括手动、也包含自动化测试，这里本文只关注后者，但二者的地位应是同等重要的。</p>

<p>Mike Cohn在《Succeeding with Agile》中介绍了自动化测试的金字塔图，书中的金字塔把自动化测试划分为三种类型，从底向上分别是单元测试、服务测试和UI测试。其中，服务测试在大多数情况下指集成测试，而UI测试目前更多被称作End-to-End测试。关于这三种测试的概念这里就不再强调，但实践中更多会面临各自权重的问题。</p>

<h4>测试权重</h4>

<p>测试金字塔给出了以下结论：当层级越高，测试的范围越大，质量保证的可靠性也越高，但是反馈时间也越久，调试难度越大；层级越低则这种趋势会完全相反。因此，合理安排测试量是一个非常重要的问题。但应强调一点，上述测试并非是一次促成，固定不变的。例如服务/UI测试一旦出现问题，最便捷的解决方法是引入更多单元测试去覆盖上述边界条件。</p>

<p>但是无论如何也不要陷入误区：即使你有更多时间去完善UI测试，也不要忽视金字塔量级的规律。一种常见的反模式是测试量呈倒金字塔状，过度依赖UI测试，而忽略了单元测试。因为这么做忽略了反馈周期的因素，随着UI测试反馈周期的不断增加，必然降低整个团队的效率，也不利于代码质量的保证。</p>

<h4>实现服务测试</h4>

<p>微服务架构下的服务测试显得尤为重要，但实际上也面临集成的问题，特别是CI架构方面。例如采用CI实时启动一个构建好的消费者服务，或是直接在测试代码中stub——但需要花费额外代价去模拟stub的功能。提到stub，可能会引出mock的问题，后者关注行为，实际上是面向边际效应的一种测试手法，《Growing Object-Oriented Software, Guided by Tests》详细比较了上述二者。当然Martin Fowler的<a href="http://www.martinfowler.com/bliki/TestDouble.html">TestDouble</a>也是一个直观的介绍。</p>

<p>现今的服务测试工具已多如牛毛，其基本原理还是stub一个消费者服务，运行测试前启动该服务即可。其趋势已是跨平台、跨语言了（参考Mountebank）。</p>

<h4>微服务和UI测试</h4>

<p>UI测试本身具有一定复杂度，更别说和微服务架构集成了。如果采用单一系统的做法，需要在CI上分别部署全部服务，然后触发UI测试——这不仅仅是花钱的问题，更意味着时间成本的增加。</p>

<p>UI测试中普遍存在某些代码片段，是时断时续的，这就导致开发人员可能会不断重复运行测试，因为这可能是一个随机产生的现象。对于这种不确定性的Flaky测试，应当尽量移除出代码库。Martin Fowler在<a href="http://martinfowler.com/articles/nonDeterminism.html">Eradicating Non-Determinism in Tests</a>中详细讨论了UI测试中存在的这类问题，并给出了一些解决方案。</p>

<p>另一个问题是UI测试的ownership分配。一般情况下，单一系统可能是全部团队成员维护一个UI测试代码库。但是这会引发测试健康值下降的问题，有时会派QA监控这一问题。而对微服务而言，UI测试可能是跨团队的，因此必须限制测试代码的提交权限，以及明确ownership。最多应覆盖相关的服务开发团队。</p>

<p>当然，微服务带来的UI测试爆炸也是一个比较严重的问题。尽管已经有一些并发框架例如Selenium Grid减少时间的浪费，但这些并不能实际解决测试爆炸的问题。终极方法可能还是精简当前测试部署，当然这涉及到UI测试的代码架构。</p>

<h4>发布堆积</h4>

<p>由于微服务的相互隔离性，一旦UI测试失败，在某个源头微服务修复前，其它微服务将无法被正确部署，从而导致发布包产生堆积现象。一种解决方法是一旦UI测试失败，停止所有的代码提交——当然这并不容易，特别是当变更较大时，修复的成本较高，可能导致全部团队效率的下降。因此保证小变更的频繁提交是一个有效减小风险的实践。</p>

<p>到这里你可能会对微服务产生质疑，既然End-to-End测试通过后才能发布，岂不意味着某一批版本的微服务将被同步发布？那么，这种部署方式还遵循微服务的独立部署原则吗？实际上，尽管可能把End-to-End测试作为一个限值，但微服务的独立性并没有遭到破坏，如果采用同一个发布版本，无意间就意味着微服务间的耦合性在增加，反而失去微服务本身的优势。因此保持平衡十分重要。</p>

<h3>2.测试代码架构</h3>

<p>当测试代码开始融入codebase，就要考虑设计的问题了——因为你不得不去考虑功能代码中遇到的同样问题。但由于根本目的不同，测试代码的设计存在不一样的可能。</p>

<h4>用户轨迹，而非用例</h4>

<p>对于UI测试，按照敏捷的一般实践，可能很自然地实现针对每一个story的测试。面向用例的UI测试带来的是大量重复性测试，这显然不利于控制UI测试的成本。另外，从探索测试的角度来说，遵循普通用户轨迹的UI测试可能才是接近真实情况的。因此，UI测试的组织应尽量面向用户轨迹，特别是核心功能的用户轨迹。</p>

<h4>消费者驱动测试和Pact</h4>

<p>前文已经提到，基于stub/mock的服务集成测试已经比较常见，但是，尚没有一个能够保证集成测试尽快响应代码变更的机制。例如，当某个服务发生变更时，就需要考虑修改其它服务实现的它的stub，否则就会降低测试结果的可靠性。一种方法被称作<a href="http://martinfowler.com/articles/consumerDrivenContracts.html">消费者驱动的契约测试</a>，其基本出发点是开发能满足消费者需求的服务，同时尽可能保证实时同步相互之间的变更。其基本过程就是由消费者一方提出需求，并构建契约文本，再与服务提供方达成一致，实现相关功能。</p>

<p>Pact是一个开源的基于消费者驱动的测试工具，分别基于Ruby、Java和.Net。而Pact生成的契约文本通常是JSON格式，这就形成了跨功能的契约传递。Pact生成的契约可以通过任何形式存储，例如CI/CD的交付物、或Pact Broker版本管理工具，后者允许服务提供者能够同时对多个版本的消费者服务运行集成测试。另一个工具Pacto，实际上记录了服务间的交互过程，并形成消费者驱动的测试，比起Pact它更为静态化，而Pact则被嵌入到测试内容中，随着功能变更实时变化。</p>

<h4>集成测试和UI测试</h4>

<p>那么问题来了，前文提到UI测试是一项非常耗成本的工作，针对微服务尤为如此。随着集成测试的有效引入，是否就意味着降低甚至移除UI测试？答案是未必。</p>

<p>UI测试能够让许多问题在发布前最后一刻暴露出来，从而避免灾难的发生。因此，在发布时间不是非常紧急的情况下，运行UI测试反而能够降低人工成本。如果发布在即，可能来不及运行UI测试，那么撰写UI测试可能就显得没有特别必要了？现在针对微服务架构已经有一种做法，直接在生产环境中运行UI测试，而整个测试过程需要通过语义化监控技术记录全程（关于监控和语义化监控，我们会在下一篇文章中介绍）。</p>

<h3>3.发布后测试</h3>

<p>如果测试只在发布前进行，当出现线上bug，测试可能就显得无能为力，只能待开发人员修复功能后，预上线环境重测。问题的本质在于，测试很难完整模拟用户行为，特别是你永远都不完全了解用户是怎样使用系统的。为了尽早发现bug，在发布后测试是一个有效方法。</p>

<h4>一次发布，分别部署</h4>

<p>我们已经知道，微服务建议独立部署各自的服务，那么在发布前针对单一服务的测试可能显得无力。如果先部署服务，再运行针对该服务的测试，就能快速发现很多问题。这种测试方式的一个典型案例就是“冒烟测试”，即快速运行针对新部署服务的测试。</p>

<p>一个稍复杂的例子是蓝/绿部署。这种形式下，系统存在两份相同的拷贝，但只有其中一个真正接收外部请求。例如现有正常服务A，当更新A+发布时，先将A+部署到另一个环境，运行冒烟测试，通过后再把生产环境的流量导入到A+。该做法还能保证即使出现更多失误，也能快速回滚代码。然而，蓝/绿部署需要额外的成本，首先你需要大量环境容纳各种版本，并且能快速切换流量（基于DNS或LBS），当你采用弹性云服务实现这些就很方便。</p>

<h4>金丝雀发布</h4>

<p>相比蓝/绿部署，金丝雀发布则更为强大（要求也更高）。在这种发布形式下，新服务部署后，会由导流工具引入一部分生产环境中的流量，然后通过比较两个共存版本间的各种监控数据来保证功能的正确性，一旦新服务的出错率明显上升，则切断该部分的路由，反之则切断原有服务的路由。金丝雀发布的生产效率更高，但技术要求也更多，特别是针对幂等规则下的请求/响应通信，如何实现无缝导流会是一个难题。</p>

<h4>MTTR和MTBF</h4>

<p>MTTR指平均修复时间，MTBF指平均错误间隔时间，这两种概念实际上体现了不同的运维策略。无论是蓝/绿部署还是金丝雀发布，其出发点都是承认线上错误是不可避免的，因此MTTR是此类策略更关注的内容。而要保证MTBF，必须在上线前实现充分测试，其花费的成本也是十分可观。因此在实际中，MTTR和MTBF只能在权衡下保证，除非你有不计成本的投入（如重大的、允许失误率极低的项目）。而按照实际经验判断，MTTR可能是面向普通业务更为现实的选择。</p>

<h3>4.跨功能测试</h3>

<p>如今我们逐渐开始关注非功能测试，例如性能测试。但从词义上理解，把非功能测试看作是“非功能的”可能并不准确，因此这里采用“跨功能测试”一词。
跨功能测试在测试四方图中占有一席之地，因为其实际上十分重要，但在大多数项目中此类测试通常都启动得太晚，以至于出现了额外的超额工作。要知道，跨功能测试从重要性、架构复杂度和维护需求上几乎和所谓的功能测试并无差别，只是更容易在初期为人所忽视而已。</p>

<p>例如性能测试，在End-to-End测试阶段，这种测试更类似负载测试，而在单元测试阶段，则属于Benchmark测试。因此结合功能测试实现性能测试是一个有效途径。但应注意性能测试对环境的真实程度要求更高，可能会产生更多额外成本。但至少在当下，应尽量开始Benchmark及相关的尝试。</p>

<h3>5.小结</h3>

<p>总结上述这些与测试的有关经验，我们可以列出以下几点主要内容：</p>

<ol>
<li><p>通过细分测试，优化快速反馈流程，减少项目风险。</p></li>
<li><p>通过消费者驱动的测试避免微服务架构下的UI测试。</p></li>
<li><p>采用消费者驱动契约建立微服务团队间的沟通渠道。</p></li>
<li><p>理解MTTR和MTBF的区别，以及实际运维中的权衡。</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[microservices陷阱: 部署微服务]]></title>
    <link href="http://www.hanyi.name/blog/2015/05/19/microservices-trap-deployment/"/>
    <updated>2015-05-19T09:44:53+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/05/19/microservices-trap-deployment</id>
    <content type="html"><![CDATA[<p>对于单一系统而言，无论采用何种形式，基本的部署工作流是显而易见的。然而一旦采用微服务架构，服务间的相互依赖性会导致现有工作流发生混乱，这肯定是我们都不愿意看到的。本文谨对此展开讨论。</p>

<h3>1.持续集成（CI）和持续交付（CD）</h3>

<p>CI的核心目标是保证团队成员进行良好的同步协作。其工作方式通常是检查代码更新状态、获取最新代码并且编译和运行测试。CI的产出物通常是可用于直接进行部署或进一步测试的软件包，理想的情况是所有环境的部署都采用同一个软件包，也就是对于CI只产生唯一的交付物。</p>

<p>值得一提的是，采用CI工具和实践CI方法完全是两回事，例如：保证每天都能合并到主干、保证代码更新都有足够的测试、保证CI持续运行是团队第一要务等等，以上实践能充分发挥CI工具的效用。</p>

<p>CD则把CI和更多软件开发实践结合在一起，例如流水线、自动化部署、以及运维等，从而有效降低项目风险，提高团队效率。</p>

<h3>2.CI与微服务</h3>

<p>当采用微服务架构时，如何与CI结合则成为眼前的工作。最简单的实践可能是，把所有服务存储在同一个代码库中，任何提交都会出发任何服务的构建、测试乃至生成部署包。然而该做法是十分浪费的选择，简单改进是增加构建脚本的复杂度，在代码check out后，针对每个服务，由不同的工作流负责构建相应微服务，从而节约资源。</p>

<p>当微服务扩展至不同团队后，共享代码库的方式可能会带来很多问题，这时就需要直接拆分代码库、实现工作流－微服务一一对应的结构了。</p>

<h4>架构演进对CI的影响</h4>

<p>值得一提的是，CI工作流的设计应和应用架构保持一致。也就是说，在初创项目时期很可能都会是一个单独的代码库，CI的结构也应当比较简单。随着领域模型的逐渐建立和API保持稳定，划分服务并且分别构建会是自然的选择。</p>

<h4>特定平台的交付包</h4>

<p>鉴于微服务允许采用不同的技术栈实现，Jar/War、Gem、Egg等区别导致了CI技术的丰富性，实际上也增加了CI实践的复杂度。因此，采用现代配置管理工具如Chef、Ansible则是必须的。另一方面，当把上述各种不同的技术部署上线时，对配置管理的依赖就更加重要了。</p>

<h4>操作系统交付包</h4>

<p>在实践中，自动配置管理面临着跨平台的挑战。即使是面向Linux，也存在发行版之间差异的问题。如果把配置管理的结果从线上环境变为Rpm、Deb、甚至MSI包，则就大幅度降低了操作系统差异所带来的挑战。当然，最好还是尽量在线上环境采用统一的平台为好。</p>

<h4>自定义镜像</h4>

<p>自定义镜像的好处是，我们不再直接在环境上运行配置管理工具，而是在本地构建好虚拟环境，部署好应用，然后再打成镜像包发布，从而节约了线上部署的繁冗时间，消除此举给线上环境带来的潜在问题。虽然说节约时间，但生成镜像依然是十分耗时的工作，好在现有的配置管理工具几乎都支持VMWare、AWS AMI、Rackspace、Digital Ocean、以及Vagrant打包，你需要做的只是本地运行一遍脚本，然后随时发布镜像包即可。</p>

<h4>镜像即交付包</h4>

<p>当采用镜像部署成为常态，一个合理的选择是把镜像包作为交付物融入CI/CD工作流，真正实现业务和基础设施的分离。</p>

<h4>服务器的不变性</h4>

<p>如果你发现每次运行部署之后，都需要人工检查并修改某些已有配置时，那就意味着配置管理发生了偏差。这种情况发生的原因通常是服务器配置环境发生了变化，而应对措施是尽量不要人工维护或修改环境配置。一个好的实践是在每次代码更新都创建全新的镜像。当然也会损失一些时间成本。</p>

<h3>3.CD与微服务</h3>

<p>当微服务运行在CD工作流中时，需要注意更多潜在的问题。</p>

<h4>环境</h4>

<p>在CD实践中，我们通常会遇到Slow Tests、UAT、Performance Tests分别部署在不同环境上的例子，针对单一系统管理上述环境本身就是一个挑战。而当这些遇到微服务，其规模和工作量就可想而知了。
环境问题本质上还是配置管理的方式，当不同微服务所需环境互不相同时，选择合理的部署方式则变的非常重要。例如对每个环境构建一个交付包，同时包含环境配置文件，当部署时同时部署代码和配置&hellip;一切看起来顺理成章，但似乎有些违背CD的原则，特别是唯一交付物原则。这就会导致多环境带来的风险削弱好处大幅丧失。另一方面，合并交付包带来的效率、安全等问题是不得不考虑的。
一种较好的实践是通过一个统一的交付包单独管理不同环境下的配置文件，或是采用配置管理系统——这对微服务而言显得尤为必要。</p>

<h4>服务－主机映射</h4>

<p>部署的另一个问题就是，一个物理机（或容器）上能运行多少服务？面对不同的选项，部署方案也会有所区别。</p>

<p>首先是多服务－单主机模式，好处是简单、方便、成本低。困难在于，监控复杂、服务部署流程也会遇到很多问题，例如如何保证不同服务间的部署代码不存在冲突，而这在微服务系统中并不少见。</p>

<p>其次是应用容器模式，这里的应用容器主要是指.Net或Java Servlet Container等充当应用服务器的容器，适当的统一能避免冲突，但也会带来一些限制。服务间的独立性也难以保证。</p>

<p>单服务－单主机模式，该方法类似于把应用部署在一个类PaaS系统上，当然灵活性也比商用PaaS高，彻底独立带来的好处就是微服务的优势，成本也是显而易见。</p>

<p>PaaS模式，更加简单、便捷的方式，缺点是灵活度低，特别是当需要触及底层改动时，PaaS显得无能为力，但从宏观上说确实是一个发展趋势。</p>

<h4>自动化</h4>

<p>自动化的优势贯穿本文始终，也是微服务技术发展的核心。如果不能实现自动化，微服务提供的各种实践就无法带来任何收益。因此微服务部署的方向就是：一切自动化。</p>

<h3>4.虚拟化</h3>

<p>实现可扩展的现行趋势就是虚拟化。虚拟化能够带来隔离、提高资源利用率等好处，但随着资源利用需求的提高，传统虚拟化显得力不从心。其中共有两种类型的虚拟化，一类是直接基于硬件的虚拟化，另一种是构建在操作系统上，采用层级架构实现的虚拟化，如AWS、VMWare、VSphere、Xen和KVM，这些虚拟机实例基于hypervisor之上，由后者提供资源分配和调度，并向上层应用提供支撑。可以看到，hypervisor承担着核心且重要的任务，其本身的资源需求就很可观。</p>

<h4>Vagrant</h4>

<p>Vagrant本质上只是一个部署平台，其更多用于开发和测试环境而非产品环境。Vagrant方便在本地构建一个虚拟云，能够尽可能真实的模拟在AWS上的线上虚拟环境。然而由于Vagrant实际还是基于虚拟机应用如VirtualBox或VMware，其所占用的资源是相当可观的。特别是在开发环境，开发人员在本地几乎不可能模拟一套完整的生产环境，因此合适的stub仍然十分必要。</p>

<h4>Linux容器</h4>

<p>Linux容器的目标是进一步榨取系统资源，实现原理却很简单：每个容器都基于内核进程fork，并且自身形成一个进程子树。除了LXC，像Solaris Zones、OpenVZ这些都是类似概念的实现，但没有前者更出名。LXC的好处是省去了hypervisor（但并不意味着它就不需要此类功能），相比VM更加轻量、高效。同时容器还提供了更细粒度的资源配置选项。
不过容器也并非灵丹妙药，相比VM而言只是换了一个载体，在正式项目中，你仍然会遇到hypervisor、routing，甚至security等各种挑战，且并不比解决VM来的容易。</p>

<h4>Docker</h4>

<p>本质上Docker只是一个构建在轻量容器之上的集成平台，它的好处在于一次性集成了容器provision、network、storage和version等功能，面向用户更加友好，并使得容器技术逐渐普及。
与VM相比，Docker具有容器所拥有的所有优势，同时正在产生一个完整的生态圈，例如CoreOS。Docker面临的挑战也等同于容器，特别是当你真正需要采用Docker搭建PaaS时，毕竟Docker本身几乎没有解决任何已有的技术问题。目前能够帮助用户解决重点问题的包括Google的Kubernetes、CoreOS的集群技术、甚至Deis这种直接提供基于Docker的PaaS平台，就像Heroku一样。</p>

<p>Docker可能解决长期困扰PaaS方案的一系列问题，例如缺少自定义特性（类似Heroku这种已经算做得不错），当PaaS的provision完全向用户放开，且不失易用性，其可选度才真正高于IaaS，Docker目前是这一趋势的有力支撑。</p>

<h3>5.采用一致的部署界面</h3>

<p>微服务部署与普通部署并无二致，同样需要解决横向扩展、相互依赖等问题，而采用一致的部署界面能有效提高效率，无论是基于Windows Powershell、batch、bash、Python Fabric或Ruby Capistrano等各类平台。一般来说部署界面应包含以下内容：</p>

<h4>1.实体名称</h4>

<p>部署对象的名称，例如微服务名。</p>

<h4>2.实体版本</h4>

<h4>3.部署环境</h4>

<p>例如：“deploy artifact=catalog environment=local version=local”。</p>

<p>部署界面的另一个重要部分是环境管理，环境管理的具体内容主要是一些provision的配置信息，部署工具应不限于provision工具的选择，包括puppet、chef或是ansible。</p>

<p>当前，在Deployment和Provision之间依然存在着缝隙，且其中的界限还不明确。例如对于Provision Heroku、或者AWS，或者Provision和Deployment间的相互依赖问题的解决，还缺少一个有效且一致的方案。Terraform看起来是一个潜在的选择。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[microservices陷阱: 切割单一系统]]></title>
    <link href="http://www.hanyi.name/blog/2015/04/13/microservices-trap-splitting/"/>
    <updated>2015-04-13T08:44:04+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/04/13/microservices-trap-splitting</id>
    <content type="html"><![CDATA[<p>前面已经提到，构建microservices的第一步即划分服务边界，而对新系统直接进行边界划分具有相当的风险，且通常是不被鼓励的。我们建议选择一个较成熟的codebase再进行服务切割。</p>

<h3>1.辨识服务边界</h3>

<p>面对已有系统，首先需要做的就是辨识其中隐藏的服务边界。在《Working Effectively with Legacy Code》中，提到架构“缝隙”的概念。我们几乎可以把“缝隙”和“边界”等同起来，实际上DDD中的服务边界即一种好的“缝隙”。那么如何找到“缝隙”则是面对遗留代码所需的第一站。
许多编程语言提供一种自然的封装方式，比如namespace，java的package也拥有类似的概念，当然并非所有语言如此（如javascript）。
在进入代码之前，首先应该至少理解高级别的边界上下文抽象O，这将有利于我们进行逐渐向下的切割。当拥有O后（当然O可能并不完美，但这不是必须的），我们可以逐步把代码移动至相应的O&#8217;中。在这一过程中通常就能发现其中存在的问题，比如更细粒度级别的边界、错误的依赖、以及其它，借助代码分析工具可能会提高一部分工作效率。
当然，面对小型系统，你可以指望在数天、甚至一天内完成全部分析工作，但是多数情况下这可能是数周、或数月的付出。因此还应注意任务分解、确定优先级、循序渐进地切割新服务。</p>

<h4>切割单一系统的好处</h4>

<p>尽管前文已经无数次提到，但这里还是简单做一下总结：相互独立的自治单元更易实现变更、根据所属服务划分团队职责、针对特定服务的安全性增强、技术更新更加频繁&hellip;所有以上会是单一系统经过合理切割之后带来的好处，然而如果你不确定这些是否真的对你有“帮助”，还是谨慎一些比较好。</p>

<h3>2.解决依赖缠绕</h3>

<p>当切割服务边界时，如何处理新旧系统之间的依赖缠绕则成为随之而来的问题。前文提到过建模工具，它能更容易地让你发现设计是否基于有向无环图从而避免了明显的缠绕关系。当然，实践表明几乎所有的缠绕都和数据库模式相关。事实上到目前为止，切割服务就像是纸上谈兵，数据库才是大boss。
基于之前的实践，首先尝试依照服务把repository层进行垂直切割，也就是分表。SchemaSpy等类似的工具能够根据代码生成类UML的可视化分析结果，从而提高理解程度。</p>

<h4>解除外键关系</h4>

<p>如果确实存在外键依赖，唯一能做的就是自己维护一个与外键类似的字段，然后按需要手动解决一致性问题（这通常与业务有关，也就是说，有时需求根本不要求强一致性）。</p>

<h4>静态共享数据</h4>

<p>例如国家代码、区划等数据，一般来说有三种解决途径：在多个服务间实现冗余拷贝；通过静态配置文件消除代码和数据；或者直接建立独立服务，并在代码中内嵌静态数据。多数情况下，静态文件会是一种最简便的解决方法。</p>

<h4>动态共享数据</h4>

<p>此类数据比外键关系更为复杂，实际上出现的几率也更高。对于此类情况，通常是由于数据库中隐含了某种领域概念，而实际上这种领域概念理应由代码直接表示出来。当抽象出该概念模型后，就可以把共享数据转变成独立服务了。</p>

<h4>动态共享表</h4>

<p>为了降低数据冗余，有时会把分属于不同领域概念的数据放在一张表中，这就是动态共享表。为了进一步划分服务边界，应允许适当的冗余，也即垂直分表，但这里的分表并非是抽象出独立服务，而是分配到不同服务中。</p>

<h3>3.重构数据库</h3>

<p>正如前文所述，切割服务确实需要重构数据库，而这一领域又少有人涉及，如《Refactoring Databases: Evolutionary Database Design》。而在预上线环境，应尽可能先部署包含两套schema的但仍然保持单一的版本，然后逐渐分离服务代码，直至成为两个不同的codebase。之所以要循序渐进，是因为隔离schema带来的第一个问题就是影响了后台数据读取操作，由原先的若干查询语句，成为API请求-查询数据库-响应模式，这就直接破坏了系统原有的事务集成特性。因此，应当在处理好这一部分之前，尽量不要独立上线新服务.</p>

<h4>事务边界</h4>

<p>在单一schema系统中，事务的好处是能轻而易举实现操作的一致性。而对分布式系统而言，事务边界被一分为众，数据一致性将面临挑战。</p>

<h4>稍后重试</h4>

<p>一致性的首要目标是处理中间出错的情况，在许多场景中，“强一致”是非必要的，而通常我们仅要求“最终一致性”。在这种情况下，可以设置一个队列或日志文件，存储数据库操作及其状态，并对出错操作进行特殊标记，稍后重试该操作，直到数据成功写入。该方法的前提是假设重试操作必然有效。</p>

<h4>全局操作中断</h4>

<p>数据回滚是另一种解决方案，但需要另维护一份回滚代码，从而保证错误数据被及时清除。问题在于保证回滚代码能够正确执行，可能需要采用前一种不断重试的方法。然而随着回滚数据的增多，该方法的有效性就会降低，成本则会不断增加。</p>

<h4>分布式事务</h4>

<p>分布式事务通过设置一个中央协调进程，监控所有执行节点的状态。一旦接收到事务请求，中央进程会向所有执行节点发出投票通知，执行节点在接到通知后会检查自己的数据提交状态，成功则返回赞成票，否则反对。只有当中央进程接收到所有节点的赞成票时，才会再向所有节点发出执行通知，每个节点分别执行数据提交，这就是朴素的分布式事务“两段提交”算法。
然而分布式事务算法始终不是“绝对正确”的，比如执行节点在投“赞成”之后出错。此外，中央协调进程的存在会使得所有资源被加锁，进而存在资源竞争行为，降低系统可用性。
目前已经有一些针对分布式事务的实现，如Java的事务API。但是，分布式事务带来的副作用是必须要考虑的问题。</p>

<h4>小结</h4>

<p>保持一致性会带来更多的复杂因素，例如分布式事务会降低可用性和伸缩性。当一致性需求发生时，首先应思考它的必要性，或者采用局部事务、最终一致性加以替代。如果确实是强一致，应尽量避免切割。如果一定要切割，也可以选择设计一种混合抽象来代表事务本身，从而降低分布式事务的复杂度，进而保证可用性（例如在销售系统中，分离出一种“处理中”的订单服务，从而降低销售和库存服务之间的耦合）。</p>

<h3>4.审计报表</h3>

<p>审计报表系统是企业应用里常见的需求，而随着微服务架构的演进，该类型的系统将面临重构。在单一系统中，报表很可能只是意味着若干SQL语句的集合，顶多在架构层面增设一个读库专供报表使用，读库和主库之间采用定时同步策略。
对微服务而言，上述方法存在一定缺陷：首先，数据库schema将以服务与报表系统之间共享的形式存在，这就导致任何变更需要格外小心；其次，许多数据库提供优化能力以提高读写性能，然而当处于微服务环境时，由于数据结构的不确定性，很难在报表数据库中实现任何优化；此外，随着异构数据库架构越来越普遍，SQL、NOSQL的混合使用将使得数据融合成为新挑战。</p>

<h4>采用服务调用获取数据</h4>

<p>假设一个商业系统报表，常见需求是列出最近15分钟产生的订单。在微服务中，这可能需要跨服务的数据调用。然而，当数据体量过大时，这种方法就会变的效率低下，例如条件变为过去24个月的订单信息查询，如果采用备份数据的形式存放在报表系统中，可能会导致非一致的结果。
一种有效方案是定时从主库中提取数据到报表库（通常是一个关系型数据库），仍然有几个问题需要解决：首先，不同微服务暴露的接口可能并非报表友好的，如果硬要基于现有API，可能会导致一些其它问题，例如数据的额外处理、cache失效等等。因此在针对可能存在的大数据传输问题，一个好的办法是目标服务并不通过HTTP直接返回数据内容，而是以文件的形式转存至第三方位置，这样主服务就可以通过轮询文件生成状态从而实现HTTP的低负载通信。</p>

<h4>数据泵</h4>

<p>除了拉取数据这种方式，也可以尝试采用数据推送的办法。传统HTTP的缺点是链接耗费较高，一方面是底层协议原因，另一方面是报表系统请求的API次数较高（有时该API甚至只为报表提供服务）。一种高效方案是设立一个第三方的数据泵，其同时拥有主数据库和报表数据库的访问权限，定时把主库的更新数据同步至报表库中。该方法唯一要解决的问题就是schema的管理，而事实上，报表库的schema可以看作是published api，泵程序最好和目标服务共同由一支团队开发，这就尽可能保证了schema的同步。</p>

<h4>事件数据泵</h4>

<p>数据泵是一种有效的数据同步方案，但同步时机缺乏验证。对微服务而言，当某个服务产生状态迁移时，可通过发出一个特殊事件通知泵程序，使后者能够订阅、接收并处理相关事件，从而实现事件驱动的数据同步。此外，为了减小通信压力，报表服务可以只提取差异数据，而非全部，这就尽可能避免了广播报表更新事件与相关数据所带来的副作用。然而，这是一种有效的近实时同步报表解决方案。</p>

<h4>备份数据泵</h4>

<p>该方法被用于Netflix的报表系统中，基于现有的备份方案。Netflix采用Cassandra作为其主数据库，并在此基础上构建了许多备份服务应用（详见github）。为了备份Cassandra，常规做法是生成一份数据文件（SSTables）拷贝并存放至第三方，例如Amazon S3。报表服务是基于Hadoop实现的大数据处理框架Aegisthus，其作用与本文中数据泵的概念类似。</p>

<h3>5.小结</h3>

<h4>面向实时</h4>

<p>由于业务需求的不同，许多服务，比如dashboard、alerting、financial reports甚至user analytics都具有相互不同的时效性要求，这就导致各个服务可建立在不同的技术选项上。微服务为此提供了良好的前提条件。</p>

<h4>变更代价</h4>

<p>微服务是面向需求变更友好的，但走向微服务的过程可能是极不友好的&hellip;例如切割服务、重构数据库等工作，都存在一定的风险。我们唯一能做的就是尽量使风险最小、可控。采用白板分析设计是一个常用的办法。此外，class-responsibility-collaboration卡是个“好”工具。</p>

<h4>理解根源</h4>

<p>问题的关键在于理解为何我们需要微服务架构。在实践中，我们经常会遇到某个服务迅速变的臃肿，尽管我们可能知道这么做所带来的不良后果。改善的第一步是找准下手位置，这正是本文的目的。当你熟练于此，随后就会自然陷入到微服务庞杂且无序的内部细节中。但是相信我，第一步才是最难的。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sessioncam: Introduction&Principle]]></title>
    <link href="http://www.hanyi.name/blog/2015/03/23/guide-for-sessioncam/"/>
    <updated>2015-03-23T23:43:49+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/03/23/guide-for-sessioncam</id>
    <content type="html"><![CDATA[<p>Recently we used an online user session recording service in one of our project, which caused my interests and push me to do some spike on such tool —— sessioncam. In this article, I will give an introduction as simple as I can, then try to dig deep into its design and implementation.</p>

<h3>1.What is sessioncam in one sentence?</h3>

<p>SessionCam is a leading “software as a service” session replay product used by clients to record and replay website sessions. you can visit <a href="http://www.sessioncam.com/">http://www.sessioncam.com/</a> for more detail.</p>

<h3>2.Basic features list about sessioncam.</h3>

<h4>i.Session replay</h4>

<p>Almost any behaviour of customers will be recorded and can be replayed by developers, including mouse clicks, movements, scrolling, form inputs, or any other actions on page, similar to specific actions on mobile devices. Developers can replay the recordings like playing videos by their sessioncam account with various speed.</p>

<h4>ii.Heatmaps</h4>

<p>User can generate website heatmaps for mouse movement(M), mouse clicks&copy;, page scrolling(S) and browser attention(A).</p>

<h4>iii.Funnels, Form Analytics, Field Drop-Off</h4>

<p>A kind of analytics tool to filter out useless data, improve conversion through assessing drop-off of users behaviour, such as page accessing or form inputing.</p>

<h4>iv.API and integration</h4>

<p>User can integrate sessioncam with their own analytics tool, such as Google Analytics, Campaign Monitor, CheetahMail and Olark.</p>

<h3>3.How to start?</h3>

<p>You must register an account on sessioncam <a href="http://www.sessioncam.com/plans/">http://www.sessioncam.com/plans/</a> , there are also free plan <a href="http://www.sessioncam.com/free-account-request/">http://www.sessioncam.com/free-account-request/</a> , with limited page count per month.</p>

<p>About which plan to choose, from our experience you can hardly use non-enterprise edition if all site visitors are planned to be recorded. Therefore, it depends on the scale of your site. If you only have hundreds users and each users will take hundreds page views on your site per month, that means medium edition is better for your situation.</p>

<p>There are many ways to deploy sessioncam to your website, most of them are very easy work with only a few javascript needed on your page. Refer to <a href="https://help.sessioncam.com/hc/en-gb/articles/200863126-Adding-SessionCam-to-your-website">https://help.sessioncam.com/hc/en-gb/articles/200863126-Adding-SessionCam-to-your-website</a> .</p>

<p>Login to your sessioncam account console and turn on recording, <a href="https://console.sessioncam.com/Dashboard/Manage/HostnameManagement.aspx?accountAdmin">https://console.sessioncam.com/Dashboard/Manage/HostnameManagement.aspx?accountAdmin</a> sessioncam will start working.</p>

<h3>4. How does it work?</h3>

<h4>Step 1. IO initialisation</h4>

<p>Reading and executing script from //d2oh4tlt9mrke9.cloudfront.net/Record/js/sessioncam.recorder.js, through which it will request for <a href="https://ws.sessioncam.com/Record/config.aspx">https://ws.sessioncam.com/Record/config.aspx</a> to initialise a sessionCamRecorder object, with tracking configurations from sessioncam server.</p>

<h4>Step 2. Run</h4>

<p>(Please refer to sessioncam.recorder.js when you reading this part)</p>

<p>Sessioncam will capture and clone the whole document inner html at line 5920(function SessionCamRecorder.prototype.ml), during this a pre-processing job should be done at line 6568. Below shows basic workflow:</p>

<ol type="a">
<li><p>Replace script, object, image, or any useless target element with short strings. The processed document content will be kept in SessionCamRecorder.hK.</p></li>
<li><p>Check whether sessionCamDebug is opened .</p></li>
<li><p>Initialise data structure which stores form data at line 5847.</p></li>
<li><p>Config for mobile device.</p></li>
<li><p>Check XHttpRequest configuration, if disabled by browser it will try swfhttprequest.</p></li>
<li><p>Bind any document interactive events in sessionCamRecorder.cU, line 7631.</p></li>
<li><p>Once any event triggered, sessioncam will collect event data and push them into IO pool, in SessionCamRecorder.prototype.gG, line 7279.</p></li>
<li><p>Looping scan all doms of page per 250ms, record any dom and its xpath value who is different from 250ms before into IO pool. line 6855-6878.</p></li>
<li><p>Looping check IO pool and send existed data flow by time to sessioncam server, in SessionCamRecorder.prototype.jM, line 8106.</p></li>
<li><p>Send data to sessioncam server per second, in SessionCamRecorder.prototype.lh, line 8584.</p></li>
</ol>


<h4>Step 3. Replay</h4>

<p>According to step 2, sessioncam almost collects all the user&rsquo;s browser data at milliseconds level, it&rsquo;s easy to replay the session by time flow. Actually, for session replay there is an iframe element which always figuring to remote getpage.aspx, with parameters like PageId, SessionId, starttime, EventId, HostnameId, etc. Javascript can play this iframe just as animation easily.</p>

<h3>5.Miscellaneous</h3>

<p>Sessioncam identify data only by website domain, which means you must register sessioncam account by a domain, and once such domain has been taken, new account can not set same domain unless the first user permits it.</p>

<p>Session data may contain some user privacy data, but sessioncam will ignore most common item like password, credentials. But admin can still config some privacy fields to be ignored.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[microservices陷阱: 实践篇(服务建模和集成)]]></title>
    <link href="http://www.hanyi.name/blog/2015/03/06/microservices-trap-practices/"/>
    <updated>2015-03-06T08:36:44+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/03/06/microservices-trap-practices</id>
    <content type="html"><![CDATA[<p>总的来说，微服务并不是指某一个具体的技术。推崇者认为它得益于Eric Evans的领域驱动设计、持续交付、Alistair Cockburn的六边形架构、基础设施可视平台和小型全功能团队等众多近年内不断涌现的高效实践。ThoughtWorks的Sam Newman认为，微服务包含两方面含义：小且只专注做一件事，自治性。</p>

<h3>1.服务建模</h3>

<p>在概念篇中我们已经提到，服务其实就是系统中的组件。容易理解的是，好的服务设计也就是常说的“高内聚、松耦合”。意味着多个服务之间的低依赖性、以及服务内部的行为紧相关性。这种特征使得代码变更带来的影响面尽可能小，同时实现快速简单部署。那么服务建模的目的就在于寻找问题域中的边界，划分出相关行为，同时保证边界间通信的低依赖性。
微服务推荐DDD的设计思想，鼓励在构建系统时参考真实世界中的领域，而不是套用分层架构。其中最重要的概念就是边界上下文——即任何领域都可以被认为是由许多边界上下文构成，其内部容纳着具体的物（模型），其中有的物无需和外界进行通信，有的物则与其它边界上下文共享。每个边界上下文都包含一个显式接口，决定哪些物共享出去的。</p>

<p>边界上下文的另一个简单解释就是“一种被显式边界强化的特定职责”。当你想和边界上下文内部进行通信，或是请求其内部的某些功能时，你需要携带模型和它的显式边界进行通信。Evan把边界上下文比喻为细胞，而决定物质进出的细胞膜就是显式边界。微服务把边界上下文和服务紧密联系在一起，尽管边界上下文可以是任何一种组件或模块，其可以存在于单一系统中，也可以存在于独立进程中。而后者也就是微服务的例子。</p>

<p>然而过早确定边界是不明智的，特别是在初期，一旦边界不稳定，就会造成更多的修改和成本增加。比较好的方法是在一个成熟codebase上划分边界，而非一开始就这么做。</p>

<p>在划分边界上下文时，需要注意该上下文对领域内其余部分提供的业务能力，而这种业务能力通过共享模型实现信息交换。而如果对单纯的CRUD操作划分边界，失去了它的业务意义，则完全没有必要。</p>

<p>在实践中，一般是自顶向下划分出边界上下文，粒度也应当是由粗到细。然而在演进的过程中，是否独立出内嵌的上下文，则取决于设计和团队等因素，如果某个团队同时负责若干个上下文，则可能会把它们组合成一个较大的上下文而非全部分离出来。这种内嵌上下文的另一个好处在于，较粗的架构能简化测试，特别是针对庞大复杂的end-to-end测试。</p>

<h3>2.服务集成</h3>

<p>服务集成是微服务架构中最重要、技术最相关的部分。一般存在两种风格：<a href="http://www.infoq.com/cn/news/2008/09/Orchestration?utm_source=infoq_en&amp;utm_medium=link_on_en_item&amp;utm_campaign=item_in_other_langs">编配和编排</a>，编配是指通过一个中心服务以同步通信的方式管理其它服务，编排则通过事件队列实现异步通信，相关服务自己监听相应事件。前者的优点是结构明确、易于开发，缺点是变更成本高、难以维护；后者则实现了松耦合，缺点是难以调试，需要额外的监控代价。
无论采用何种风格，都避免不了集成方法的选择。一般可用的集成方式有SOAP、XML-RPC、REST、Protocol Buffer等，但这些方法有一定的针对性。值得注意的是，编配风格的架构更易于构建，特别是带语义的请求/响应类型的通信，同步方式是最简洁的实现。相比之下，编排风格的架构就需要额外的callback机制处理响应数据。</p>

<h4>请求/响应类</h4>

<p>目前请求/响应类通信存在两种流行的方式：RPC和REST，其特点各不相同。</p>

<p>RPC包括多种技术，如SOAP、Java RMI、Thrift、Protocol Buffer等。其中SOAP采用XML格式的协议构建消息，其余则为纯二进制形式。
一些RPC技术仅限于某种特定领域，如Java RMI，必须运行在JVM中。尽管有些不限定语言或平台，但依然会带来或多或少的集成限制。
RPC的另一个缺点是过于“底层”，除SOAP外，几乎都直接基于TCP/UDP实现，然而由于网络环境的限制，应用不得不考虑可靠性、容错性、语义性。
在设计上，RPC方式如Java RMI过度依赖于服务接口和Model实现，任意变更都很可能影响服务端、客户端以及相关测试代码，并继而影响后续的测试和部署，这就是lock-step release。当然Thrift和Protocol Buffer为此改进了许多。</p>

<p>与RPC从底层构建不同的是，现代REST提供了更为抽象的<a href="http://martinfowler.com/articles/richardsonMaturityModel.html">架构方式</a>。一般来说，REST over HTTP是最易于实现的一种REST，但不是唯一途径，本文只就REST over HTTP展开讨论。</p>

<p>REST over HTTP的好处在于，二者拥有许多能够相互对应的概念，如动词GET、POST和PUT，其含义是十分明确的。此外，HTTP拥有极为完整的生态系统，从缓存代理Varnish、负载均衡modproxy、以及监控系统，这就使得构建系统变得十分高效。另外，HTTP还支持较完整的安全控制机制，从基本验证到客户端证书等等。
值得一提的是，SOAP同样基于HTTP，然而却抛弃了大量HTTP中极富内涵的概念，使得学习成本、系统复杂度都大大增加。
REST over HTTP也存在缺点，一、生成客户端stub的成本较高，超媒体控制客户端很可能以共享库的方式在微服务中广泛使用，从而导致变更困难；二、HTTP动词并没有得到服务器端的良好支持，但是通常有绕过的办法解决该问题；三、HTTP连接是基于TCP的，因此即使是JSON或二进制数据传输，性能也比不上Thrift这种纯二进制协议，对于低延迟的应用就更是如此。</p>

<h4>异步事件类</h4>

<p>事件处理需要考虑两方面内容：服务端发送和客户端接收。
传统的消息队列如RabbitMQ，试图一次解决上述问题。发送者通过API向队列中发送事件，队列处理针对这些事件的订阅，向接收者发出通知，甚至还能处理接收者状态，例如帮助跟踪历史消息。然而类似的中间件系统目前变的越来越臃肿，厂商向其注入了更多智能化组件，这不得不让人联想到ESB的情形。因此，时刻保持哑管道和智能终端，是引入中间件技术时必须要考虑的问题。
除此之外还有一个特殊选择：<a href="http://tools.ietf.org/html/rfc4287">ATOM</a>。ATOM本身就是基于REST的服务发布协议，由于开发库较完备，事实上也可被当作事件发布/订阅工具。同样，基于HTTP的架构具有良好的扩展性，却不适用低延迟应用。</p>

<p>尽管事件驱动架构具有诸如松耦合、可扩展等优点，但其带来的系统复杂性也随之大幅提高。或者至少应当着重注意监控过程，特别是跟踪跨服务边界的请求。<a href="http://www.enterpriseintegrationpatterns.com/">Enterprise Integration Patterns</a>是目前服务集成领域的权威著作。</p>

<h3>3. 服务集成需要注意的问题</h3>

<h4>服务即状态机</h4>

<p>无论是否采用REST，服务即状态机都是一种强大的思维模式。其核心在于，构建具有尽可能丰富功能的服务，而非将部分功能划分至服务外，例如管道甚至消费者一边，这会丧失高内聚的特性。举个例子，当消费者向提供者发送更新请求时，应由提供者一方决定是否接受这次修改，而非由消费者决定，从而保证数据和行为的一致性。</p>

<h4>重新思考DRY</h4>

<p>我们都清楚DRY的含义，并且了解DRY带来的好处。然而，在微服务架构中，服务间的代码共享可能会导致修改灾难，一般而言，应当允许一定的重复代码存在于不同服务中，而非使用统一的共享库。当然，微服务内部应遵循DRY原则。
一个例外是对客户端库的设计，客户端库能够方便保持整个系统的可靠性和可扩展性，例如引入服务发现、请求失败、日志等通用特性，这种DRY是有益的。但应注意保证客户端库不被具体的服务逻辑污染这一原则。</p>

<h4>引用访问</h4>

<p>当在服务请求间传递领域实体时，需要考虑值传递或引用传递两种方式。一般而言，消费者并不需要保证自己获取的资源是最新的。但某些特殊需求可能会有此限制，这时就需要在获取资源时同时取得该资源的引用方式，从而使消费者时刻能获取其最新的状态。当然，频繁的资源请求也会导致系统负载增加，这里我们需要考虑是否一定要实现实时更新，如果不是，则可以利用HTTP自身的缓存控制机制减轻负载；或者根据不同需求只传递需要的资源属性。</p>

<h4>版本化</h4>

<p>版本化会引入更多复杂性，因此在对服务接口进行变更时，尽量避免采用版本机制。如果一定要采用，应分配语义化版本，一般遵循MAJOR.MINOR.PATCH即可。这种令不同版本接口共存的做法，能够尽量减轻消费者的迁移压力。当然如果项目足够小，只需要保持新旧接口同时存在就好，版本化就太过了。</p>

<h4>用户界面集成</h4>

<p>用户界面集成几乎是任何系统都必须要考虑的问题，微服务中尤为如此。传统上，不同服务可能会有各自的UI组件，并嵌入在页面相应位置。然而该方法需要考虑用户体验的一致性，同时，由于要适应不同设备的需求，各UI组件还需要考虑响应式的问题。此外，有些服务并不能以单个UI组件的方式提供给用户，而可能存在与其它服务协作的情况。因此，用户界面最有效的构建方法就是前端负责UI，后端负责提供API，互不干涉。
整块前端的做法并不利于降低开发的复杂度。为了解决这一问题，采用API网关技术，针对不同设备的请求返回不同的内容聚集。然而API网关可能会导致该层过于复杂，有时会适得其反。一种轻量的解决方法是前端＋特定后端技术，即不采用整块API网关，而是针对不同设备构建特定的后端支持系统，尽量减轻复杂度。</p>

<h4>集成第三方应用</h4>

<p>采用第三方应用有时会显著降低成本，最简单的就是直接集成到现有微服务系统中，通过暴露应用API从而向其它角色提供服务。更进一步，如果能够抽象出系统角色，就能借助角色层连接微服务和该第三方应用。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Microservices陷阱：概念篇]]></title>
    <link href="http://www.hanyi.name/blog/2015/02/18/microservices-trap/"/>
    <updated>2015-02-18T20:33:00+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/02/18/microservices-trap</id>
    <content type="html"><![CDATA[<p><em>2011年5月，microservice一词由一次在威尼斯举行的软件架构工作坊中被提出，直到次年的同次会议中被正式命名为microservices（微服务）。</em> <a href="http://martinfowler.com/articles/microservices.html">James Lewis, Martin Folwer</a></p>

<p>通常，微服务被用于描述一种架构风格。在这种风格下，单个应用软件被设计成一系列可独立部署的服务。尽管业界在微服务的具体定义上还有争议，但其基本上代表了自动化部署、智能终端、语言和数据的去中心化等特征。</p>

<h3>1.基本概念</h3>

<p>Martin是这样用一句话描述微服务的：</p>

<p><em>对于每一个小型服务，其拥有独立的进程、轻量化通信机制（通常是http请求）、这些服务围绕着业务上下文构建，并可以实现独立的自动化部署。而这种控制的去中心化允许不同服务可以采用不同的语言和数据库技术实现。</em></p>

<p>微服务的拥趸把与之相反的设计风格称为monolithic，也就是单一系统。在他们看来，凡是不符合微服务特征的架构，都属于单一系统。</p>

<h4>企业web应用中的单一系统和微服务架构</h4>

<p>基本的企业web应用架构包含三层，分别是用户界面层（页面）、数据层、以及服务端应用层。其中服务端应用层负责接收请求，处理领域逻辑，操作数据库，然后选择响应的视图。单一系统风格一般是指服务端应用层的设计，任何修改都需要对整个系统进行重新部署。</p>

<p>单一系统风格的缺点是：1.小的更新需要对整个系统进行重新构建和部署；2.单一系统内的模块化设计通常很难维持，事实上很难做到完全的修改隔离；3.扩展时需要考虑整个系统，而不是其中拥有真正需求的一小部分。</p>

<p>针对单一系统的上述问题，微服务提供了自己的解决方案：应用软件被设计为一系列服务，这些服务允许独立部署和扩展。每个服务需要提供一个稳固的模块边界，允许由不同语言和团队实现。</p>

<h3>2.微服务的基本特征</h3>

<h4>利用服务实现组件化</h4>

<p>在微服务中，组件化是目的，分割服务是方法。这里的组件是指实现替换和更新独立的软件单位。其中，在不同的场景中软件组件的定义可能不同。一种情况是采用库实现组件，这里的库是链接程序代码、并且直接在内存中调用的一种组件化形式。而对微服务而言，由于服务是进程隔离的，通常采用web service或者rpc实现相互通信的组件化。</p>

<p>基于服务的好处在于，1.允许独立部署，对整体变化更轻量，尽管有些改动不可避免地影响到接口层面，从而产生协同变化，但可以通过聚合服务边界和利用服务契约实现优化演进。2.更加明确的发布接口，对于语言层面来说，发布接口可能没有什么太好的办法，通常只能借助文档并且约束用户破坏组件的封装性，导致组件间的紧耦合。</p>

<p>当然服务也有缺点，首先rpc的效率远不及进程内调用，意味着远程api需要是粗粒度的，但使用起来并不方便。如果需要跨组件的职责变更，跨进程边界通常并不容易。再次，服务内的进程完全独立于外界，包括开发和部署，也就意味着应用服务器和数据库也应当是独立并仅为该服务使用的。</p>

<h4>围绕业务能力构建组织</h4>

<p>为了避免康威法则，应转变固有的以功能划分团队的方式，尽可能组建全功能团队。对于大型单一系统应用，几乎都可以围绕业务能力进行模块化，但这通常需要团队按照业务线划分，这里遇到的主要问题是，通常这些团队的组织都基于复杂的上下文。如果单一系统跨越了多个模块边界，那么对团队中的个体成员来说消化成本是非常高的。此外，模块线需要一个强有力的约定去保证实施。而服务组件能够提供更加明确的分割，从而使团队边界更清晰。</p>

<h4>产品而非项目</h4>

<p>绝大多数的应用开发采用项目模型的方式运作，即完成软件并交付给运维团队，然后开发团队解散。而微服务建议摈弃这种项目形式，而是让团队拥有产品的整个生命周期。这种做法的好处是令整个开发团队能够更进一步和用户接触，承担一定的用户支持任务，并理解用户的业务需求。而对于单一系统而言，该做法几乎很难实现。</p>

<h4>智能终端和哑管道</h4>

<p>当构建不同过程间的通信框架时，多数做法是将业务智能整合进通信机制中，例如Enterprise Service Bus，ESB。ESB产品通常包括了消息路由、编排、变换、乃至业务规则的制定等复杂功能。智能终端和哑管道则相反，由于解耦的需求，服务应当拥有其自身的逻辑，采用类似REST的通信协议，而非WS-Choreography，BPEL或其它采用集中式工具编写的复杂协议。两个好的例子分别是Http API（或protobuf）和轻量级消息总线。后者通常的特点也是“哑”的，如RabbitMQ或ZeroMQ，它们仅仅提供一套异步纤程，智能仍掌握在终端服务手中。</p>

<p>当你试图从单一系统转移至微服务时，最大的难点在于解决内部消息机制。而朴素的转移可能会导致不良通信行为，这里可能需要采用粗粒度方法解决细粒度通信的问题。</p>

<h4>去中心化的控制</h4>

<p>控制中心化的一个结果是使单一的系统平台成为标准，这么做的缺点在于，并非每个问题都是钉子，也并不是每个问题都是锤子，更恰当的方法是在具体情况下采用正确的工具。</p>

<p>微服务的理念是条条大路通罗马式的，也就是说强调服务的独立性。实际上，你会发现越来越多的开发人员开始从自己的实现中分离出实用工具，并分享至社区（工具之间可能拥有类似的功能，却存在不同的实现形式）。</p>

<p>然而这种自由并不意味着微服务并不遵守服务契约。恰恰相反，像是Tolerant Reader和Consumer-Driven Contracts这种契约模式经常被用于微服务实现，帮助服务能够独立发展。同时契约能够保证新服务开发的精简性，保证YAGNI原则，提高开发效率。</p>

<h4>去中心化的数据管理</h4>

<p>目前存在许多方法来解决数据管理中心化的问题。在最抽象级，就意味着划分出系统间不同的概念模型。例如，在大型企业级应用中，顾客的销售视图和支持视图之间存在差异，在销售视图中的顾客信息并不会存在于所有支持视图中，而这又会由于不同语义间的细微差别而存在不同或相同情况。</p>

<p>基于上述原因，如果试图把单一系统划分为多个分离的组件，采用领域驱动设计DDD会是一个不错的方法。DDD能够把复杂的领域分解成多个带边界的上下文，并建立其相互之间的映射关系。对于单一系统和微服务来说DDD都很有效，而后者在概念上更加符合DDD增加隔离的思想。</p>

<p>当基于概念模型进行去中心化时，微服务同样要求把数据存储去中心，而单一系统则采用单独的逻辑数据库进行持久化，企业甚至倾向于使用同一个数据库覆盖多种应用（这在很大程度上取决于供应商的许可证业务）。微服务则更加极端，既可以采用同一数据库技术的多个实例，或者采用完全不同的数据库技术实现（Polyglot Persistence，同样可适用于单一系统）。</p>

<p>这里最大的问题是变更管理，因为在许多应用场景中，单一系统采用事务处理的方式保证多个资源间的一致性。而在分布式系统中，事务无疑变得十分困难，这令微服务面临两难的问题：既要保持分割独立，又要保证一致性。而在实际上，微服务的设计思想倾向于强调服务间的弱事务性。这就使得一致性只可能是最终一致性，并采用弥补操作解决相关出现的问题。</p>

<p>这种非一致性管理的问题对多数团队都是一项挑战，但在实际业务中却时有发生。有时具体业务会要求将不一致性保持在一定程度以内，从而快速响应需求，同时拥有一些类似于回退的过程处理错误。一旦修复这些错误的耗费小于保证业务的强一致性，这种权衡就是值得的。</p>

<h4>基础设施自动化</h4>

<p>近年来，基础设施自动化技术取得了巨大的进步，特别是类似AWS这种公有云服务的兴起，降低了构建、部署、以及操作微服务的门槛。</p>

<p>一般来说，采用微服务的团队通常都能熟练应用持续集成CI、甚至持续交付CD技术，拥有丰富的基础设施自动化背景。CI/CD的目标是令构建和部署变得“无趣”，一旦目标达成，任何扩展就变得非常容易实现，而这在单一系统上已经得到了充分验证。对于微服务来说，该项技术与单一系统相比没有太大区别，但两者的操作域存在明显区别。</p>

<h4>高融错设计</h4>

<p>当采用服务作为应用组件以后，该应用就需要被设计成面向服务的高容错系统。而在实际情况中，任何服务都有可能发生错误而中止服务，客户端必须据此给出合理的响应。与单一系统相比，这是一个存在于微服务系统中的额外复杂度。</p>

<p>首先是测试，包括在生产环境中执行自动测试，以及当某些服务或者数据中心出错的意外情况恢复和监控。然而对习惯于单一系统的运维团队来说，这种方式可能是一时难以接受。
微服务特别强调服务的实时监控，无论是架构方面，还是业务方面，这种语义化监控能够提早给出出错警告并同时开发团队。对于单一系统，可以把单个应用视为一个微服务，区别是你需要在不同进程中的服务出错时得到警告。而由于单一系统通常采用库实现组件化，相同进程内的服务出错可能并不会得到明确的警告。</p>

<p>总而言之，微服务要求较为完善的监控和日志系统，同时拥有一个实时的dashboard随时通知开发团队，重要的测量单位有断路器状态、吞吐量、延迟等等。</p>

<h4>演进化设计</h4>

<p>微服务的实践者通常拥有演进化设计背景，他们把服务分解当作未来控制变更的工具之一。控制变更的目的并非是要降低变更频率，而是保证更好、更快地控制变更对软件的影响。
无论何时对现有系统进行组件化分解，你都需要遵守一个分解原则：组件的关键属性之一是独立可替换和升级。这就意味着我们需要寻找一个点，能够通过重写这部分的组件而不会影响其它组件。而实际上，很多团队选择直接将服务碎片化，而非进行长期演进。</p>

<p>在模块化设计中，一个通用的准则是强调可替换性，这样就可以保证接受变更。当你发现你需要重复的修改两个服务时，那就意味着它们应当被合并。</p>

<p>微服务的优势是降低变更发生时的构建和部署时间，缺点是你需要考虑服务变更对消费者带来的影响。一个传统的解决方式是采用服务版本管理策略，但对于微服务来说，应当尽量不要进行版本管理。在许多情况下，我们可以通过设计使得服务尽可能接受不同的消费者请求。</p>

<h3>2. 总结</h3>

<p>上文几乎列出了微服务架构到目前为止被发现的全部优点，这里列出其缺陷或尚未解决的问题：</p>

<h4>组件边界的确定</h4>

<p>由于微服务本质上是采用服务实现系统组件化，那么组件边界就成为衡量微服务设计优劣的重要参考价值。一旦设计完成，任何代码级重构、借口变更、向下兼容、以及测试架构的复杂度都会提升。</p>

<h4>组件的组成</h4>

<p>当组件的组成方式存在瑕疵，剩下来能做的就是把组件内的复杂性转移至组件连接部分。当你关注组件内部时，应当注意组件间的组成方式设计。</p>

<h4>团队技能</h4>

<p>任何新技术都倾向于更适合拥有中高级能力的团队，但并非对其它团队完全无用。即使是采用单一系统，某些团队依然做的一团糟，而微服务表现如何犹未可知。</p>

<p>最后给出Martin对何时向微服务架构迈进的评论：
<em>One reasonable argument we&rsquo;ve heard is that you shouldn&rsquo;t start with a microservices architecture. Instead begin with a monolith, keep it modular, and split it into microservices once the monolith becomes a problem. (Although this advice isn&rsquo;t ideal, since a good in-process interface is usually not a good service interface.)</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[喜讯：热烈祝贺本站正式被OOXX！！]]></title>
    <link href="http://www.hanyi.name/blog/2012/10/13/xi-xun-re-lie-zhu-he-ben-zhan-zheng-shi-bei-OOXX/"/>
    <updated>2012-10-13T01:05:39+08:00</updated>
    <id>http://www.hanyi.name/blog/2012/10/13/xi-xun-re-lie-zhu-he-ben-zhan-zheng-shi-bei-OOXX</id>
    <content type="html"><![CDATA[<p>经向有关部门了解，本站已被GFW屏蔽，具体原因不明。大家今后VPN见！百度的朋友就对不住啦&hellip;&hellip;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[有关秋雨、毕业、软件测试、痛苦根源、《金刚经》和妄念的一切]]></title>
    <link href="http://www.hanyi.name/blog/2012/09/08/you-guan-qiu-yu-bi-ye-ruan-jian-ce-shi-tong-ku-gen-yuan-jin-gang-jing-he-wang-nian-de-yi-qie/"/>
    <updated>2012-09-08T01:43:30+08:00</updated>
    <id>http://www.hanyi.name/blog/2012/09/08/you-guan-qiu-yu-bi-ye-ruan-jian-ce-shi-tong-ku-gen-yuan-jin-gang-jing-he-wang-nian-de-yi-qie</id>
    <content type="html"><![CDATA[<p><em>须菩提白佛言：“世尊！佛得阿耨多罗三藐三菩提，为无所得耶？”佛言：“如是，如是。须菩提！我于阿耨多罗三藐三菩提乃至无有少法可得，是名阿耨多罗三藐三菩提。”</em></p>

<p style="text-align: right;">——《金刚般若波罗蜜经》，第二十二品 无法可得分</p>


<p>趁着雨天赶上了入夜前的最后一班校车，结果遇到喜闻乐见的大堵车，折腾回家天已全黑。待饭毕，终于不愿去碰什么C++、数据结构与算法的书——最近整天泡在图书馆里读各种经典，恨不能把本科和研究生几年来西大欠我的一座图书馆一下子搬走。结局是书读了不少，却毫无长进：恐怕是因为我这种随众的心态，毕竟眼见人人都揣着本面试宝典之类的畅销书，再淡定也终不能自持了。但这真称得上是所谓的奋斗么？却未必尽然。</p>

<p>现在回头看一眼前一篇文章的日期：写于大约一个半月之前。在那又之前的很长一段时间里，我始终以为未来将在那之后笃定，我甚至认为自己将与心仪的导师和朝气蓬勃的团队会面，大家相谈甚欢，以至于令我觉得能够在自己钟爱的领域大干十年，人生便没有遗憾了。然而当青岛会议结束后，却发现情况和当初预想的完全不同：首先，如果稍了解国内的科研现状，你会发现好的导师和团队真是凤毛菱角，即便遇到了，准入门槛也极高，甚至不完全取决于主观因素，有时真得称得上是可遇而不可求；其次，我发现自己现有的心智模式中可能缺少非常重要的一块，尽管多年来不时遇到好心人提醒，却很少真的思考这个问题。换言之，如果我选择并得以“再干十年”，难道就真能得到自己想要的东西么？</p>

<p>这是一个矛盾，而且以我仅有的经验而言根本无法解决之，也无法获得能够真正说服自己的第三方的帮助。再加上七八月份的火气：令我不得不选择逃离，去到一个能够给自己降温的圣地，也是为了给自己留一点时间：我明智地选择了一人出发，在青藏高原起伏的草场上，试图短暂忘却平均海拔4000米下的一切，而有时候，甚至真的已经感到有些“乐不思蜀”了。有意思的是，等我回到家，发现命运已经把自己落下了一截。</p>

<p>我不知道它是如何发生，实话说也不想知道。大概是因为我有一种固有的计算思维，在提前制定测试用例时，我会像是强迫症似地列举出每条分支和可能性，然后从自己的角度做出对结果的评估。也就是说，我已经意识到这会是结局之一，的确就不很讶异了。但这种所谓的“淡定”存在明显的缺陷，即如果我们只一味做黑盒测试，无法真正从编码的角度去解释问题的原因，那么作为此生唯一的程序员，怎么保证自己能谱下一首生命之歌呢？然而关于这个问题，我至今没有想太明白。</p>

<p>后来有机会和朋友讨论这件事，还是不到两周前的事。谁知道大家听了都很不屑：“这简直太显而易见了吧？”我很惊奇他们是如何熟练掌握这种技能的，更有可能是道听途说吧？但如今世界的规则不就是由道听途说演变而来的么？唯一能确定的，就这是一切都没有超出合理的范围之外，如果连这些都不合理，那人类恐怕早都灭亡了也说不定。</p>

<p>于是我觉得自己又面临着一次需求跟踪与评估，值变了，维度却没变，复杂度依然毫无降低。唯一能做的，就是像众人一样，去啃那些本不值得在此时去啃的书。也就是说，虽然自己的算法bug了，换成朴素的一样好用，当然前提是你不是一个追求完美的狂热份子。我显然在这又悲剧了一把。</p>

<p>所以好不容易回趟家，绵绵秋雨，好时节当然不能全浪费了，便去读大乘经典。本文开头的《金刚经》第二十二分，大意为“须菩提问佛说：世尊，佛所得至高无上、大彻大悟大智慧，也就是什么也没得到吗？佛回答道：正是这样，正是这样！须菩提，我于阿耨多罗三藐三菩提，是无所得，（须菩提）一点法都没得到，只是说我成就了至高无上、大彻大悟大智慧。”另文中的名词可参见关于心经的注，在此就不讨论佛学。南怀瑾亦有关于本品的偈颂：“多年行脚觅归途，入室知为道路愚。检点旧时新衣钵，了无一物可提扶。”或许可当做送给自己的安慰作？仔细想了下，自己恐怕永远也到不了那个境界&hellip;&hellip;</p>

<p>尽管我崇尚绝对自由，甚至可以说如果没有自由，我就不再是我。但是另一方面，如果未来我选择妥协，用自己的自由去换取世界观，我就变成了另外一个我，一个背叛了原始的我的我，到那时，我该怎么看待自己？我只能确定，本文完成后还剩了一摞的书等着我去啃。至少通过这种方法，我就有机会去变成一个不一样的我，然后告诉原始的我：原来我是这样的我！</p>

<p>最后，如果读者您完全看懂了本文，那么也请尽量告诉我，让我能够佩服一下自己 ，谢谢。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[网络里的隐形蝴蝶]]></title>
    <link href="http://www.hanyi.name/blog/2012/07/24/wang-luo-li-de-yin-xing-hu-die/"/>
    <updated>2012-07-24T02:24:10+08:00</updated>
    <id>http://www.hanyi.name/blog/2012/07/24/wang-luo-li-de-yin-xing-hu-die</id>
    <content type="html"><![CDATA[<p>取道天津回家的路上，回想起在研讨班上介绍的近期发表在《Science》上的一篇文章——《<a href="http://www.sciencemag.org/content/337/6090/49.abstract">Network Interventions</a>》，恰好随身u盘里存有该期的full text，为了打发时间，便试读了这篇Review（很少去碰《Science》上的Review，往往感觉高贵但又不知所云）。结合最近、特别是这几天会议期间的经历，觉得有所感触，于是就想写文章，无奈下了动车就找不到一个能接到电源的地方，于是只好回家后将其完善。事实上，南加州大学Thomas W. Valente博士通过这篇Review列举了一些针对社会网络的最新研究成果，并向我们展示了一个看待现实问题的新思路。</p>

<p>原文作者Thomas W. Valente是USC的传播学博士，现任该校预防医学系副教授，由于数学学士的背景，其研究兴趣主要集中于网络分析和基于社会网络与程序评估的社会影响研究。Network Interventions的字面意思是网络介入，指利用社会网络数据加速行为变更或改善组织效率的一种新方法。近年来，研究人员逐渐发现通过分析已有的社会网络数据，并采用合适的方法就能得到一种具体且有效的Network Intervention方案，而一旦应用该方案就有可能引发强烈的正面或负面效应（Interventions并不是本文的重点，但却是原文的核心主题）。应当注意的是，Network Interventions之所以可被看作一门科学，是因为前期已有大量有关社会网络分析的研究，并取得了不乏瞩目的成果，而Network Interventions实际上是建立在前述成果基础上的一系列应用。那么，随着时间的推移，社会网络的规模和复杂度不断更迭，其本质是否已发生了无数次巨变呢？</p>

<p>同一篇文章的原作者著有一本《Social Networks and Health: Models, Methods, and Applications》，别出心裁地将社会网络分析的理论和方法应用于公共卫生和其它社会科学领域，其基本观点是：不同人类分组之间相互交流和传播形成了个体的健康行为。这里的“分组”可以指一个族群，也可以指一个个体。通过对社会网络的数据、特别是近年出现的基于互联网的虚拟社会网络所带来的庞大数据进行网络分析，研究人员发现个体行为和精神状态不同程度地受到了网络中相邻节点的影响，影响力最大的节点被称为“变更代理”。目前已有许多判别网络中“变更代理”的方法，而采用Borgatti提出的最关键节点方法可以找到网络中的局部Key player，即所谓的Leader。通常情况下Leader影响了网络中大部分节点的行为属性，但对于类似存在桥节点（且Leader非该类型节点）的网络，传播效率就很大程度上受到非Leader因素的影响。具体到公共卫生领域，这种影响可能是饮食性超重在节点间的传染，其根源则是Key player对其它节点施加了影响，使节点的固有行为、如饮食习惯等发生变化，从而导致超重节点数量的增加。另一个典型案例就是某种抑郁症的网络传播，这里会另文介绍。进一步，研究人员为了度量个体行为在网络中的传播速度和冲量（动量的变化量），通常采用一种“低阈值变更代理”的方法，即通过分析邻接Key Player数量与所有相邻的节点数，从而得到节点的曝光度，其值实际上就是每个节点的阈值。低阈值携带节点有时也会成为变更代理，但确定这部分则需要获取行为学意义上的先验数据加以支持。</p>

<p>总的来说，社会网络可被看作是一个个体相互间施加行为影响的媒介，如同一只隐形的蝴蝶，有意无意将花粉传播到网络中的各个角落。而随着电子信息工业的发展，互联网上的社会网络逐渐崛起，非常丰富和高质量的社会网络数据直接被用于网络分析，从而为底层的基础理论研究提供数据保障，使这第一手资料变得弥足珍贵。但是，研究人员仍需要进一步明确传统社会网络和所谓SNS的本质区别，由于网络传播的即时性和爆炸性，行为影响传播在广度上会有极大的促进，但也未必完全意味着好消息。毕竟，从植物学的角度来说，错误的花粉被授予柱头，将导致花粉和胚珠的双重浪费，这显然不是进化论给予我们的答案。</p>

<p>即使是在传统社会网络里，这种情况发生的概率也非常之低。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[整站迁移完成]]></title>
    <link href="http://www.hanyi.name/blog/2012/07/07/zheng-zhan-qian-yi-wan-cheng/"/>
    <updated>2012-07-07T21:20:38+08:00</updated>
    <id>http://www.hanyi.name/blog/2012/07/07/zheng-zhan-qian-yi-wan-cheng</id>
    <content type="html"><![CDATA[<p>最近一直在考虑是不是该升级到vps了？毕竟单纯的空间已经远远无法满足现在互联网DIY的需求。然而思考再三，vps需要花更多时间去照顾，恰好在未来一段时间内又不会很轻松，只好先忍一忍。于是决定趁早先拿下新域名hanyi.name。结果问题就来了，国内的空间商要求新绑定域名必须重新备案，否则按规定不予解析。还好我对这一套比较熟悉，屁颠儿跑去XX部网站办备案，结果被告知个人只允许备案1次，机构最多也只允许备案5次。而我前次备案是在08年，当时还是因为他们无故删除了我在06年就提交并审核通过的备案信息，悲剧的是他们这次居然成功保存了4年前的信息！回来找空间商商量，最简单的方法还是换别人的真实信息重新提交。顿时无语，原来早前CN域名开放是纯属坑人呢？进而有了将整站迁移至国外空间的想法。</p>

<p>域名问题很好解决，许多国外知名域名商支持通过支付宝进行国际支付，加上pending共花了一天时间完成。缺点是DNS初解析较慢，平时用的CN域名的解析在国内几乎是实时更新的。另一方面采用了原空间商在国外的主机业务，用电信线路看主机的ping不错，不过迁移后发现明显还是慢了一个级别，目前看来只好通过在今后优化页面内容来改善了。好处是空间容量是以前的三倍，不过现在看来用处似乎不大。</p>

<p>迁移工作还是颇费周折，现在看来wordpress迁移唯一必然的成功办法还是数据库内容链接的全文替换，否则只改几个字段可能会出现无法进入后台的情况。再加上周中实验室网络欠费，用了几天坑爹的“西大国内网”，很难顺利完成整站内容的迁移。于是只好把多余的时间用来进行一些反思：多年以来我做了许多自己感兴趣的工作，尽管无甚成果，但确实也学习了不少东西，总体上始终循着当初所谓“自由学习，自由思想”的理念，也从未遇过大的挫折。然而，出于一些忧虑和回避，自己有意无意忽视了平等交流：所谓平等交流，在我看来就是用自己的想法去换取别人的想法，并且所有人都认同且遵守唯一的道德准则。事实上，我对周围真实环境的了解程度非常低，某种程度上是基于以上原因。这也就导致了自己对身边事物的看法具有很强的不确定性，难以在自身问题上做出有效判断。另一方面也导致自己至今缺乏一些常识&hellip;&hellip;有些事在别人看来是显而易见，自己却不容易想明白。</p>

<p>考虑到有些外链是指向原mp77.cn，本站仍会对继续支持这个域名，并持续至少1年时间。而hanyi.name会是我的永久性域名，今后也不会再向站外自动导出文章。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[手嶌葵拯救世界]]></title>
    <link href="http://www.hanyi.name/blog/2012/06/28/shou-dao-kui-zheng-jiu-shi-jie/"/>
    <updated>2012-06-28T01:58:13+08:00</updated>
    <id>http://www.hanyi.name/blog/2012/06/28/shou-dao-kui-zheng-jiu-shi-jie</id>
    <content type="html"><![CDATA[<p>如果说，手嶌葵是六年前的《地海战记》迄今为止给人们留下的<a href="http://www.hanyi.name/blog/?p=189">唯一记忆</a>的话，同样的评价送给《虞美人盛开的山坡》恐怕也没多少人会提出异议。然而必须承认，宫崎吾朗的二次登场的确令人耳目一新，看似俗套的少女漫画情节，影片最终展现出的信息却远超出这个范畴。毫无疑问，我们都被影片和她的主题歌声完全治愈了。</p>

<p>仅从观影的角度来说，影片的主线情节可以说毫无新意，即使单是吉卜力在近二十年里也已拍了不少类似的主题，观者可能会感到比较乏味。不过如果换一个方向，会发现影片丝毫不含蓄地表达着一种积极向上的氛围，这一点却是同类型片中所少见的。正如《萤火虫之墓》展现给我们一个焦灼的日本一样，《虞美人盛开的山坡》所展现的是短短二十年后一个全新的社会。许多中国人都对五六十年代的日本感兴趣，以至于有关彼国六十年代经济腾飞的著述迄今都颇受欢迎，然而恐怕许多人（包括我）至今都为此感到困惑，如今幸好一部2011年本土票房冠军的影片能够给我们以管中窥豹的机会。</p>

<p>故事原设于公元1963年，恰好是东京第十八届夏季奥运会的前一年。阿海和阿俊几乎在同一时间内都遇到了“人生的重要挑战”，一是“拉丁楼事件”，二是关于自身的身世之谜。然而二人自始至终都未言放弃，一方面成功使得作为历史见证的活动大楼免遭校方为了“迎接奥运”而进行的拆毁重建；另一方面，同时也颇具戏剧性的是，历史真相的唯一见证人恰好在片末出现，吐露出了阿俊身世的秘密，并且终于卸下了重压在两人身上的历史包袱。如果仅仅从青春爱情故事的视角去鉴赏影片，有些情节可能经不起推敲，于是宁愿称之为一种朦胧的、尚未成熟的情感加以附会，但叙事手法上就显然比不上早年的《侧耳倾听》。事实上，从《地海战记》中我们就可以发现，宫崎吾朗的思想深度其实不亚于老爹，广度上则可能要更甚一些。然而他的劣势在讲故事的能力上，导演没能像上一辈的几部经典作品（当然宫老也并非只是传说）那样能够抓住观众，这种小遗憾现在看来恐怕仍然是不可避免的。</p>

<p>不过，导演真正希望传递的信息可能不止于此。其实，真正令人惊讶的是片中人物所共有的思维方式。例如，作为全剧线索的“拉丁楼事件”，即使在争辩双方矛盾非常尖锐的情况下，依然能够齐心协力维护大家得来不易的自由。学生们甚至喊出了“少数服从多数，即是多数人对少数人的暴力”这样颇具智慧的政治口号：这些桥段无一不体现着当时日本社会的整体风貌。另一方面，阿海和阿俊都是非常严肃地看待两人之间的微妙关系，哪怕是后来所谓的“兄妹疑云”，也没有发生任何情绪化事件，相反二人都在尽力追求真正的谜底：相比之下，在五十年后的现代社会，这样的“死理性派”是否太少了点呢？</p>

<p>如果对故事的所有事件追根溯源，则要归结于立花洋和泽村雄一郎两位长辈在战时的先后离世。阿俊每天驾着拖船驶过阿海家门前的一片水域，不经意间发现少女每天准时升起祈愿平安的U.W信号旗，于是撰下诗篇并发表在校园刊物上：</p>

<p><em>少女扬起了旗帜 </em>
<em>何故 </em>
<em>要将思念寄语晨风 </em>
<em>呼唤著远方 </em>
<em>伴著一时心血来潮的老鸦 </em>
<em>少女啊 </em>
<em>那藏青色围绕下红白相间的旗帜今日也在风中飞扬</em></p>

<p>命运就那样巧合。阿海偶然读到诗文，从此记住了松间俊这个名字，也为二人相识奠定了命运的基础。最后，唯一历史亲历者小野寺善雄的出现，使得尘封十余年的故事最终浮出水面，拖船缓缓驶向岸边，夕阳下的阿海和阿俊终于如释重负：对阿俊而言当然是得知了自己的真实身世；另一方面则包含了阿海对父亲的怀念；而当下乃至未来的意义则是不言自明了。片末，阿海完成了人生中迄今为止最为宁静的一次升旗，镜头回到姐姐的那副画作，正是不远处水域上航行的那艘拖船，船头也挂起了“答语U.W”。对导演来说，战后的日本社会长期受到历史遗留问题的困扰，而同样作为战争受害者的普通民众则受之更甚：人们需要通过某些方式得到彻底解脱，才能坦然面对未来并开始新的生活。实际上，六十年代的日本国民不仅做到了，而且还比其他亚洲国家要出色的多。或许这才是导演的真正意图：唤醒国民对美好时代的回忆与憧憬，而且不应仅仅是怀念而已。</p>

<p>手嶌葵的歌声在片尾响起，其实是翻唱自森山良子在七十年代的一首老歌《さよならの夏（告别之夏）》，宫氏招牌式的完美结局，在手MM的伴奏下逾显动人了（也彻底填补了影片末尾与《侧耳倾听》之间存在的思想差距）。</p>

<p>附歌词：</p>

<p><em>光る海に かすむ船は</em></p>

<p><em>さよならの汽笛 のこします</em></p>

<p><em>ゆるい坂を おりてゆけば</em></p>

<p><em>夏色の风に あえるかしら</em></p>

<p><em>わたしの爱 それはメロディー</em></p>

<p><em>たかく ひくく 歌うの</em></p>

<p><em>わたしの爱 それはカモメ</em></p>

<p><em>たかく ひくく 飞ぶの</em></p>

<p><em>夕阳のなか 呼んでみたら</em></p>

<p><em>やさしいあなたに 逢えるかしら</em></p>

<p><em>だれかが弾く ピアノの音</em></p>

<p><em>海鸣りみたいに きこえます</em></p>

<p><em>おそい午後を 往き交うひと</em></p>

<p><em>夏色の梦を はこぶかしら</em></p>

<p><em>わたしの爱 それはダイアリー</em></p>

<p><em>日々のページ つづるの</em></p>

<p><em>わたしの爱 それは小舟</em></p>

<p><em>空の海をゆくの</em></p>

<p><em>夕阳のなか 降り返れば</em></p>

<p><em>あなたはわたしを 探すかしら</em></p>

<p><em>散歩道に ゆれる木々は</em></p>

<p><em>さよならの影を おとします</em></p>

<p><em>古いチャペル 风见の鶏(とり)</em></p>

<p><em>夏色の街は みえるかしら</em></p>

<p><em>きのうの爱 それは涙</em></p>

<p><em>やがて かわき 消えるの</em></p>

<p><em>あしたの爱 それはルフラン</em></p>

<p><em>おわりのない言叶</em></p>

<p><em>夕阳のなか めぐり逢えば</em></p>

<p><em>あなたはわたしを 抱くかしら</em></p>

<p>（完）</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kinect的三维重建(1)]]></title>
    <link href="http://www.hanyi.name/blog/2012/06/22/Kinect-de-san-wei-chong-jian-1/"/>
    <updated>2012-06-22T20:35:07+08:00</updated>
    <id>http://www.hanyi.name/blog/2012/06/22/Kinect-de-san-wei-chong-jian-1</id>
    <content type="html"><![CDATA[<p>有关Kinect应用开发正日新月异，稍有懈怠就会被远远甩在身后。不过，Kinect目前带给我们的仍只是一个充满无限可能的远景，正如App store能吸引年仅<a href="http://www.cnbeta.com/articles/161695.htm">11岁的开发者</a>一样，Kinect未来将对“全民开发者”产生重要推动作用。另一方面，一些基于Kinect的应用研究仍颇复杂，主要是因为一些关键环节的滞后而导致的。2011年的siggraph talks上，<a href="http://research.microsoft.com/en-us/projects/surfacerecon/">KinectFusion</a>首次展示了实时、廉价、轻便的室内场景三维重建，使得我们向着“无处不在的数字化”迈进了一大步。该项目主要由微软剑桥研究院的研究人员发起实施，研究小组目前公开发表了两篇文章：</p>

<p>Shahram Izadi, David Kim, Otmar Hilliges, David Molyneaux, Richard Newcombe, Pushmeet Kohli, Jamie Shotton, Steve Hodges, Dustin Freeman, Andrew Davison, and Andrew Fitzgibbon, <strong>KinectFusion: Real-time 3D Reconstruction and Interaction Using a Moving Depth Camera</strong>, ACM Symposium on User Interface Software and Technology, October 2011</p>

<p>Richard A. Newcombe, Shahram Izadi, Otmar Hilliges, David Molyneaux, David Kim, Andrew J. Davison, Pushmeet Kohli, Jamie Shotton, Steve Hodges, and Andrew Fitzgibbon, <strong>KinectFusion: Real-Time Dense Surface Mapping and Tracking</strong>, in IEEE ISMAR, IEEE, October 2011</p>

<p>除了Microsoft Research外，国内外大量机构都借助Kinect进行相关研究。仅就实时场景三维重建这项应用而言，由开源机器人研发公司Willow Garage在2011年发起的Point Cloud Libary (PCL)就吸引了全世界数十家著名科研机构参与、十余家公司提供经济支持。PCL是一项集点云获取与处理、滤波、特征提取、关键点标定、表面重建和点云配准以及点云融合等功能为一体的开源点云处理库，PCL使用OpenNI作为系统IO接口，实际成为KinectFusion的开源实现项目，该项目的相关论文发表在<a href="http://www.pointclouds.org/assets/pdf/pcl_icra2011.pdf">ICRA2011</a>上。</p>

<p>上述文献可以说是迄今为止有关Kinect的三维重建应用的最佳切入点了。应注意的是这两篇文章讨论重点的区别，前者先是对KinectFusion整个项目进行了流水式说明，随后解释了文中采用的经典算法的GPU实现，开发者可能会比较感兴趣；而后一篇文章则重点讨论了新的并行算法的形式化描述和性能分析，这部分可能会更吸引一部分研究者。我们将采用一种自上而下的方法先对这两篇文章进行简要介绍。</p>

<p><strong> 概述</strong></p>

<p>有关Kinect的结构光技术读者可以参考这篇<a href="http://www.hanyi.name/blog/?p=335">文章</a>或直接去Google下PrimeSense的专利，这里不再赘述。不过，尽管Kinect在获取深度图方面几乎是达到了性能与质量的完美结合，但仍无法避免深度图中大量抖动的产生，如果我们直接对单张深度图进行bilateral filter双边滤波然后重建出网格模型，会发现重建出的模型表面质量较低，甚至出现孔洞的情况。更重要的是，单张深度图能够获得的只是模型在某个视角下所展现出的一部分，而非表示完整的模型。因此，如何改善基于Kinect深度图的模型重建质量，并实现物体的完整重建成为该项技术的关键。</p>

<p>KinectFusion的首要任务就是克服该难题，它允许用户手持Kinect设备在室内场景自由移动，并实现场景的高质量三维重建。同时，KinectFusion还提供了精彩的AR应用，包括前景、背景和人体的分割与重建、以及AR世界中的多点触摸识别技术。</p>

<p><strong>场景重建</strong></p>

<p>基于上述需求，KinectFusion允许用户手持Kinect设备自由探索室内环境，系统将自动跟踪Kinect摄像头的6DOF姿态，然后融合不同时序的深度图数据并重建出场景的全局模型。由于视角的不断变化，Kinect反馈的深度图也会发生改变，这里采用了类似图像超分辨率技术对深度图进行了细节优化，从而提高模型的重建质量。最后利用Kinect自带的RGB数据进行场景纹理映射。</p>

<p>首先如何利用单Kinect摄像头去跟踪它自己的6DOF姿态？这里采用点云模型的刚性配准对齐来计算摄像头在空间中的6DOF变换，点云配准首选经典的ICP[Besl92, RusinKiewicz01]。之前需要将深度图像数据变换至摄像机的空间坐标系中，并计算其对应点的法线信息；然后逐帧采用基于GPU的ICP实现进行模型配准和6DOF计算；在重建部分，KinectFusion并没有直接融合点云或生成网格模型，而是采用了[Curless96]的体集成算法，最终在全局坐标系中生成一个三维体素网格并进行不断更新，每个体素内最终保存了一段时间内从该体素到物理表面上某一点的平均距离。最后使用Raycast给出隐式表面的渲染结果，另一方面，以摄像机位置作为视点做Raycasting，同样能够得到一个具有真实细节的高质量的合成深度图，然后再对其进行下一轮ICP迭代。这就允许我们能够利用合成深度图与下一帧的深度图进行配准，使重建结果的精度不断提高。</p>

<p>具体算法实现采用了CUDA并行架构，算法基本流程如下：</p>

<p>1）深度坐标变换，对于每个像素启用一只CUDA线程，给定一个Kinect红外摄像头的内部校准矩阵K，使用如下公式</p>

<p><img class="aligncenter" title="\textup{v}_{i}(u) = \textup{D}_{i}(u)\textup{K}^{-1}[u ,1]" src="http://latex.codecogs.com/gif.latex?\textup{v}_{i}(u) = \textup{D}_{i}(u)\textup{K}^{-1}[u ,1]" alt="" /></p>

<p>计算坐标变换；相应的顶点法线则直接取其右、下邻向量的外积，并进行归一化。时间i时的6DOF摄像机姿态使用一个刚性变换矩阵T表示，其中T包括了摄像机的旋转矩阵R和平移矩阵t。变换后的顶点和法线通过T即可再变换至全局坐标系中。</p>

<p>2）摄像机跟踪，该部分的主要目的就是计算6DOF姿态。核心的ICP即迭代最近点算法，首要是需要逐帧计算不同朝向的点集的相关度。这里采用了projective data association方法计算相关度。</p>

<p>3）体集成，针对已配准的点云数据，需要执行后续的融合处理，这里采用了经典的[Curless96]体集成方法融合这些点云数据。</p>

<p>4）光线投射渲染，采用光线投射渲染前步生成的隐式表面。</p>

<p>上述整个管线均采用了并行GPU实现，在下文中，我们将重点解析上述算法的CUDA实现细节。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TangleTracer(Basic edition/B) 1.0 beta开源发布]]></title>
    <link href="http://www.hanyi.name/blog/2012/06/08/tangletacerbasic-editionb-1-0-TangleTracer-Basic-edition-B-1-0-beta-kai/"/>
    <updated>2012-06-08T22:32:17+08:00</updated>
    <id>http://www.hanyi.name/blog/2012/06/08/tangletacerbasic-editionb-1-0-TangleTracer-Basic-edition-B-1-0-beta-kai</id>
    <content type="html"><![CDATA[<p>TangleTracer是一个实验性光线跟踪渲染平台，目的在于为真实感绘制技术的初学者提供完备的学习例程和友好的实验接口。系统设计思路主要源于Kevin Suffern的《Ray tracing from the Ground Up》一书，同时部分参考了著名的真实感绘制圣经《PBRT 2nd》。从今年三月中旬起我们就开始了前期的技术储备工作，该项目由四月初正式开始，截至目前完成代码近9万行，系统框架基本完善，实现并调试通过了440个demo或Kevin书中的习题（这部分代码超过4万行）。与K书中提供的原型系统不同，项目开发平台选择了Microsoft Visual Studio 2010和Qt framework 4.7.3，为快速开发提供了良好基础。
由于系统和部分框架来源于K书，我们循例采用GPLv2开源发布。此次发布的主要内容是系统的代码部分，为便于大家测试，我们稍后会提供基于win32平台的二进制版本（目前正在进行兼容性测试），运行系统内置的全部例程需要同时满足以下条件：
1.下载例程所需的纹理包：<a href="http://www.raytracegroundup.com/downloads/TextureImages.zip%EF%BC%9B">http://www.raytracegroundup.com/downloads/TextureImages.zip%EF%BC%9B</a>
2.下载例程所需的模型包：<a href="http://www.raytracegroundup.com/downloads/PLYFiles.zip%EF%BC%9B">http://www.raytracegroundup.com/downloads/PLYFiles.zip%EF%BC%9B</a>
3.确保纹理包的TextureFiles目录和模型包的PLYFiles目录与程序二进制文件位于同一目录下；
4.部分模型需要下载stanford的原始文件并进行替换（具体请阅读README及代码注释）：<a href="http://www-graphics.stanford.edu/data/3Dscanrep/%EF%BC%9B">http://www-graphics.stanford.edu/data/3Dscanrep/%EF%BC%9B</a>
此次发布的是TangleTracer的Basic edition/B版本，其目的在于提供思路清晰的CPU渲染技术，但实际渲染性能较低。我们正在进行系统的并行迁移实现，并力求在下半年提供TangleTracer的GPU edition/G版本。详情请关注项目github主页：<a href="http://mp77.github.com%E3%80%82">http://mp77.github.com%E3%80%82</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《武训传》的现实意义]]></title>
    <link href="http://www.hanyi.name/blog/2012/03/25/wu-xun-chuan-de-xian-shi-yi-yi/"/>
    <updated>2012-03-25T02:33:30+08:00</updated>
    <id>http://www.hanyi.name/blog/2012/03/25/wu-xun-chuan-de-xian-shi-yi-yi</id>
    <content type="html"><![CDATA[<p>我对所谓的“国产禁片”并不感冒。其原因在于真正要被禁的影片根本不可能启动拍摄，而已经拍出来的所谓“禁片”注定是褪去了核心思想的阉货，顶多被允许在课堂上当教学片放，还需得是遮遮掩掩的那种。不过，当听到《武训传》要出数码修复版时又不禁小兴奋了一下，突然对这部筹划于上世纪四十年代初、成片于1950年并在中国当代史上扮演了重要角色的“第一禁片”十分好奇起来。尽管寻找片源时颇费了一番周折，好在终于在周末第一次看完时长197分钟的全片。</p>

<p>使我对该片产生好奇的第一个问题是，《武训传》在今天仍不失影响力，那么是因为传主事迹确实称得上“感天动地”、堪得流芳百年？还是由于该片后来“意外地”成为了首个思想文化批判与改造运动的漩涡中心，以致于迄今为止仍有许多人们念念不忘，难以释怀？我们知道，影片创作最初源于民国著名教育家陶行知先生对“武训精神”的推崇和力行，并随段承泽和漫画家孙之俊两位先生的《武训先生画传》而广为人知（1950年李士钊和孙之俊又重新出版了一套《武训画传》）。据《武训画传》载，武训（武七）幼年丧父，与母亲以讨饭为生，年少时先后在自己的姨夫家和李地主家做工，饱受欺辱。由于没上过学，被地主骗光了三年工钱。经过几番沉重打击后，武训意识到只有读书才能改变穷孩子们的命运，才能真正帮助穷人摆脱这种不公正。经过近四十年行乞的勤劳与节俭，武训先后创办“崇贤”、“杨二庄”以及“御使巷”三家义塾，免费供贫困子弟上学。武训事迹轰动山东，最终得到清廷嘉奖并授予“义学正”。总的来说，武训事迹是真其人、确其事的贫民教育典范，理应作传以传后世。不过，当漫画版传记到银幕则产生了原因复杂到令人难以理解的后果。</p>

<p>昆仑公司出品的《武训传》成片于1950年，实际上影片曾断断续续拍了几年时间，周恩来等领导人都曾经对拍摄中的剧本进行了修改和建议。不过，影片的编导对原《画传》的核心思想进行了改编，我认为这恐怕是为创作团队带来日后横祸的重要原因，但也不得不佩服孙瑜导演及其他主创对待文艺创作的理性态度和勇气。影片新引入的一条主要线索是前太平军周大的经历，北伐失利的周大与武训一同在张举人家里做工，最终与武训共同逃离，不过他的选择和武训大相径庭，后者选择兴办“义学”，而周大则去做了响马，其理想是将地主“抢光”、“杀光”，有意影射清末数量庞大的农民起义运动。影片中武训的态度很清楚：“读书改变命运”，一味烧杀并不能解决问题。但在片末，农民运动达到了高潮，响马们履行诺言回来复仇，武训看着一切只能又标志性地挠了挠头，但影片没有给出事件的最后结局。批判者指责影片推崇“改良”，在某种程度上说并不完全错误，同时这也是至今影片仍存争议的原因。不过，关于所谓的“路线”争执是自百年前至今都确实存在的，只是取决于我们怎样对待这种应当仅存于学术层面的争论。</p>

<p>然而影片中武训的担心也未必没有道理，当狂热到丧失理性之时，原本就缺乏思考的人们会变成怎样可怕的怪兽？君不见，当代中国又横遭了多少磨难？我对影片与《画传》的一处细节差别印象深刻，首先片中强调“张举人”的读书人身份，后来又编出什么“没收武训所积造文昌帝庙，以明读书人之修身齐家的志愿”？读书人是不完美，但人始终无完人，影片着重渲染了一干“读书轻义”的当权者，与武训到处跪求贫困家庭送子入学形成了明显矛盾，尽管片中也给出了几个开明乡绅的形象。而当武训听到对“学而优则仕”的解释时又大为困惑起来，是顺带批评了当时的知识分子么？可见，影片所带给人的思考余地是非常广阔的。</p>

<p>现在回去看《武训传》所遭遇的不公正待遇，我认为这正是影片创作者们的担心终成现实的结果，甚至可能丝毫不出他们所预料。当然恐怕有更多的人宁愿相信这些卓越的文艺创作者们是犯了某些错误，至少是某一“特定历史时期”下的错误。但我始终觉得这些说辞只会是无力面对历史的辩解之词，看似轻描淡写，实则是一个讳疾忌医的病人罢了。</p>

<p>最后，针对《武训传》的当代史研究在最近30多年里已经著述颇丰，我认为要了解一段历史，必须行史学家的态度去阅读文献，在此之前不应轻下结论，否则必然是一叶障目。本文不提非官方的野史故事，理由一是资料真假难辨，有失严谨；二是希望现今的人们能继续从本质上对武训及这部影片展开讨论，当然这种讨论必须是完全理性的、有意义的观点和看法。尽管我们长久以来避而不谈，但历史终究会使我们不得不去思考，今后的路朝哪里走。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[参数化设计/建模及其在艺术创作领域的应用前景]]></title>
    <link href="http://www.hanyi.name/blog/2012/02/02/can-shu-hua-she-ji-jian-mo-ji-qi-zai-yi-shu-chuang-zuo-ling-yu-de-ying-yong-qian-jing/"/>
    <updated>2012-02-02T20:58:30+08:00</updated>
    <id>http://www.hanyi.name/blog/2012/02/02/can-shu-hua-she-ji-jian-mo-ji-qi-zai-yi-shu-chuang-zuo-ling-yu-de-ying-yong-qian-jing</id>
    <content type="html"><![CDATA[<p><strong>一、概述</strong></p>

<p>迄今为止，参数化设计/建模仍代表一种理念，尽管这种理念已经经历了CAD/CAM近五十年的发展历程。系统化的CAD/CAM技术包含两种基本思路，一是使用二维几何原语如点、线或样条表示三维物体，如Bezier、De Casteljau以及Sutherland这些先驱们的工作；明暗处理的需求接着被提出，从而出现了早期着色模型的研究（本文将不涉及这部分内容）；即使是目前最广泛使用的Nurbs，也是A.R. Forrest早在1980年就已经完成了。</p>

<p>另一种思路是使用体素构造表示（CSG）进行实体建模（该技术实际上也诞生于60年代初期），其基本方法是使用一组基本几何体，如球、柱体、椎体等，对其执行交、并、补等布尔运算序列，从而构建复杂三维物体，通常再使用B-Reps表示最终生成的三维模型。这种方法由于能够保持模型拓扑的欧拉示性数V-F+E，有助于满足三维物体的基本几何特征，因而得到了广泛应用。</p>

<p>现在看来，CAD/CAM的关键技术似乎早在30年前就已经比较完整了，那么继续该领域的研究还存在哪些意义？事实上，CAD/CAM目前仍面临许多瓶颈，这些瓶颈已经影响了目前广泛采用此类技术的汽车制造、电子和建筑等行业的进一步发展。例如面向三维模型的可编辑性，模型编辑的目的通常有两类：一是用户设计意图发生变化，需要变更现有设计；二是模型的适用条件发生变化，不得不做出调整以适应新变化：如某些工业组件所面临的不同规格需求。在参数化设计提出之前，针对三维模型的编辑主要采用直观交互式的方法进行，其复杂程度甚至超过最初的建模过程。一些行业专家分析，模型编辑的主要难点在于该过程既要保持原组件的局部特征，还要适应新的条件，同时还要确保这种编辑不会影响组件之间的相互关系；特别重要的是，在整个设计、建模、编辑的过程中要保证一定的数据精度。提高可编辑性一度成为现有CAD/CAM技术的重要研究方向。</p>

<p><strong>二、参数化设计的发展和现状</strong></p>

<p>参数化设计的最初目标就是解决CAD/CAM的上述问题，并取得了一定成果，特别是在建筑业。参数化设计的本质就是使用一系列参数定义三维模型的基本特征，包括基本尺寸、各组件间关系等。在一些文献中，参数化设计也被称为关系型建模或是变量化设计。在参数化设计中，建模原语通过一组参数表示，如使用位置、长度和方向参数表示空间线段，而如果仅涉及到这部分，那么参数化设计似乎与传统的交互式设计并无不同。更进一步，为了保证模型在一定条件下的可编辑性，参数化设计要求用户建立建模规则的参数化表示。如AutoDesk推出的AutoLisp语言，实际上是通过编写脚本制定规则，而把输入参数转化成三维模型的应用在目前已经十分流行了。然而对于绝大多数设计师而言，学习编程语言其实没有太多必要，同样对于一些复杂模型的构造，编程实现会真正意味着缘木求鱼。因此参数化设计需要进一步的形式化、领域化和直观化，才有可能被大多数设计师所接受。</p>

<p>“约束”是参数化设计的一个重要概念，不过其提出要比“参数化设计”本身还早。约束表示针对一个或一组实体的行为关系限定。实体可看作是三维模型的一个组件，实体行为则代表该组件在不同参数下表现出的状态。例如&#8221;一组线段相互平行、垂直或共线&#8221;就是一种约束描述，每条线段受相应参数控制其行为，而各线段的参数却受到“平行、垂直或共线”的关系限定。在带约束的设计和建模过程中，无论是施约束端还是受约束端，都需要得到完整的参数列表才能进行，由于约束的存在，某些参数实际上需要通过“推理”进行估计和计算，这种推理估算参数的过程在很大程度上影响了建模效率。当前应用中普遍存在两类约束：几何约束和物理或称工程约束。平行、垂直、共线、相邻、尺寸等都属于几何约束，此外包括一些物理方程、条件关系等则属于后者。这类方法需要用户在建模初期提供实体类型、空间位置和尺寸参数，然后通过一些具体方法描述实体关系，如前面所述的编程脚本。</p>

<p>1982年，Gossard和Light首次提出了“变量化设计”的概念。此后十年间，由于几何造型、自由曲面和实体建模技术的迅速发展，出现了愈多针对交互性及可编辑性的改进需求。大量工作开始致力于该领域中，如前面介绍的变量化编程的提出，通过编写一段程序脚本控制建模过程，这种方法实际上并不能有效解决存在的问题。而为了保证用户设计意图的准确实现，直观交互通常是必须的，因此提供领域化的参数化设计工具是较为合理的选择。</p>

<p>1、基于时序的约束建模，即记录用户交互式建模时产生的参数集时序变化，在修正设计时，通过随机选取并更改时序中的参数变化内容，实现参数化设计。这种方法要求模型的构建过程保证良好的层次性；</p>

<p>2、变量几何和变量化设计，即通过构建基于参变量的建模公式进行参数化设计，例如利用简单解析式创建二次曲面。对于复杂模型而言，其构建公式的有效性就成为实现参数化设计的基础；</p>

<p>3、基于规则的变量化设计，前面两种方法在实际应用中很难真正实现，出于实用的考虑，人们首先建立基本规则库，利用人工智能方法进行推理并最终得出约束条件。例如，对于两个实体而言，系统内置了有关实体位置参数的规则，通过推理即可得出实体间的相对位置关系（对于直线段可能就是平行、垂直、共线、相交或其它情况）。实际上，该方法目前仍是参数化设计的研究热点之一；</p>

<p>4、基于特征的参数化设计，从视觉上看，特征指模型在某些观察角度下所呈现出的特殊现象。而在参数化设计中，特征包括了与其相关的实体、参数和关系式，特征是相对于变量或规则的更高级别的语义描述，例如描述物体表面有一处“凹陷”，这就是一种特征。但是，良好的基于特征的设计需要精心设计特征库。</p>

<p><strong>三、参数化设计的应用现状</strong></p>

<p>尽管参数化设计目前已经深入工业设计和制造业，但最令人瞩目的则是其在建筑设计领域中的应用。应注意的是，由于建筑设计本身带有艺术气质和时代特征，引领前端的通常都是著名研究机构或设计公司，而更多的从业人员仅仅是采用稍成熟方法满足需求即可，因此参数化设计在该领域存在着两种截然不同的应用思路。</p>

<p>毫无疑问，最早提出的变量化编程已经为大多数CAD建筑设计师所知了，如AutoLisp。另一方面，参数化设计在这一阶段的主要工作是实现2D和3D的协同设计，具体方法可以是时序法或变量几何。在这期间许多计算机科学家努力向领域专家们推荐各种工具和应用，如William Mitchell于1987年推出的《The Art of Computer Graphics Programming. A structured introduction for Architects and Designers》，书中使用了流行的Pascal语言描述建模脚本。</p>

<p>在许多人看来，上述编程建立三维模型的应用过于抽象，可行性极低。事实亦如此，变量化编程目前已经成为参数化设计领域的非主流技术，而对我们来说更加常见的可能就是诸如ArchiCad或3DStudio Max：直观的交互式界面，以及大量参数输入对话框，该模式至今仍占据绝对优势。后者的缺点是，用户很难针对复杂模型整体进行参数化考虑，除非建模阶段存在非常精妙的参数设计，而这往往是不现实的。一种解决方法是确保层次化建模，例如K. Martini试图采用面向对象程序设计中的层次化类结构模拟建模过程。由此我们可以联想到一系列层次化方法，如集合、树等；另一方面，考虑到层次化建模的可行性尚未得到证明，我们还可以考虑使用图表示参数化设计中实体之间的约束关系。针对这方面的讨论目前仍是非常开放的问题。</p>

<p><strong>四、艺术创作中的参数化设计思想和实践</strong></p>

<p>首先，这里所说的艺术创作实际上包括前文提到的工业设计；另一方面，我们希望能在更多的艺术设计领域引入参数化的元素，其目的在于：1、大部分现有的艺术创作实际上与商业应用相关，原创效率和大规模应用能力将成为关键的风险因素；2、参数化设计为创作前所未有的艺术形式提供了新途径，而并非字面上的对艺术创作施加“约束”的意思。</p>

<p>达芬奇的《维特鲁威人》堪称把建筑学和人体解剖学相结合的传世名著，而这种艺术上的联系同样也反映到现代CAD/CAM技术中。香港中文大学的王昌凌(Charlie C. L. Wang)就在现代服装设计中引入参数化设计技术，并提出了一种新的基于人体特征的参数化设计方法。该方法从人体点云中提取相关特征，并在参数化模型（注意这里的参数化与“参数化设计”的区别）的基础上使用参数化设计创建新的模型。其中人体模型的参数化包含两个主要阶段，首先使用激光扫描仪获取人体点云，根据语义特征提取并重构人体的特征线框；其次，对人体网格曲面的对称信息进行建模，在特征线框上通过曲线插值生成Gregory曲面片。然后利用一种体素算法在G1连续的曲面上添加细节点云；最后再调整网格曲面的对称性。在完成人体模型参数化后，根据用户输入参数采用参数化设计方法把样例模型映射至参数化模型中，同时对样例模型的选用需依据相关策略进行。与普通的数值插值函数相比，该方法具有较低的出错率，能够保证参数化模型的正确性。基于正确的参数化模型，即可在人体上自动导入使用参数化设计方法在样例模型上设计的服装模型。</p>

<p>事实上，关于服装的参数化设计在最近十年已成为CAD的热点之一，并取得了一些研究成果，但仍鲜见规模化应用。而对于参数化设计技术本身而言，能否继续扩展其应用范围、并在此过程中完善自身的方法论，将成为CAD发展的一个未知数。不过，进一步扩展出有效的杀手级应用则是当务之急。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[新海诚的云和他的孩子们]]></title>
    <link href="http://www.hanyi.name/blog/2011/12/10/xin-hai-cheng-de-yun-he-ta-de-hai-zi-men/"/>
    <updated>2011-12-10T18:34:06+08:00</updated>
    <id>http://www.hanyi.name/blog/2011/12/10/xin-hai-cheng-de-yun-he-ta-de-hai-zi-men</id>
    <content type="html"><![CDATA[<p><em>克查尔特把所有的记忆寄托在歌声里留下，歌声将改变形状一直流传着，在空气的振动中不断下去，不知不觉融合在我们的身体，如此在世界的某个地方永远留存下来。</em></p>

<p><em>[singlepic id=45 w=480 h=320 float=]</em></p>

<p>影片《追逐星星的孩子们》充满吉卜力式的风格和桥段，乍一看让人觉得影片监督和宫老有着千丝万缕的联系，然而漂浮在天空的云却在不断提醒着我们完全不同的事实。新海诚把英文片名定为《Children who Chase Lost Voices from Deep Below》，相比于日语片名恐怕更贴近故事情节，而就后者来说，来自雅戈泰的迦南族人瞬恐怕是唯一真正“追逐星星”的孩子，其余的主角么，当然是为了寻找位于菲尼斯·特拉生死门另一端的灵魂了。本片正是一部讴歌生命的唯美之作。</p>

<p>事实上，这个星球上的每一个人在新海诚眼里都是影片所讲述的孩子，自出世起就受到了来自雅戈泰神明的诅咒，从而死亡就成为生命必须的部分，灵魂最终被融入雅思特拉里。然而总会有许多人无法真正面对死亡，甚至希望故人能够得以重生。生命之船谢库纳·威玛纳的回应是要求一个完整的肉身以及一只许愿人的眼睛——这恰恰体现出一种绝对公平，所谓的复活也根本毫无意义。人类所需要做的，即是背负着愈来愈多的离别与思念度过一生，也是女主角明日菜最终意识到自己执意进入雅戈泰的原因：生活除了日复一日的单调重复，其余的就是想念了。毫无疑问的是，这次生命之旅让女主角卸下了曾经的包袱，从此更加乐观地面对生活。付出沉重代价并再次失去理莎的森崎老师也逐渐走出了十余年前亡妻的阴影。心也彻底摆脱了失去哥哥瞬的心结。</p>

<p>而对于另一个男主角瞬而言，他原本就属于跟随克查尔特在数万年前进入地下的人族后代，尽管雅戈泰人都对生命的时间线充满敬畏，而在瞬的心里，看一眼地上世界夜空中的繁星，以及那个潜意识中似曾相识的人，已是他在临死前最后的愿望。而当这种情绪达到最强烈时，歌薇丝感应到了另一个世界中的心灵，从而带瞬来到了这个世界，在临死前对明日菜进行了生命的祝福，故事也就此展开。令人感到奇怪的是，尽管瞬坦然接受了死亡结局，但依然在命运中破除了雅戈泰人的世代约定：即永不允许地上人进入这个世界，而是选择追求自由——这也是人类无止境地追逐繁星的真正意识。这恐怕是新海诚对生命从另一个角度的诠释。</p>

<p>至于片头提及的地上人的堕落，故事并没有在此展开讨论，恐怕是脚本原始设定上的一个小失误。然而《追逐星星的孩子们》给人以强烈的宫崎骏式的感官，同时又夹带了《EVA》的世界观（威达之水 vs LCL？），这让许多对新海诚充满期待的资深动漫迷们感到无法接受。但是无论如何，观影的过程是让人感到无比舒适的。</p>

<p>附惊艳片尾曲歌词《Hello Goodbye &amp; Hello》：</p>

<p>Hello Goodbye &amp; Hello</p>

<p>相遇 分别与重逢</p>

<p>词曲：熊木杏里</p>

<p>编曲：清水俊也</p>

<p>歌：熊木杏里</p>

<p>君(きみ)に会(あ)って</p>

<p>今(いま)　君(きみ)とさよなら</p>

<p>Hello goodbye and hello</p>

<p>そして君(きみ)のいない</p>

<p>この世界(せかい)にHello</p>

<p>本当(ほんとう)のさよならを</p>

<p>知(し)らなかったあの时(とき)</p>

<p>壊(こわ)れゆく心(こころ)はずっと</p>

<p>君(きみ)を探(さが)してた</p>

<p>もしも届(とど)くのならば</p>

<p>伝(つた)えたかったことがたくさんある</p>

<p>すべての気持(きも)ちで</p>

<p>君(きみ)の笑(え)み颜(かを)を</p>

<p>绝(た)やさずそばにいたいと誓(ちか)うよ</p>

<p>Hello goodbye and hello</p>

<p>君(きみ)に会(あ)って</p>

<p>今(いま)　君(きみ)にさよなら</p>

<p>Hello goodbye and hello</p>

<p>そして君(きみ)のいない</p>

<p>この世界(せかい)にHello</p>

<p>思(おも)い出(で)が温(ぬく)もりは</p>

<p>君(きみ)へと続(つづ)く糸(いと)</p>

<p>たとえても见(み)つからない</p>

<p>それだけを见(み)つけた</p>

<p>失(な)くしたくない愿(ねが)い</p>

<p>一番(いちばん)</p>

<p>远(とお)い星(ほし)だと思(おも)ったよ</p>

<p>空(そら)は広(ひろ)がる</p>

<p>明日(あす)のように</p>

<p>果(は)てないけれど手(て)を伸(の)ばしたいよ</p>

<p>Hello goodbye and hello</p>

<p>君(きみ)の事(こと)を</p>

<p>いつも忘(わす)れないよ</p>

<p>Hello goodbye and hello</p>

<p>そしてこの道(みち)を</p>

<p>歩(ある)いてゆくなあ</p>

<p>君(きみ)を好(す)きになった时(とき)から</p>

<p>始(はじ)まていたこの旅(たび)&hellip;</p>

<p>Hello goodbye and hello</p>

<p>君(きみ)に会(あ)って</p>

<p>今(いま)　君(きみ)とさよなら</p>

<p>Hello goodbye and hello</p>

<p>そして君(きみ)のいない</p>

<p>この世界(せかい)にHello</p>

<p>Hello goodbye and hello</p>

<p>君(きみ)に会(あ)って</p>

<p>今(いま)　君(きみ)にさよなら</p>

<p>Hello goodbye and hello</p>

<p>そして君(きみ)のいない</p>

<p>この世界(せかい)にHello</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[有关Beta 2和Kinect for Windows商用前瞻]]></title>
    <link href="http://www.hanyi.name/blog/2011/11/13/you-guan-Beta-2-he-Kinect-for-Windows-shang-yong-qian-zhan/"/>
    <updated>2011-11-13T00:07:03+08:00</updated>
    <id>http://www.hanyi.name/blog/2011/11/13/you-guan-Beta-2-he-Kinect-for-Windows-shang-yong-qian-zhan</id>
    <content type="html"><![CDATA[<p>在本月初Kinect正式发布一周年之际，微软公司副总裁Frank X. Shaw在公司官方博客上发表纪念文章“<a href="http://blogs.technet.com/b/microsoft_blog/archive/2011/10/31/feeling-the-kinect-effect.aspx" target="_blank">Feeling the Kinect Effect</a>”，并透露Kinect的商用计划“Kinect for Windows commercial program”，该项目将于2012年初正式公布。文章称专门负责商用计划的团队已获得来自超过25个国家的知名公司共超过200项商业应用申请，这些应用覆盖了20多个不同领域，这恐怕会令即将到来的2012年成为名副其实的“Kinect年”。</p>

<p>而在上个月27号，微软注册了kinectforwindows.org域名并将其作为Kinect for Windows项目新的官方网站，紧接着Kinect for Windows SDK 1.0 Beta 2在本月5号正式发布。相较于8月份后就再没更新过的Beta 1，新版本SDK在以下功能上进行了持续改进：</p>

<p>1、骨骼跟踪功能得到显著增强，在跟踪精度、计算和传输性能上有了明显提升。此外骨骼跟踪现在能够正确支持多核处理器，在同时使用2个Kinect时，开发人员也可以指定专门用于骨骼跟踪的设备了；</p>

<p>2、API现在能够对设备的状态进行有效检测和管理了，例如device unplugged, device plugged in, power unplugged等，这样应用程序就能在系统从待机状态恢复时自动重新连接设备了。一个很好的程序示例被写进了新版本的Shape Game Demo里；</p>

<p>3、在WPF程序中使用语音功能的开发人员不需要从额外的线程访问DMO了，现在可以直接从UI线程创建KinectAudioSource，从而能够简化现有工程的代码。</p>

<p>4、新的驱动程序、运行时系统和SDK现在能够在<strong>Windows 8 Developer Preview</strong>中使用了。</p>

<p>5、现在能直接创建64位应用程序；</p>

<p>6、NuiImageBuffer被新的INuiFrameTexture代替,新定义在MSR_NuiImageCamera.h中，现有项目不再需要引用NuiImageBuffer.h了；</p>

<p>7、安装目录的结构进行了调整，现在的安装路径使用环境变量%KINECTSDK_DIR%定义，默认值为C:\Program Files\Microsoft SDKs\Kinect\v1.0 Beta2；</p>

<p>8、示例代码的更改包括：</p>

<p>一个新的C#程序示例：KinectAudioDemo；</p>

<p>示例程序现在被默认安装在C:\Program Files\Microsoft SDKs\Kinect\v1.0 Beta2\Samples，你需要Unzip以便查看源代码，而这里建议将源码Unzip到Program Files以外的目录去；</p>

<p>9、驱动程序和运行时系统的稳定性和性能进一步提升，<strong>尤其是在托管API层</strong>。</p>

<p>总的来看，Beta 2并未提供关键功能上的改进，更多是对现有问题的修正。此外，备受瞩目的Kinect for Windows杀手级应用仍未出现，社区反馈是目前很多未公开的商业项目在尝试OpenNI，对MS SDK反倒比较谨慎。不过从长远角度考虑，MS SDK在开发社区、系统平台和资源支撑方面拥有众多优势，明年商业化后必然会率先占据有利位置。由此联想到近期在4S上被热炒的Siri，看来自然交互的春天真的离我们不远了。</p>
]]></content>
  </entry>
  
</feed>
