<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 软件架构 | Wing of Dream 梦境之翼]]></title>
  <link href="http://www.hanyi.name/blog/categories/ruan-jian-jia-gou/atom.xml" rel="self"/>
  <link href="http://www.hanyi.name/"/>
  <updated>2015-05-27T10:07:34+08:00</updated>
  <id>http://www.hanyi.name/</id>
  <author>
    <name><![CDATA[Han Yi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[microservices陷阱: 部署微服务]]></title>
    <link href="http://www.hanyi.name/blog/2015/05/19/microservices-trap-deployment/"/>
    <updated>2015-05-19T09:44:53+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/05/19/microservices-trap-deployment</id>
    <content type="html"><![CDATA[<p>对于单一系统而言，无论采用何种形式，基本的部署工作流是显而易见的。然而一旦采用微服务架构，服务间的相互依赖性会导致现有工作流发生混乱，这肯定是我们都不愿意看到的。本文谨对此展开讨论。</p>

<h3>1.持续集成（CI）和持续交付（CD）</h3>

<p>CI的核心目标是保证团队成员进行良好的同步协作。其工作方式通常是检查代码更新状态、获取最新代码并且编译和运行测试。CI的产出物通常是可用于直接进行部署或进一步测试的软件包，理想的情况是所有环境的部署都采用同一个软件包，也就是对于CI只产生唯一的交付物。</p>

<p>值得一提的是，采用CI工具和实践CI方法完全是两回事，例如：保证每天都能合并到主干、保证代码更新都有足够的测试、保证CI持续运行是团队第一要务等等，以上实践能充分发挥CI工具的效用。</p>

<p>CD则把CI和更多软件开发实践结合在一起，例如流水线、自动化部署、以及运维等，从而有效降低项目风险，提高团队效率。</p>

<h3>2.CI与微服务</h3>

<p>当采用微服务架构时，如何与CI结合则成为眼前的工作。最简单的实践可能是，把所有服务存储在同一个代码库中，任何提交都会出发任何服务的构建、测试乃至生成部署包。然而该做法是十分浪费的选择，简单改进是增加构建脚本的复杂度，在代码check out后，针对每个服务，由不同的工作流负责构建相应微服务，从而节约资源。</p>

<p>当微服务扩展至不同团队后，共享代码库的方式可能会带来很多问题，这时就需要直接拆分代码库、实现工作流－微服务一一对应的结构了。</p>

<h4>架构演进对CI的影响</h4>

<p>值得一提的是，CI工作流的设计应和应用架构保持一致。也就是说，在初创项目时期很可能都会是一个单独的代码库，CI的结构也应当比较简单。随着领域模型的逐渐建立和API保持稳定，划分服务并且分别构建会是自然的选择。</p>

<h4>特定平台的交付包</h4>

<p>鉴于微服务允许采用不同的技术栈实现，Jar/War、Gem、Egg等区别导致了CI技术的丰富性，实际上也增加了CI实践的复杂度。因此，采用现代配置管理工具如Chef、Ansible则是必须的。另一方面，当把上述各种不同的技术部署上线时，对配置管理的依赖就更加重要了。</p>

<h4>操作系统交付包</h4>

<p>在实践中，自动配置管理面临着跨平台的挑战。即使是面向Linux，也存在发行版之间差异的问题。如果把配置管理的结果从线上环境变为Rpm、Deb、甚至MSI包，则就大幅度降低了操作系统差异所带来的挑战。当然，最好还是尽量在线上环境采用统一的平台为好。</p>

<h4>自定义镜像</h4>

<p>自定义镜像的好处是，我们不再直接在环境上运行配置管理工具，而是在本地构建好虚拟环境，部署好应用，然后再打成镜像包发布，从而节约了线上部署的繁冗时间，消除此举给线上环境带来的潜在问题。虽然说节约时间，但生成镜像依然是十分耗时的工作，好在现有的配置管理工具几乎都支持VMWare、AWS AMI、Rackspace、Digital Ocean、以及Vagrant打包，你需要做的只是本地运行一遍脚本，然后随时发布镜像包即可。</p>

<h4>镜像即交付包</h4>

<p>当采用镜像部署成为常态，一个合理的选择是把镜像包作为交付物融入CI/CD工作流，真正实现业务和基础设施的分离。</p>

<h4>服务器的不变性</h4>

<p>如果你发现每次运行部署之后，都需要人工检查并修改某些已有配置时，那就意味着配置管理发生了偏差。这种情况发生的原因通常是服务器配置环境发生了变化，而应对措施是尽量不要人工维护或修改环境配置。一个好的实践是在每次代码更新都创建全新的镜像。当然也会损失一些时间成本。</p>

<h3>3.CD与微服务</h3>

<p>当微服务运行在CD工作流中时，需要注意更多潜在的问题。</p>

<h4>环境</h4>

<p>在CD实践中，我们通常会遇到Slow Tests、UAT、Performance Tests分别部署在不同环境上的例子，针对单一系统管理上述环境本身就是一个挑战。而当这些遇到微服务，其规模和工作量就可想而知了。
环境问题本质上还是配置管理的方式，当不同微服务所需环境互不相同时，选择合理的部署方式则变的非常重要。例如对每个环境构建一个交付包，同时包含环境配置文件，当部署时同时部署代码和配置&hellip;一切看起来顺理成章，但似乎有些违背CD的原则，特别是唯一交付物原则。这就会导致多环境带来的风险削弱好处大幅丧失。另一方面，合并交付包带来的效率、安全等问题是不得不考虑的。
一种较好的实践是通过一个统一的交付包单独管理不同环境下的配置文件，或是采用配置管理系统——这对微服务而言显得尤为必要。</p>

<h4>服务－主机映射</h4>

<p>部署的另一个问题就是，一个物理机（或容器）上能运行多少服务？面对不同的选项，部署方案也会有所区别。</p>

<p>首先是多服务－单主机模式，好处是简单、方便、成本低。困难在于，监控复杂、服务部署流程也会遇到很多问题，例如如何保证不同服务间的部署代码不存在冲突，而这在微服务系统中并不少见。</p>

<p>其次是应用容器模式，这里的应用容器主要是指.Net或Java Servlet Container等充当应用服务器的容器，适当的统一能避免冲突，但也会带来一些限制。服务间的独立性也难以保证。</p>

<p>单服务－单主机模式，该方法类似于把应用部署在一个类PaaS系统上，当然灵活性也比商用PaaS高，彻底独立带来的好处就是微服务的优势，成本也是显而易见。</p>

<p>PaaS模式，更加简单、便捷的方式，缺点是灵活度低，特别是当需要触及底层改动时，PaaS显得无能为力，但从宏观上说确实是一个发展趋势。</p>

<h4>自动化</h4>

<p>自动化的优势贯穿本文始终，也是微服务技术发展的核心。如果不能实现自动化，微服务提供的各种实践就无法带来任何收益。因此微服务部署的方向就是：一切自动化。</p>

<h3>4.虚拟化</h3>

<p>实现可扩展的现行趋势就是虚拟化。虚拟化能够带来隔离、提高资源利用率等好处，但随着资源利用需求的提高，传统虚拟化显得力不从心。其中共有两种类型的虚拟化，一类是直接基于硬件的虚拟化，另一种是构建在操作系统上，采用层级架构实现的虚拟化，如AWS、VMWare、VSphere、Xen和KVM，这些虚拟机实例基于hypervisor之上，由后者提供资源分配和调度，并向上层应用提供支撑。可以看到，hypervisor承担着核心且重要的任务，其本身的资源需求就很可观。</p>

<h4>Vagrant</h4>

<p>Vagrant本质上只是一个部署平台，其更多用于开发和测试环境而非产品环境。Vagrant方便在本地构建一个虚拟云，能够尽可能真实的模拟在AWS上的线上虚拟环境。然而由于Vagrant实际还是基于虚拟机应用如VirtualBox或VMware，其所占用的资源是相当可观的。特别是在开发环境，开发人员在本地几乎不可能模拟一套完整的生产环境，因此合适的stub仍然十分必要。</p>

<h4>Linux容器</h4>

<p>Linux容器的目标是进一步榨取系统资源，实现原理却很简单：每个容器都基于内核进程fork，并且自身形成一个进程子树。除了LXC，像Solaris Zones、OpenVZ这些都是类似概念的实现，但没有前者更出名。LXC的好处是省去了hypervisor（但并不意味着它就不需要此类功能），相比VM更加轻量、高效。同时容器还提供了更细粒度的资源配置选项。
不过容器也并非灵丹妙药，相比VM而言只是换了一个载体，在正式项目中，你仍然会遇到hypervisor、routing，甚至security等各种挑战，且并不比解决VM来的容易。</p>

<h4>Docker</h4>

<p>本质上Docker只是一个构建在轻量容器之上的集成平台，它的好处在于一次性集成了容器provision、network、storage和version等功能，面向用户更加友好，并使得容器技术逐渐普及。
与VM相比，Docker具有容器所拥有的所有优势，同时正在产生一个完整的生态圈，例如CoreOS。Docker面临的挑战也等同于容器，特别是当你真正需要采用Docker搭建PaaS时，毕竟Docker本身几乎没有解决任何已有的技术问题。目前能够帮助用户解决重点问题的包括Google的Kubernetes、CoreOS的集群技术、甚至Deis这种直接提供基于Docker的PaaS平台，就像Heroku一样。</p>

<p>Docker可能解决长期困扰PaaS方案的一系列问题，例如缺少自定义特性（类似Heroku这种已经算做得不错），当PaaS的provision完全向用户放开，且不失易用性，其可选度才真正高于IaaS，Docker目前是这一趋势的有力支撑。</p>

<h3>5.采用一致的部署界面</h3>

<p>微服务部署与普通部署并无二致，同样需要解决横向扩展、相互依赖等问题，而采用一致的部署界面能有效提高效率，无论是基于Windows Powershell、batch、bash、Python Fabric或Ruby Capistrano等各类平台。一般来说部署界面应包含以下内容：</p>

<h4>1.实体名称</h4>

<p>部署对象的名称，例如微服务名。</p>

<h4>2.实体版本</h4>

<h4>3.部署环境</h4>

<p>例如：“deploy artifact=catalog environment=local version=local”。</p>

<p>部署界面的另一个重要部分是环境管理，环境管理的具体内容主要是一些provision的配置信息，部署工具应不限于provision工具的选择，包括puppet、chef或是ansible。</p>

<p>当前，在Deployment和Provision之间依然存在着缝隙，且其中的界限还不明确。例如对于Provision Heroku、或者AWS，或者Provision和Deployment间的相互依赖问题的解决，还缺少一个有效且一致的方案。Terraform看起来是一个潜在的选择。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[microservices陷阱: 切割单一系统]]></title>
    <link href="http://www.hanyi.name/blog/2015/04/13/microservices-trap-splitting/"/>
    <updated>2015-04-13T08:44:04+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/04/13/microservices-trap-splitting</id>
    <content type="html"><![CDATA[<p>前面已经提到，构建microservices的第一步即划分服务边界，而对新系统直接进行边界划分具有相当的风险，且通常是不被鼓励的。我们建议选择一个较成熟的codebase再进行服务切割。</p>

<h3>1.辨识服务边界</h3>

<p>面对已有系统，首先需要做的就是辨识其中隐藏的服务边界。在《Working Effectively with Legacy Code》中，提到架构“缝隙”的概念。我们几乎可以把“缝隙”和“边界”等同起来，实际上DDD中的服务边界即一种好的“缝隙”。那么如何找到“缝隙”则是面对遗留代码所需的第一站。
许多编程语言提供一种自然的封装方式，比如namespace，java的package也拥有类似的概念，当然并非所有语言如此（如javascript）。
在进入代码之前，首先应该至少理解高级别的边界上下文抽象O，这将有利于我们进行逐渐向下的切割。当拥有O后（当然O可能并不完美，但这不是必须的），我们可以逐步把代码移动至相应的O&#8217;中。在这一过程中通常就能发现其中存在的问题，比如更细粒度级别的边界、错误的依赖、以及其它，借助代码分析工具可能会提高一部分工作效率。
当然，面对小型系统，你可以指望在数天、甚至一天内完成全部分析工作，但是多数情况下这可能是数周、或数月的付出。因此还应注意任务分解、确定优先级、循序渐进地切割新服务。</p>

<h4>切割单一系统的好处</h4>

<p>尽管前文已经无数次提到，但这里还是简单做一下总结：相互独立的自治单元更易实现变更、根据所属服务划分团队职责、针对特定服务的安全性增强、技术更新更加频繁&hellip;所有以上会是单一系统经过合理切割之后带来的好处，然而如果你不确定这些是否真的对你有“帮助”，还是谨慎一些比较好。</p>

<h3>2.解决依赖缠绕</h3>

<p>当切割服务边界时，如何处理新旧系统之间的依赖缠绕则成为随之而来的问题。前文提到过建模工具，它能更容易地让你发现设计是否基于有向无环图从而避免了明显的缠绕关系。当然，实践表明几乎所有的缠绕都和数据库模式相关。事实上到目前为止，切割服务就像是纸上谈兵，数据库才是大boss。
基于之前的实践，首先尝试依照服务把repository层进行垂直切割，也就是分表。SchemaSpy等类似的工具能够根据代码生成类UML的可视化分析结果，从而提高理解程度。</p>

<h4>解除外键关系</h4>

<p>如果确实存在外键依赖，唯一能做的就是自己维护一个与外键类似的字段，然后按需要手动解决一致性问题（这通常与业务有关，也就是说，有时需求根本不要求强一致性）。</p>

<h4>静态共享数据</h4>

<p>例如国家代码、区划等数据，一般来说有三种解决途径：在多个服务间实现冗余拷贝；通过静态配置文件消除代码和数据；或者直接建立独立服务，并在代码中内嵌静态数据。多数情况下，静态文件会是一种最简便的解决方法。</p>

<h4>动态共享数据</h4>

<p>此类数据比外键关系更为复杂，实际上出现的几率也更高。对于此类情况，通常是由于数据库中隐含了某种领域概念，而实际上这种领域概念理应由代码直接表示出来。当抽象出该概念模型后，就可以把共享数据转变成独立服务了。</p>

<h4>动态共享表</h4>

<p>为了降低数据冗余，有时会把分属于不同领域概念的数据放在一张表中，这就是动态共享表。为了进一步划分服务边界，应允许适当的冗余，也即垂直分表，但这里的分表并非是抽象出独立服务，而是分配到不同服务中。</p>

<h3>3.重构数据库</h3>

<p>正如前文所述，切割服务确实需要重构数据库，而这一领域又少有人涉及，如《Refactoring Databases: Evolutionary Database Design》。而在预上线环境，应尽可能先部署包含两套schema的但仍然保持单一的版本，然后逐渐分离服务代码，直至成为两个不同的codebase。之所以要循序渐进，是因为隔离schema带来的第一个问题就是影响了后台数据读取操作，由原先的若干查询语句，成为API请求-查询数据库-响应模式，这就直接破坏了系统原有的事务集成特性。因此，应当在处理好这一部分之前，尽量不要独立上线新服务.</p>

<h4>事务边界</h4>

<p>在单一schema系统中，事务的好处是能轻而易举实现操作的一致性。而对分布式系统而言，事务边界被一分为众，数据一致性将面临挑战。</p>

<h4>稍后重试</h4>

<p>一致性的首要目标是处理中间出错的情况，在许多场景中，“强一致”是非必要的，而通常我们仅要求“最终一致性”。在这种情况下，可以设置一个队列或日志文件，存储数据库操作及其状态，并对出错操作进行特殊标记，稍后重试该操作，直到数据成功写入。该方法的前提是假设重试操作必然有效。</p>

<h4>全局操作中断</h4>

<p>数据回滚是另一种解决方案，但需要另维护一份回滚代码，从而保证错误数据被及时清除。问题在于保证回滚代码能够正确执行，可能需要采用前一种不断重试的方法。然而随着回滚数据的增多，该方法的有效性就会降低，成本则会不断增加。</p>

<h4>分布式事务</h4>

<p>分布式事务通过设置一个中央协调进程，监控所有执行节点的状态。一旦接收到事务请求，中央进程会向所有执行节点发出投票通知，执行节点在接到通知后会检查自己的数据提交状态，成功则返回赞成票，否则反对。只有当中央进程接收到所有节点的赞成票时，才会再向所有节点发出执行通知，每个节点分别执行数据提交，这就是朴素的分布式事务“两段提交”算法。
然而分布式事务算法始终不是“绝对正确”的，比如执行节点在投“赞成”之后出错。此外，中央协调进程的存在会使得所有资源被加锁，进而存在资源竞争行为，降低系统可用性。
目前已经有一些针对分布式事务的实现，如Java的事务API。但是，分布式事务带来的副作用是必须要考虑的问题。</p>

<h4>小结</h4>

<p>保持一致性会带来更多的复杂因素，例如分布式事务会降低可用性和伸缩性。当一致性需求发生时，首先应思考它的必要性，或者采用局部事务、最终一致性加以替代。如果确实是强一致，应尽量避免切割。如果一定要切割，也可以选择设计一种混合抽象来代表事务本身，从而降低分布式事务的复杂度，进而保证可用性（例如在销售系统中，分离出一种“处理中”的订单服务，从而降低销售和库存服务之间的耦合）。</p>

<h3>4.审计报表</h3>

<p>审计报表系统是企业应用里常见的需求，而随着微服务架构的演进，该类型的系统将面临重构。在单一系统中，报表很可能只是意味着若干SQL语句的集合，顶多在架构层面增设一个读库专供报表使用，读库和主库之间采用定时同步策略。
对微服务而言，上述方法存在一定缺陷：首先，数据库schema将以服务与报表系统之间共享的形式存在，这就导致任何变更需要格外小心；其次，许多数据库提供优化能力以提高读写性能，然而当处于微服务环境时，由于数据结构的不确定性，很难在报表数据库中实现任何优化；此外，随着异构数据库架构越来越普遍，SQL、NOSQL的混合使用将使得数据融合成为新挑战。</p>

<h4>采用服务调用获取数据</h4>

<p>假设一个商业系统报表，常见需求是列出最近15分钟产生的订单。在微服务中，这可能需要跨服务的数据调用。然而，当数据体量过大时，这种方法就会变的效率低下，例如条件变为过去24个月的订单信息查询，如果采用备份数据的形式存放在报表系统中，可能会导致非一致的结果。
一种有效方案是定时从主库中提取数据到报表库（通常是一个关系型数据库），仍然有几个问题需要解决：首先，不同微服务暴露的接口可能并非报表友好的，如果硬要基于现有API，可能会导致一些其它问题，例如数据的额外处理、cache失效等等。因此在针对可能存在的大数据传输问题，一个好的办法是目标服务并不通过HTTP直接返回数据内容，而是以文件的形式转存至第三方位置，这样主服务就可以通过轮询文件生成状态从而实现HTTP的低负载通信。</p>

<h4>数据泵</h4>

<p>除了拉取数据这种方式，也可以尝试采用数据推送的办法。传统HTTP的缺点是链接耗费较高，一方面是底层协议原因，另一方面是报表系统请求的API次数较高（有时该API甚至只为报表提供服务）。一种高效方案是设立一个第三方的数据泵，其同时拥有主数据库和报表数据库的访问权限，定时把主库的更新数据同步至报表库中。该方法唯一要解决的问题就是schema的管理，而事实上，报表库的schema可以看作是published api，泵程序最好和目标服务共同由一支团队开发，这就尽可能保证了schema的同步。</p>

<h4>事件数据泵</h4>

<p>数据泵是一种有效的数据同步方案，但同步时机缺乏验证。对微服务而言，当某个服务产生状态迁移时，可通过发出一个特殊事件通知泵程序，使后者能够订阅、接收并处理相关事件，从而实现事件驱动的数据同步。此外，为了减小通信压力，报表服务可以只提取差异数据，而非全部，这就尽可能避免了广播报表更新事件与相关数据所带来的副作用。然而，这是一种有效的近实时同步报表解决方案。</p>

<h4>备份数据泵</h4>

<p>该方法被用于Netflix的报表系统中，基于现有的备份方案。Netflix采用Cassandra作为其主数据库，并在此基础上构建了许多备份服务应用（详见github）。为了备份Cassandra，常规做法是生成一份数据文件（SSTables）拷贝并存放至第三方，例如Amazon S3。报表服务是基于Hadoop实现的大数据处理框架Aegisthus，其作用与本文中数据泵的概念类似。</p>

<h3>5.小结</h3>

<h4>面向实时</h4>

<p>由于业务需求的不同，许多服务，比如dashboard、alerting、financial reports甚至user analytics都具有相互不同的时效性要求，这就导致各个服务可建立在不同的技术选项上。微服务为此提供了良好的前提条件。</p>

<h4>变更代价</h4>

<p>微服务是面向需求变更友好的，但走向微服务的过程可能是极不友好的&hellip;例如切割服务、重构数据库等工作，都存在一定的风险。我们唯一能做的就是尽量使风险最小、可控。采用白板分析设计是一个常用的办法。此外，class-responsibility-collaboration卡是个“好”工具。</p>

<h4>理解根源</h4>

<p>问题的关键在于理解为何我们需要微服务架构。在实践中，我们经常会遇到某个服务迅速变的臃肿，尽管我们可能知道这么做所带来的不良后果。改善的第一步是找准下手位置，这正是本文的目的。当你熟练于此，随后就会自然陷入到微服务庞杂且无序的内部细节中。但是相信我，第一步才是最难的。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[microservices陷阱: 实践篇(服务建模和集成)]]></title>
    <link href="http://www.hanyi.name/blog/2015/03/06/microservices-trap-practices/"/>
    <updated>2015-03-06T08:36:44+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/03/06/microservices-trap-practices</id>
    <content type="html"><![CDATA[<p>总的来说，微服务并不是指某一个具体的技术。推崇者认为它得益于Eric Evans的领域驱动设计、持续交付、Alistair Cockburn的六边形架构、基础设施可视平台和小型全功能团队等众多近年内不断涌现的高效实践。ThoughtWorks的Sam Newman认为，微服务包含两方面含义：小且只专注做一件事，自治性。</p>

<h3>1.服务建模</h3>

<p>在概念篇中我们已经提到，服务其实就是系统中的组件。容易理解的是，好的服务设计也就是常说的“高内聚、松耦合”。意味着多个服务之间的低依赖性、以及服务内部的行为紧相关性。这种特征使得代码变更带来的影响面尽可能小，同时实现快速简单部署。那么服务建模的目的就在于寻找问题域中的边界，划分出相关行为，同时保证边界间通信的低依赖性。
微服务推荐DDD的设计思想，鼓励在构建系统时参考真实世界中的领域，而不是套用分层架构。其中最重要的概念就是边界上下文——即任何领域都可以被认为是由许多边界上下文构成，其内部容纳着具体的物（模型），其中有的物无需和外界进行通信，有的物则与其它边界上下文共享。每个边界上下文都包含一个显式接口，决定哪些物共享出去的。</p>

<p>边界上下文的另一个简单解释就是“一种被显式边界强化的特定职责”。当你想和边界上下文内部进行通信，或是请求其内部的某些功能时，你需要携带模型和它的显式边界进行通信。Evan把边界上下文比喻为细胞，而决定物质进出的细胞膜就是显式边界。微服务把边界上下文和服务紧密联系在一起，尽管边界上下文可以是任何一种组件或模块，其可以存在于单一系统中，也可以存在于独立进程中。而后者也就是微服务的例子。</p>

<p>然而过早确定边界是不明智的，特别是在初期，一旦边界不稳定，就会造成更多的修改和成本增加。比较好的方法是在一个成熟codebase上划分边界，而非一开始就这么做。</p>

<p>在划分边界上下文时，需要注意该上下文对领域内其余部分提供的业务能力，而这种业务能力通过共享模型实现信息交换。而如果对单纯的CRUD操作划分边界，失去了它的业务意义，则完全没有必要。</p>

<p>在实践中，一般是自顶向下划分出边界上下文，粒度也应当是由粗到细。然而在演进的过程中，是否独立出内嵌的上下文，则取决于设计和团队等因素，如果某个团队同时负责若干个上下文，则可能会把它们组合成一个较大的上下文而非全部分离出来。这种内嵌上下文的另一个好处在于，较粗的架构能简化测试，特别是针对庞大复杂的end-to-end测试。</p>

<h3>2.服务集成</h3>

<p>服务集成是微服务架构中最重要、技术最相关的部分。一般存在两种风格：<a href="http://www.infoq.com/cn/news/2008/09/Orchestration?utm_source=infoq_en&amp;utm_medium=link_on_en_item&amp;utm_campaign=item_in_other_langs">编配和编排</a>，编配是指通过一个中心服务以同步通信的方式管理其它服务，编排则通过事件队列实现异步通信，相关服务自己监听相应事件。前者的优点是结构明确、易于开发，缺点是变更成本高、难以维护；后者则实现了松耦合，缺点是难以调试，需要额外的监控代价。
无论采用何种风格，都避免不了集成方法的选择。一般可用的集成方式有SOAP、XML-RPC、REST、Protocol Buffer等，但这些方法有一定的针对性。值得注意的是，编配风格的架构更易于构建，特别是带语义的请求/响应类型的通信，同步方式是最简洁的实现。相比之下，编排风格的架构就需要额外的callback机制处理响应数据。</p>

<h4>请求/响应类</h4>

<p>目前请求/响应类通信存在两种流行的方式：RPC和REST，其特点各不相同。</p>

<p>RPC包括多种技术，如SOAP、Java RMI、Thrift、Protocol Buffer等。其中SOAP采用XML格式的协议构建消息，其余则为纯二进制形式。
一些RPC技术仅限于某种特定领域，如Java RMI，必须运行在JVM中。尽管有些不限定语言或平台，但依然会带来或多或少的集成限制。
RPC的另一个缺点是过于“底层”，除SOAP外，几乎都直接基于TCP/UDP实现，然而由于网络环境的限制，应用不得不考虑可靠性、容错性、语义性。
在设计上，RPC方式如Java RMI过度依赖于服务接口和Model实现，任意变更都很可能影响服务端、客户端以及相关测试代码，并继而影响后续的测试和部署，这就是lock-step release。当然Thrift和Protocol Buffer为此改进了许多。</p>

<p>与RPC从底层构建不同的是，现代REST提供了更为抽象的<a href="http://martinfowler.com/articles/richardsonMaturityModel.html">架构方式</a>。一般来说，REST over HTTP是最易于实现的一种REST，但不是唯一途径，本文只就REST over HTTP展开讨论。</p>

<p>REST over HTTP的好处在于，二者拥有许多能够相互对应的概念，如动词GET、POST和PUT，其含义是十分明确的。此外，HTTP拥有极为完整的生态系统，从缓存代理Varnish、负载均衡modproxy、以及监控系统，这就使得构建系统变得十分高效。另外，HTTP还支持较完整的安全控制机制，从基本验证到客户端证书等等。
值得一提的是，SOAP同样基于HTTP，然而却抛弃了大量HTTP中极富内涵的概念，使得学习成本、系统复杂度都大大增加。
REST over HTTP也存在缺点，一、生成客户端stub的成本较高，超媒体控制客户端很可能以共享库的方式在微服务中广泛使用，从而导致变更困难；二、HTTP动词并没有得到服务器端的良好支持，但是通常有绕过的办法解决该问题；三、HTTP连接是基于TCP的，因此即使是JSON或二进制数据传输，性能也比不上Thrift这种纯二进制协议，对于低延迟的应用就更是如此。</p>

<h4>异步事件类</h4>

<p>事件处理需要考虑两方面内容：服务端发送和客户端接收。
传统的消息队列如RabbitMQ，试图一次解决上述问题。发送者通过API向队列中发送事件，队列处理针对这些事件的订阅，向接收者发出通知，甚至还能处理接收者状态，例如帮助跟踪历史消息。然而类似的中间件系统目前变的越来越臃肿，厂商向其注入了更多智能化组件，这不得不让人联想到ESB的情形。因此，时刻保持哑管道和智能终端，是引入中间件技术时必须要考虑的问题。
除此之外还有一个特殊选择：<a href="http://tools.ietf.org/html/rfc4287">ATOM</a>。ATOM本身就是基于REST的服务发布协议，由于开发库较完备，事实上也可被当作事件发布/订阅工具。同样，基于HTTP的架构具有良好的扩展性，却不适用低延迟应用。</p>

<p>尽管事件驱动架构具有诸如松耦合、可扩展等优点，但其带来的系统复杂性也随之大幅提高。或者至少应当着重注意监控过程，特别是跟踪跨服务边界的请求。<a href="http://www.enterpriseintegrationpatterns.com/">Enterprise Integration Patterns</a>是目前服务集成领域的权威著作。</p>

<h3>3. 服务集成需要注意的问题</h3>

<h4>服务即状态机</h4>

<p>无论是否采用REST，服务即状态机都是一种强大的思维模式。其核心在于，构建具有尽可能丰富功能的服务，而非将部分功能划分至服务外，例如管道甚至消费者一边，这会丧失高内聚的特性。举个例子，当消费者向提供者发送更新请求时，应由提供者一方决定是否接受这次修改，而非由消费者决定，从而保证数据和行为的一致性。</p>

<h4>重新思考DRY</h4>

<p>我们都清楚DRY的含义，并且了解DRY带来的好处。然而，在微服务架构中，服务间的代码共享可能会导致修改灾难，一般而言，应当允许一定的重复代码存在于不同服务中，而非使用统一的共享库。当然，微服务内部应遵循DRY原则。
一个例外是对客户端库的设计，客户端库能够方便保持整个系统的可靠性和可扩展性，例如引入服务发现、请求失败、日志等通用特性，这种DRY是有益的。但应注意保证客户端库不被具体的服务逻辑污染这一原则。</p>

<h4>引用访问</h4>

<p>当在服务请求间传递领域实体时，需要考虑值传递或引用传递两种方式。一般而言，消费者并不需要保证自己获取的资源是最新的。但某些特殊需求可能会有此限制，这时就需要在获取资源时同时取得该资源的引用方式，从而使消费者时刻能获取其最新的状态。当然，频繁的资源请求也会导致系统负载增加，这里我们需要考虑是否一定要实现实时更新，如果不是，则可以利用HTTP自身的缓存控制机制减轻负载；或者根据不同需求只传递需要的资源属性。</p>

<h4>版本化</h4>

<p>版本化会引入更多复杂性，因此在对服务接口进行变更时，尽量避免采用版本机制。如果一定要采用，应分配语义化版本，一般遵循MAJOR.MINOR.PATCH即可。这种令不同版本接口共存的做法，能够尽量减轻消费者的迁移压力。当然如果项目足够小，只需要保持新旧接口同时存在就好，版本化就太过了。</p>

<h4>用户界面集成</h4>

<p>用户界面集成几乎是任何系统都必须要考虑的问题，微服务中尤为如此。传统上，不同服务可能会有各自的UI组件，并嵌入在页面相应位置。然而该方法需要考虑用户体验的一致性，同时，由于要适应不同设备的需求，各UI组件还需要考虑响应式的问题。此外，有些服务并不能以单个UI组件的方式提供给用户，而可能存在与其它服务协作的情况。因此，用户界面最有效的构建方法就是前端负责UI，后端负责提供API，互不干涉。
整块前端的做法并不利于降低开发的复杂度。为了解决这一问题，采用API网关技术，针对不同设备的请求返回不同的内容聚集。然而API网关可能会导致该层过于复杂，有时会适得其反。一种轻量的解决方法是前端＋特定后端技术，即不采用整块API网关，而是针对不同设备构建特定的后端支持系统，尽量减轻复杂度。</p>

<h4>集成第三方应用</h4>

<p>采用第三方应用有时会显著降低成本，最简单的就是直接集成到现有微服务系统中，通过暴露应用API从而向其它角色提供服务。更进一步，如果能够抽象出系统角色，就能借助角色层连接微服务和该第三方应用。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Microservices陷阱：概念篇]]></title>
    <link href="http://www.hanyi.name/blog/2015/02/18/microservices-trap/"/>
    <updated>2015-02-18T20:33:00+08:00</updated>
    <id>http://www.hanyi.name/blog/2015/02/18/microservices-trap</id>
    <content type="html"><![CDATA[<p><em>2011年5月，microservice一词由一次在威尼斯举行的软件架构工作坊中被提出，直到次年的同次会议中被正式命名为microservices（微服务）。</em> <a href="http://martinfowler.com/articles/microservices.html">James Lewis, Martin Folwer</a></p>

<p>通常，微服务被用于描述一种架构风格。在这种风格下，单个应用软件被设计成一系列可独立部署的服务。尽管业界在微服务的具体定义上还有争议，但其基本上代表了自动化部署、智能终端、语言和数据的去中心化等特征。</p>

<h3>1.基本概念</h3>

<p>Martin是这样用一句话描述微服务的：</p>

<p><em>对于每一个小型服务，其拥有独立的进程、轻量化通信机制（通常是http请求）、这些服务围绕着业务上下文构建，并可以实现独立的自动化部署。而这种控制的去中心化允许不同服务可以采用不同的语言和数据库技术实现。</em></p>

<p>微服务的拥趸把与之相反的设计风格称为monolithic，也就是单一系统。在他们看来，凡是不符合微服务特征的架构，都属于单一系统。</p>

<h4>企业web应用中的单一系统和微服务架构</h4>

<p>基本的企业web应用架构包含三层，分别是用户界面层（页面）、数据层、以及服务端应用层。其中服务端应用层负责接收请求，处理领域逻辑，操作数据库，然后选择响应的视图。单一系统风格一般是指服务端应用层的设计，任何修改都需要对整个系统进行重新部署。</p>

<p>单一系统风格的缺点是：1.小的更新需要对整个系统进行重新构建和部署；2.单一系统内的模块化设计通常很难维持，事实上很难做到完全的修改隔离；3.扩展时需要考虑整个系统，而不是其中拥有真正需求的一小部分。</p>

<p>针对单一系统的上述问题，微服务提供了自己的解决方案：应用软件被设计为一系列服务，这些服务允许独立部署和扩展。每个服务需要提供一个稳固的模块边界，允许由不同语言和团队实现。</p>

<h3>2.微服务的基本特征</h3>

<h4>利用服务实现组件化</h4>

<p>在微服务中，组件化是目的，分割服务是方法。这里的组件是指实现替换和更新独立的软件单位。其中，在不同的场景中软件组件的定义可能不同。一种情况是采用库实现组件，这里的库是链接程序代码、并且直接在内存中调用的一种组件化形式。而对微服务而言，由于服务是进程隔离的，通常采用web service或者rpc实现相互通信的组件化。</p>

<p>基于服务的好处在于，1.允许独立部署，对整体变化更轻量，尽管有些改动不可避免地影响到接口层面，从而产生协同变化，但可以通过聚合服务边界和利用服务契约实现优化演进。2.更加明确的发布接口，对于语言层面来说，发布接口可能没有什么太好的办法，通常只能借助文档并且约束用户破坏组件的封装性，导致组件间的紧耦合。</p>

<p>当然服务也有缺点，首先rpc的效率远不及进程内调用，意味着远程api需要是粗粒度的，但使用起来并不方便。如果需要跨组件的职责变更，跨进程边界通常并不容易。再次，服务内的进程完全独立于外界，包括开发和部署，也就意味着应用服务器和数据库也应当是独立并仅为该服务使用的。</p>

<h4>围绕业务能力构建组织</h4>

<p>为了避免康威法则，应转变固有的以功能划分团队的方式，尽可能组建全功能团队。对于大型单一系统应用，几乎都可以围绕业务能力进行模块化，但这通常需要团队按照业务线划分，这里遇到的主要问题是，通常这些团队的组织都基于复杂的上下文。如果单一系统跨越了多个模块边界，那么对团队中的个体成员来说消化成本是非常高的。此外，模块线需要一个强有力的约定去保证实施。而服务组件能够提供更加明确的分割，从而使团队边界更清晰。</p>

<h4>产品而非项目</h4>

<p>绝大多数的应用开发采用项目模型的方式运作，即完成软件并交付给运维团队，然后开发团队解散。而微服务建议摈弃这种项目形式，而是让团队拥有产品的整个生命周期。这种做法的好处是令整个开发团队能够更进一步和用户接触，承担一定的用户支持任务，并理解用户的业务需求。而对于单一系统而言，该做法几乎很难实现。</p>

<h4>智能终端和哑管道</h4>

<p>当构建不同过程间的通信框架时，多数做法是将业务智能整合进通信机制中，例如Enterprise Service Bus，ESB。ESB产品通常包括了消息路由、编排、变换、乃至业务规则的制定等复杂功能。智能终端和哑管道则相反，由于解耦的需求，服务应当拥有其自身的逻辑，采用类似REST的通信协议，而非WS-Choreography，BPEL或其它采用集中式工具编写的复杂协议。两个好的例子分别是Http API（或protobuf）和轻量级消息总线。后者通常的特点也是“哑”的，如RabbitMQ或ZeroMQ，它们仅仅提供一套异步纤程，智能仍掌握在终端服务手中。</p>

<p>当你试图从单一系统转移至微服务时，最大的难点在于解决内部消息机制。而朴素的转移可能会导致不良通信行为，这里可能需要采用粗粒度方法解决细粒度通信的问题。</p>

<h4>去中心化的控制</h4>

<p>控制中心化的一个结果是使单一的系统平台成为标准，这么做的缺点在于，并非每个问题都是钉子，也并不是每个问题都是锤子，更恰当的方法是在具体情况下采用正确的工具。</p>

<p>微服务的理念是条条大路通罗马式的，也就是说强调服务的独立性。实际上，你会发现越来越多的开发人员开始从自己的实现中分离出实用工具，并分享至社区（工具之间可能拥有类似的功能，却存在不同的实现形式）。</p>

<p>然而这种自由并不意味着微服务并不遵守服务契约。恰恰相反，像是Tolerant Reader和Consumer-Driven Contracts这种契约模式经常被用于微服务实现，帮助服务能够独立发展。同时契约能够保证新服务开发的精简性，保证YAGNI原则，提高开发效率。</p>

<h4>去中心化的数据管理</h4>

<p>目前存在许多方法来解决数据管理中心化的问题。在最抽象级，就意味着划分出系统间不同的概念模型。例如，在大型企业级应用中，顾客的销售视图和支持视图之间存在差异，在销售视图中的顾客信息并不会存在于所有支持视图中，而这又会由于不同语义间的细微差别而存在不同或相同情况。</p>

<p>基于上述原因，如果试图把单一系统划分为多个分离的组件，采用领域驱动设计DDD会是一个不错的方法。DDD能够把复杂的领域分解成多个带边界的上下文，并建立其相互之间的映射关系。对于单一系统和微服务来说DDD都很有效，而后者在概念上更加符合DDD增加隔离的思想。</p>

<p>当基于概念模型进行去中心化时，微服务同样要求把数据存储去中心，而单一系统则采用单独的逻辑数据库进行持久化，企业甚至倾向于使用同一个数据库覆盖多种应用（这在很大程度上取决于供应商的许可证业务）。微服务则更加极端，既可以采用同一数据库技术的多个实例，或者采用完全不同的数据库技术实现（Polyglot Persistence，同样可适用于单一系统）。</p>

<p>这里最大的问题是变更管理，因为在许多应用场景中，单一系统采用事务处理的方式保证多个资源间的一致性。而在分布式系统中，事务无疑变得十分困难，这令微服务面临两难的问题：既要保持分割独立，又要保证一致性。而在实际上，微服务的设计思想倾向于强调服务间的弱事务性。这就使得一致性只可能是最终一致性，并采用弥补操作解决相关出现的问题。</p>

<p>这种非一致性管理的问题对多数团队都是一项挑战，但在实际业务中却时有发生。有时具体业务会要求将不一致性保持在一定程度以内，从而快速响应需求，同时拥有一些类似于回退的过程处理错误。一旦修复这些错误的耗费小于保证业务的强一致性，这种权衡就是值得的。</p>

<h4>基础设施自动化</h4>

<p>近年来，基础设施自动化技术取得了巨大的进步，特别是类似AWS这种公有云服务的兴起，降低了构建、部署、以及操作微服务的门槛。</p>

<p>一般来说，采用微服务的团队通常都能熟练应用持续集成CI、甚至持续交付CD技术，拥有丰富的基础设施自动化背景。CI/CD的目标是令构建和部署变得“无趣”，一旦目标达成，任何扩展就变得非常容易实现，而这在单一系统上已经得到了充分验证。对于微服务来说，该项技术与单一系统相比没有太大区别，但两者的操作域存在明显区别。</p>

<h4>高融错设计</h4>

<p>当采用服务作为应用组件以后，该应用就需要被设计成面向服务的高容错系统。而在实际情况中，任何服务都有可能发生错误而中止服务，客户端必须据此给出合理的响应。与单一系统相比，这是一个存在于微服务系统中的额外复杂度。</p>

<p>首先是测试，包括在生产环境中执行自动测试，以及当某些服务或者数据中心出错的意外情况恢复和监控。然而对习惯于单一系统的运维团队来说，这种方式可能是一时难以接受。
微服务特别强调服务的实时监控，无论是架构方面，还是业务方面，这种语义化监控能够提早给出出错警告并同时开发团队。对于单一系统，可以把单个应用视为一个微服务，区别是你需要在不同进程中的服务出错时得到警告。而由于单一系统通常采用库实现组件化，相同进程内的服务出错可能并不会得到明确的警告。</p>

<p>总而言之，微服务要求较为完善的监控和日志系统，同时拥有一个实时的dashboard随时通知开发团队，重要的测量单位有断路器状态、吞吐量、延迟等等。</p>

<h4>演进化设计</h4>

<p>微服务的实践者通常拥有演进化设计背景，他们把服务分解当作未来控制变更的工具之一。控制变更的目的并非是要降低变更频率，而是保证更好、更快地控制变更对软件的影响。
无论何时对现有系统进行组件化分解，你都需要遵守一个分解原则：组件的关键属性之一是独立可替换和升级。这就意味着我们需要寻找一个点，能够通过重写这部分的组件而不会影响其它组件。而实际上，很多团队选择直接将服务碎片化，而非进行长期演进。</p>

<p>在模块化设计中，一个通用的准则是强调可替换性，这样就可以保证接受变更。当你发现你需要重复的修改两个服务时，那就意味着它们应当被合并。</p>

<p>微服务的优势是降低变更发生时的构建和部署时间，缺点是你需要考虑服务变更对消费者带来的影响。一个传统的解决方式是采用服务版本管理策略，但对于微服务来说，应当尽量不要进行版本管理。在许多情况下，我们可以通过设计使得服务尽可能接受不同的消费者请求。</p>

<h3>2. 总结</h3>

<p>上文几乎列出了微服务架构到目前为止被发现的全部优点，这里列出其缺陷或尚未解决的问题：</p>

<h4>组件边界的确定</h4>

<p>由于微服务本质上是采用服务实现系统组件化，那么组件边界就成为衡量微服务设计优劣的重要参考价值。一旦设计完成，任何代码级重构、借口变更、向下兼容、以及测试架构的复杂度都会提升。</p>

<h4>组件的组成</h4>

<p>当组件的组成方式存在瑕疵，剩下来能做的就是把组件内的复杂性转移至组件连接部分。当你关注组件内部时，应当注意组件间的组成方式设计。</p>

<h4>团队技能</h4>

<p>任何新技术都倾向于更适合拥有中高级能力的团队，但并非对其它团队完全无用。即使是采用单一系统，某些团队依然做的一团糟，而微服务表现如何犹未可知。</p>

<p>最后给出Martin对何时向微服务架构迈进的评论：
<em>One reasonable argument we&rsquo;ve heard is that you shouldn&rsquo;t start with a microservices architecture. Instead begin with a monolith, keep it modular, and split it into microservices once the monolith becomes a problem. (Although this advice isn&rsquo;t ideal, since a good in-process interface is usually not a good service interface.)</em></p>
]]></content>
  </entry>
  
</feed>
